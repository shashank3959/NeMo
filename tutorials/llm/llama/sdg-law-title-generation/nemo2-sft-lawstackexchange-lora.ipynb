{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Llama 3.1 LoRA adapter with NeMo Framework using a Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook showcases performing LoRA finetuning on **Llama 3.1-8B** with a synthetically augmented version of [Law Stack Exchange](https://huggingface.co/datasets/ymoslem/Law-StackExchange) dataset using NeMo Framework. Law StackExchange is a dataset of legal question/answers. Each record consists of a question, its title, as well as human-provided answers.\n",
    "\n",
    "For this demonstration, we will tune the model on the task of title/subject generation, that is, given a Law Stack Exchange forum question, auto-generate an appropriate title for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites and Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** Run this notebook inside the [NeMo Framework container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo) which includes all required dependencies. See the tutorial README for instructions on downloading the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!apt-get update && apt-get install -y graphviz\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NEMO_DATASETS_CACHE\"] = \"/nemo-experiments/data-cache-chat\"\n",
    "os.environ[\"NEMO_MODELS_CACHE\"] = \"/nemo-experiments/models/\"\n",
    "\n",
    "\n",
    "# Configure the number of GPUs to use\n",
    "NUM_GPU_DEVICES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Required) Configure your HuggingFace token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# login(token=getpass(\"Input your HF Access Token\"))\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) Configure your WandB token for experiment tracking.\n",
    "\n",
    "Leave empty and press \"Enter\" when prompted if you don't wish to configure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# WANDB_API_KEY = getpass(\"Your Wandb API Key:\")\n",
    "WANDB_API_KEY = \"\"\n",
    "\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1. Import the Hugging Face Checkpoint\n",
    "We use the `llm.import_ckpt` API to download the specified model using the \"hf://<huggingface_model_id>\" URL format. It will then convert the model into NeMo 2.0 format. For all model supported in NeMo 2.0, refer to [Large Language Models](https://docs.nvidia.com/nemo-framework/user-guide/24.09/llms/index.html#large-language-models) section of NeMo Framework User Guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-08-05 02:19:47 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import nemo_run as run\n",
    "from megatron.core.optimizer import OptimizerConfig\n",
    "from nemo import lightning as nl\n",
    "from nemo.collections import llm\n",
    "from nemo.collections.llm.recipes.precision.mixed_precision import bf16_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llm.import_ckpt is the Nemo2 API for converting Hugging Face checkpoint to NeMo format\n",
    "example python usage:\n",
    "\n",
    "```python\n",
    "llm.import_ckpt(model=llm.llama3_8b.model(), source=\"hf://meta-llama/Meta-Llama-3.1-8B\")\n",
    "```\n",
    "Below we wrap this with run.Partial to configure it, and then we execute it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─ </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.import_ckpt with id: nemo.collections.llm.api.import_ckpt_1754360…</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─ \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.import_ckpt with id: nemo.collections.llm.api.import_ckpt_1754360…\u001b[0m\u001b[92m ─\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.import_ckpt/nemo.collections.llm.api.import_ckpt_1754360388/nemo.collections.llm.api.import_ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02:19:49] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.import_ckpt for experiment </span>                     <a href=\"file:///opt/Run/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/Run/nemo_run/run/experiment.py#771\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">771</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.import_ckpt</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02:19:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.import_ckpt for experiment \u001b[0m                     \u001b]8;id=924464;file:///opt/Run/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=639015;file:///opt/Run/nemo_run/run/experiment.py#771\u001b\\\u001b[2m771\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.import_ckpt\u001b[0m                                                   \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.import_ckpt/nemo.collections.llm.api.import_ckpt_1754360388/nemo.collections.llm.api.import_ckpt\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.import_ckpt-mpkfjns3cmtql\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.import_ckpt_1754360388 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.import_ckpt_1754360388 to finish\u001b[0m\u001b[92m ─────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.import_ckpt_1754360388</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.import_ckpt_1754360388\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.import_ckpt</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.import_ckpt-mpkfjns3cmtql\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/nemo.collections.llm.api.import_ckpt/nemo.collections.llm.api.import_ckpt_1754360388/nemo.collections.llm.api.import_ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.import_ckpt\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.import_ckpt-mpkfjns3cmtql\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/nemo.collections.llm.api.import_ckpt/nemo.collections.llm.api.import_ckpt_1754360388/nemo.collections.llm.api.import_ckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.import_ckpt-mpkfjns3cmtql to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mport_ckpt/0 [NeMo W 2025-08-05 02:20:00 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "mport_ckpt/0       warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "mport_ckpt/0     \n",
      "mport_ckpt/0 \u001b[32m $\u001b[0m\u001b[32mNEMO_MODELS_CACHE\u001b[0m\u001b[32m=\u001b[0m\u001b[32m/nemo-experiments/\u001b[0m\u001b[32mmodels\u001b[0m\u001b[32m \u001b[0m\n",
      "mport_ckpt/0 \u001b[1;34mImported Checkpoint\u001b[0m\n",
      "mport_ckpt/0 ├── \u001b[1;36mcontext/\u001b[0m\n",
      "mport_ckpt/0 │   ├── \u001b[1;36martifacts/\u001b[0m\n",
      "mport_ckpt/0 │   │   └── \u001b[33mgeneration_config.json\u001b[0m\n",
      "mport_ckpt/0 │   ├── \u001b[1;36mnemo_tokenizer/\u001b[0m\n",
      "mport_ckpt/0 │   │   ├── \u001b[33mspecial_tokens_map.json\u001b[0m\n",
      "mport_ckpt/0 │   │   ├── \u001b[33mtokenizer.json\u001b[0m\n",
      "mport_ckpt/0 │   │   └── \u001b[33mtokenizer_config.json\u001b[0m\n",
      "mport_ckpt/0 │   ├── \u001b[33mio.json\u001b[0m\n",
      "mport_ckpt/0 │   └── \u001b[37mmodel.yaml\u001b[0m\n",
      "mport_ckpt/0 └── \u001b[1;36mweights/\u001b[0m\n",
      "mport_ckpt/0     ├── \u001b[37m.metadata\u001b[0m\n",
      "mport_ckpt/0     ├── \u001b[37m__0_0.distcp\u001b[0m\n",
      "mport_ckpt/0     ├── \u001b[37m__0_1.distcp\u001b[0m\n",
      "mport_ckpt/0     ├── \u001b[35mcommon.pt\u001b[0m\n",
      "mport_ckpt/0     └── \u001b[33mmetadata.json\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.import_ckpt-mpkfjns3cmtql finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.import_ckpt']</span><span style=\"background-color: #272822\">                        </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.import_ckpt_1754360388\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.import_ckpt\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.import_ckpt\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">             </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.import_ckpt']\u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.import_ckpt_1754360388\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.import_ckpt\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.import_ckpt\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.import_ckpt_1754360388</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.import_ckpt_1754360388 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.import_ckpt_1754360388 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.import_ckpt_1754360388\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.import_ckpt_1754360388\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.import_ckpt_1754360388\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# We use run.Partial from NeMo-Run to configure this function\n",
    "def configure_checkpoint_conversion():\n",
    "    return run.Partial(\n",
    "        llm.import_ckpt,\n",
    "        model=llm.llama31_8b.model(),\n",
    "        source=\"hf://meta-llama/Llama-3.1-8B\",\n",
    "        overwrite=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# configure your function\n",
    "import_ckpt = configure_checkpoint_conversion()\n",
    "\n",
    "# define your executor\n",
    "local_executor = run.LocalExecutor()\n",
    "\n",
    "# run your experiment\n",
    "run.run(import_ckpt, executor=local_executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps downloads the checkpoint from HuggingFace, converts it to NeMo format, and saves it to the directory specified by the `NEMO_MODELS_CACHE` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context  weights\n"
     ]
    }
   ],
   "source": [
    "!ls $NEMO_MODELS_CACHE/meta-llama/Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2. Prepare the Data and Customize the DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NeMo 2.0 provides a generic `FineTuningDataModule` class that you can extend for custom preprocessing.\n",
    "\n",
    "To use your own data, subclass `FineTuningDataModule` to leverage existing data handling logic (e.g., packed sequences). You may see the [`FineTuningDataModule`](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/gpt/data/fine_tuning.py) class for reference.\n",
    "\n",
    "For more data modules (including [Chat](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/gpt/data/chat.py)), refer to the [data module directory](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/llm/gpt/data).\n",
    "\n",
    "Below, we extend the `FineTuningDataModule` for the LawStackExchange dataset. Beyond all the boilerplate code, take note of the two methods, that we tweak -\n",
    "1. `_download_data()` that downloads the dataset\n",
    "2. `_preprocess_and_split_data()` has any cleaning and splitting logic, to prepare the dataset as **train/val/test.jsonl** files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lse_datamodule.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lse_datamodule.py\n",
    "\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from nemo.collections.llm.gpt.data.core import get_dataset_root\n",
    "from nemo.collections.llm.gpt.data.fine_tuning import FineTuningDataModule\n",
    "from nemo.lightning.io.mixin import IOMixin\n",
    "from nemo.utils import logging\n",
    "\n",
    "\n",
    "class LawStackExchangeDataModule(FineTuningDataModule, IOMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_length: int = 2048,\n",
    "        tokenizer: Optional[\"TokenizerSpec\"] = None,\n",
    "        micro_batch_size: int = 4,\n",
    "        global_batch_size: int = 8,\n",
    "        rampup_batch_size: Optional[List[int]] = None,\n",
    "        force_redownload: bool = False,\n",
    "        delete_raw: bool = True,\n",
    "        seed: int = 1234,\n",
    "        memmap_workers: int = 1,\n",
    "        num_workers: int = 8,\n",
    "        pin_memory: bool = True,\n",
    "        persistent_workers: bool = False,\n",
    "        packed_sequence_specs: Optional[\"PackedSequenceSpecs\"] = None,\n",
    "        dataset_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    ):\n",
    "        self.force_redownload = force_redownload\n",
    "        self.delete_raw = delete_raw\n",
    "\n",
    "        super().__init__(\n",
    "            dataset_root=get_dataset_root(\"lse\"),\n",
    "            seq_length=seq_length,\n",
    "            tokenizer=tokenizer,\n",
    "            micro_batch_size=micro_batch_size,\n",
    "            global_batch_size=global_batch_size,\n",
    "            rampup_batch_size=rampup_batch_size,\n",
    "            seed=seed,\n",
    "            memmap_workers=memmap_workers,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            persistent_workers=persistent_workers,\n",
    "            packed_sequence_specs=packed_sequence_specs,\n",
    "            dataset_kwargs=dataset_kwargs,\n",
    "        )\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # if train file is specified, no need to do anything\n",
    "        if not self.train_path.exists() or self.force_redownload:\n",
    "            dset = self._download_data()\n",
    "            self._preprocess_and_split_data(dset)\n",
    "        super().prepare_data()\n",
    "\n",
    "    def _download_data(self):\n",
    "        logging.info(f\"Downloading {self.__class__.__name__}...\")\n",
    "        return load_dataset(\n",
    "            \"ymoslem/Law-StackExchange\",\n",
    "            cache_dir=str(self.dataset_root),\n",
    "            download_mode=\"force_redownload\" if self.force_redownload else None,\n",
    "        )\n",
    "\n",
    "    def _preprocess_and_split_data(\n",
    "        self, dset, train_ratio: float = 0.85, val_ratio: float = 0.13\n",
    "    ):\n",
    "        print(\n",
    "            f\"Preprocessing {self.__class__.__name__} to jsonl format and splitting...\"\n",
    "        )\n",
    "\n",
    "        test_ratio = 1 - train_ratio - val_ratio\n",
    "        save_splits = {}\n",
    "        dataset = dset.get(\"train\")\n",
    "        split_dataset = dataset.train_test_split(\n",
    "            test_size=val_ratio + test_ratio, seed=self.seed\n",
    "        )\n",
    "        split_dataset2 = split_dataset[\"test\"].train_test_split(\n",
    "            test_size=test_ratio / (val_ratio + test_ratio), seed=self.seed\n",
    "        )\n",
    "        save_splits[\"training\"] = split_dataset[\"train\"]\n",
    "        save_splits[\"validation\"] = split_dataset2[\"train\"]\n",
    "        save_splits[\"test\"] = split_dataset2[\"test\"]\n",
    "\n",
    "        for split_name, dataset in save_splits.items():\n",
    "            print(f\"Processing {split_name} split ...\")\n",
    "            output_file = self.dataset_root / f\"{split_name}.jsonl\"\n",
    "            with output_file.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                for example in dataset:\n",
    "                    # Cleanup - Remove HTML tags from the question body\n",
    "                    cleaned_question_body = re.sub(\n",
    "                        \"<[^<]+?>\", \"\", example[\"question_body\"]\n",
    "                    )\n",
    "\n",
    "                    # Create the formatted input string\n",
    "                    input_text = (\n",
    "                        \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\"\n",
    "                        f\"\\nQUESTION: {cleaned_question_body.strip()} \\nTITLE: \"\n",
    "                    )\n",
    "\n",
    "                    # Write the JSON object to the file\n",
    "                    json_line = json.dumps(\n",
    "                        {\"input\": input_text, \"output\": example[\"question_title\"]}\n",
    "                    )\n",
    "                    f.write(json_line + \"\\n\")\n",
    "\n",
    "            print(f\"{split_name} split saved to {output_file}\")\n",
    "\n",
    "        if self.delete_raw:\n",
    "            for p in self.dataset_root.iterdir():\n",
    "                if p.is_dir():\n",
    "                    shutil.rmtree(p)\n",
    "                elif \".jsonl\" not in str(p.name):\n",
    "                    p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more data modules (including [Chat](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/gpt/data/chat.py)), refer to the [data module directory](https://github.com/NVIDIA/NeMo/tree/main/nemo/collections/llm/gpt/data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does a sanity check, and visualizes the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lse_datamodule import LawStackExchangeDataModule\n",
    "\n",
    "test_datamodule = LawStackExchangeDataModule(\n",
    "    seq_length=2048, micro_batch_size=1, global_batch_size=8\n",
    ")\n",
    "\n",
    "test_datamodule.prepare_data()  # Downloads and preprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: Suppose person A tells person B, \\\"If you perform (service X) for me, I will donate $1,000 to Save the Whales (but no other compensation).\\\" Neither A nor B has any connection to whales and will not benefit from this donation, but B happens to like whales and agrees anyway. Does this still count as consideration, even though there was never any possibility of B getting anything out of it? (United States) \\nTITLE: \", \"output\": \"Does consideration have to have value for someone who is a party to the contract?\"}\n"
     ]
    }
   ],
   "source": [
    "!head -n1 {test_datamodule.train_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Example format:\n",
    " - \"input\" contains the prompt plus user question\n",
    " - \"output\" contains the the desired autogenerated post title\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: Suppose person A tells person B, \\\"If you perform (service X) for me, I will donate $1,000 to Save the Whales (but no other compensation).\\\" Neither A nor B has any connection to whales and will not benefit from this donation, but B happens to like whales and agrees anyway. Does this still count as consideration, even though there was never any possibility of B getting anything out of it? (United States) \\nTITLE: \", \n",
    "    \"output\": \"Does consideration have to have value for someone who is a party to the contract?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data example is saved as a json string as one line in the `train/validation/test.jsonl` file, under `NEMO_DATASETS_CACHE` directory you specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19496 /nemo-experiments/data-cache-chat/lse/training.jsonl\n",
      "3655 /nemo-experiments/data-cache-chat/lse/validation.jsonl\n",
      "1219 /nemo-experiments/data-cache-chat/lse/test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Check the number of lines in the train, validation, and test files\n",
    "!wc -l {test_datamodule.train_path}\n",
    "!wc -l {test_datamodule.validation_path}\n",
    "!wc -l {test_datamodule.test_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've validated that the data preparation works as expected, the following code wraps the `LawStackExchangeDataModule` into a run.Config object that can be passed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse_data() -> run.Config[pl.LightningDataModule]:\n",
    "    return run.Config(\n",
    "        LawStackExchangeDataModule,\n",
    "        seq_length=2048,\n",
    "        micro_batch_size=4,\n",
    "        global_batch_size=16,\n",
    "        num_workers=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Synthetic Data Generation using NeMo Curator\n",
    "\n",
    "If you are following the tutorial to augment this data with [synthetic data generation using NeMo Curator](https://github.com/NVIDIA/NeMo-Curator/tree/main/tutorials/peft-curation-with-sdg), your steps above would look slightly different.\n",
    "\n",
    "You may follow the [documentation](https://docs.nvidia.com/nemo-framework/user-guide/latest/data/finetune_data.html#option-2-use-finetuningdatamodule-with-preprocessed-data) for using the `FineTuningDataModule` directly by pointing them to the prepared .jsonl files.\n",
    "\n",
    "1. Organize your data into a directory like\n",
    "```bash\n",
    "curated-data\n",
    "    ├── training.jsonl\n",
    "    ├── validation.jsonl\n",
    "    └── test.jsonl\n",
    "```\n",
    "\n",
    "2. Then you may define your data module as\n",
    "\n",
    "```python\n",
    "\n",
    "def lse_data() -> run.Config[pl.LightningDataModule]:\n",
    "    return run.Config(\n",
    "        FineTuningDataModule,\n",
    "        dataset_root=\"/path/to/curated-data\",\n",
    "        seq_length=2048,\n",
    "        micro_batch_size=4,\n",
    "        global_batch_size=16,\n",
    "        num_workers=0,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Configure LoRA with the NeMo 2.0 API \n",
    "\n",
    "First we configure the following components for training. These components are similar between SFT and PEFT (LoRA). SFT and PEFT both uses `llm.finetune` API. To switch from PEFT to SFT, you just need to remove the `peft` parameter.\n",
    "\n",
    "### 3.1: Configure the Trainer\n",
    "The NeMo 2.0 Trainer works similarly to the PyTorch Lightning trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer() -> run.Config[nl.Trainer]:\n",
    "    strategy = run.Config(nl.MegatronStrategy, tensor_model_parallel_size=1)\n",
    "    trainer = run.Config(\n",
    "        nl.Trainer,\n",
    "        devices=NUM_GPU_DEVICES,\n",
    "        max_steps=1000,\n",
    "        accelerator=\"gpu\",\n",
    "        strategy=strategy,\n",
    "        plugins=bf16_mixed(),\n",
    "        log_every_n_steps=1,\n",
    "        limit_val_batches=2,\n",
    "        val_check_interval=10,\n",
    "        num_sanity_val_steps=0,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2: Configure the Logger\n",
    "Configure your training steps, output directories and logging through `NeMoLogger`. In the following example, the experiment output will be saved at `log_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"506pt\" height=\"291pt\"\n",
       " viewBox=\"0.00 0.00 506.00 291.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 287)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-287 502,-287 502,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"0,-113.5 0,-132.5 276,-132.5 276,-113.5 0,-113.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-113.5 0,-132.5 276,-132.5 276,-113.5 0,-113.5\"/>\n",
       "<text text-anchor=\"start\" x=\"73.5\" y=\"-121.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"105.5\" y=\"-121.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> ModelCheckpoint</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,-94.5 0,-113.5 147,-113.5 147,-94.5 0,-94.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-94.5 0,-113.5 147,-113.5 147,-94.5 0,-94.5\"/>\n",
       "<text text-anchor=\"start\" x=\"100\" y=\"-101.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">monitor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-94.5 147,-113.5 276,-113.5 276,-94.5 147,-94.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-101.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;reduced_train_loss&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,-75.5 0,-94.5 147,-94.5 147,-75.5 0,-75.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-75.5 0,-94.5 147,-94.5 147,-75.5 0,-75.5\"/>\n",
       "<text text-anchor=\"start\" x=\"88\" y=\"-82.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_last</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-75.5 147,-94.5 276,-94.5 276,-75.5 147,-75.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-82.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,-56.5 0,-75.5 147,-75.5 147,-56.5 0,-56.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-56.5 0,-75.5 147,-75.5 147,-56.5 0,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_top_k</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-56.5 147,-75.5 276,-75.5 276,-56.5 147,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,-37.5 0,-56.5 147,-56.5 147,-37.5 0,-37.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-37.5 0,-56.5 147,-56.5 147,-37.5 0,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"28\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">every_n_train_steps</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-37.5 147,-56.5 276,-56.5 276,-37.5 147,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">200</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,-18.5 0,-37.5 147,-37.5 147,-18.5 0,-18.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-18.5 0,-37.5 147,-37.5 147,-18.5 0,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"4\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_on_train_epoch_end</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,-18.5 147,-37.5 276,-37.5 276,-18.5 147,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0,0.5 0,-18.5 147,-18.5 147,0.5 0,0.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,0.5 0,-18.5 147,-18.5 147,0.5 0,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"4\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_optim_on_train_end</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"147,0.5 147,-18.5 276,-18.5 276,0.5 147,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"52,-264 52,-283 352,-283 352,-264 52,-264\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-264 52,-283 352,-283 352,-264 52,-264\"/>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-272\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"184.5\" y=\"-272\" font-family=\"Courier,monospace\" font-size=\"10.00\"> NeMoLogger</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"52,-245 52,-264 181,-264 181,-245 52,-245\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-245 52,-264 181,-264 181,-245 52,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-252\" font-family=\"Courier,monospace\" font-size=\"10.00\">name</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181,-245 181,-264 352,-264 352,-245 181,-245\"/>\n",
       "<text text-anchor=\"start\" x=\"185\" y=\"-252\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;nemo2_llama31_8b_lse_peft&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"52,-226 52,-245 181,-245 181,-226 52,-226\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-226 52,-245 181,-245 181,-226 52,-226\"/>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-233\" font-family=\"Courier,monospace\" font-size=\"10.00\">log_dir</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181,-226 181,-245 352,-245 352,-226 181,-226\"/>\n",
       "<text text-anchor=\"start\" x=\"185\" y=\"-233\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;/nemo&#45;experiments/results&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"52,-207 52,-226 181,-226 181,-207 52,-207\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-207 52,-226 181,-226 181,-207 52,-207\"/>\n",
       "<text text-anchor=\"start\" x=\"56\" y=\"-214\" font-family=\"Courier,monospace\" font-size=\"10.00\">use_datetime_version</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181,-207 181,-226 352,-226 352,-207 181,-207\"/>\n",
       "<text text-anchor=\"start\" x=\"185\" y=\"-214\" font-family=\"Courier,monospace\" font-size=\"10.00\">False</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"52,-188 52,-207 181,-207 181,-188 52,-188\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-188 52,-207 181,-207 181,-188 52,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"152\" y=\"-195\" font-family=\"Courier,monospace\" font-size=\"10.00\">ckpt</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181,-188 181,-207 352,-207 352,-188 181,-188\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"185,-192 185,-203 348,-203 348,-192 185,-192\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"185,-192 185,-203 348,-203 348,-192 185,-192\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"52,-169 52,-188 181,-188 181,-169 52,-169\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"52,-169 52,-188 181,-188 181,-169 52,-169\"/>\n",
       "<text text-anchor=\"start\" x=\"146\" y=\"-176\" font-family=\"Courier,monospace\" font-size=\"10.00\">wandb</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181,-169 181,-188 352,-188 352,-169 181,-169\"/>\n",
       "<polygon fill=\"#fff8dc\" stroke=\"transparent\" points=\"185,-173 185,-184 348,-184 348,-173 185,-173\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"185,-173 185,-184 348,-184 348,-173 185,-173\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;1:c</title>\n",
       "<path fill=\"none\" stroke=\"#73be73\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M262.71,-191.72C253.09,-182.14 228.71,-157.86 204.04,-133.28\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#fff8dc\" stroke=\"transparent\" points=\"294,-75.5 294,-94.5 498,-94.5 498,-75.5 294,-75.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"294,-75.5 294,-94.5 498,-94.5 498,-75.5 294,-75.5\"/>\n",
       "<text text-anchor=\"start\" x=\"343.5\" y=\"-83.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"375.5\" y=\"-83.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> WandbLogger</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"294,-56.5 294,-75.5 345,-75.5 345,-56.5 294,-56.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"294,-56.5 294,-75.5 345,-75.5 345,-56.5 294,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"316\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">name</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345,-56.5 345,-75.5 498,-75.5 498,-56.5 345,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"349\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;LSE_Run_1&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"294,-37.5 294,-56.5 345,-56.5 345,-37.5 294,-37.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"294,-37.5 294,-56.5 345,-56.5 345,-37.5 294,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"298\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">project</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345,-37.5 345,-56.5 498,-56.5 498,-37.5 345,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"349\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;NeMo2_LoRA_LSE_Example&#39;</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;2:c</title>\n",
       "<path fill=\"none\" stroke=\"#cbc6b0\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M271.9,-172.84C286.72,-160.26 331.98,-121.84 363.54,-95.06\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Config[NeMoLogger(\n",
       "  name='nemo2_llama31_8b_lse_peft',\n",
       "  log_dir='/nemo-experiments/results',\n",
       "  use_datetime_version=False,\n",
       "  ckpt=<Config[ModelCheckpoint(\n",
       "    monitor='reduced_train_loss',\n",
       "    save_last=True,\n",
       "    save_top_k=1,\n",
       "    every_n_train_steps=200,\n",
       "    save_on_train_epoch_end=True,\n",
       "    save_optim_on_train_end=True)]>,\n",
       "  wandb=<Config[WandbLogger(name='LSE_Run_1', project='NeMo2_LoRA_LSE_Example')]>)]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "LOG_DIR = \"/nemo-experiments/results\"\n",
    "LOG_NAME = \"nemo2_llama31_8b_lse_peft\"\n",
    "\n",
    "def logger() -> run.Config[nl.NeMoLogger]:\n",
    "    ckpt = run.Config(\n",
    "        nl.ModelCheckpoint,\n",
    "        save_last=True,\n",
    "        every_n_train_steps=200,\n",
    "        monitor=\"reduced_train_loss\",\n",
    "        save_top_k=1,\n",
    "        save_on_train_epoch_end=True,\n",
    "        save_optim_on_train_end=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    if WANDB_API_KEY is not None and WANDB_API_KEY != \"\":\n",
    "        wandb_config = run.Config(\n",
    "            WandbLogger, project=\"NeMo2_LoRA_LSE_Example\", name=\"LSE_Run_1\"\n",
    "        )\n",
    "    else:\n",
    "        wandb_config = None\n",
    "\n",
    "    return run.Config(\n",
    "        nl.NeMoLogger,\n",
    "        name=LOG_NAME,\n",
    "        log_dir=LOG_DIR,\n",
    "        use_datetime_version=False,\n",
    "        ckpt=ckpt,\n",
    "        wandb=wandb_config,\n",
    "    )\n",
    "\n",
    "\n",
    "logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Configure the Optimizer\n",
    "In the following example, we will be using the distributed adam optimizer and pass in the optimizer configuration through `OptimizerConfig`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"257pt\" height=\"215pt\"\n",
       " viewBox=\"0.00 0.00 256.50 215.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-211 252.5,-211 252.5,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"44.5,-113.5 44.5,-132.5 248.5,-132.5 248.5,-113.5 44.5,-113.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-113.5 44.5,-132.5 248.5,-132.5 248.5,-113.5 44.5,-113.5\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-121.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"114\" y=\"-121.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> OptimizerConfig</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,-94.5 44.5,-113.5 203.5,-113.5 203.5,-94.5 44.5,-94.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-94.5 44.5,-113.5 203.5,-113.5 203.5,-94.5 44.5,-94.5\"/>\n",
       "<text text-anchor=\"start\" x=\"144.5\" y=\"-101.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">optimizer</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,-94.5 203.5,-113.5 248.5,-113.5 248.5,-94.5 203.5,-94.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-101.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;adam&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,-75.5 44.5,-94.5 203.5,-94.5 203.5,-75.5 44.5,-75.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-75.5 44.5,-94.5 203.5,-94.5 203.5,-75.5 44.5,-75.5\"/>\n",
       "<text text-anchor=\"start\" x=\"186.5\" y=\"-82.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">lr</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,-75.5 203.5,-94.5 248.5,-94.5 248.5,-75.5 203.5,-75.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-82.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1e&#45;05</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,-56.5 44.5,-75.5 203.5,-75.5 203.5,-56.5 44.5,-56.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-56.5 44.5,-75.5 203.5,-75.5 203.5,-56.5 44.5,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"174.5\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">bf16</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,-56.5 203.5,-75.5 248.5,-75.5 248.5,-56.5 203.5,-56.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-63.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,-37.5 44.5,-56.5 203.5,-56.5 203.5,-37.5 44.5,-37.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-37.5 44.5,-56.5 203.5,-56.5 203.5,-37.5 44.5,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"138.5\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">adam_beta2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,-37.5 203.5,-56.5 248.5,-56.5 248.5,-37.5 203.5,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-44.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">0.98</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,-18.5 44.5,-37.5 203.5,-37.5 203.5,-18.5 44.5,-18.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,-18.5 44.5,-37.5 203.5,-37.5 203.5,-18.5 44.5,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"48.5\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">use_distributed_optimizer</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,-18.5 203.5,-37.5 248.5,-37.5 248.5,-18.5 203.5,-18.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-25.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"44.5,0.5 44.5,-18.5 203.5,-18.5 203.5,0.5 44.5,0.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"44.5,0.5 44.5,-18.5 203.5,-18.5 203.5,0.5 44.5,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"144.5\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">clip_grad</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"203.5,0.5 203.5,-18.5 248.5,-18.5 248.5,0.5 203.5,0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"207.5\" y=\"-6.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1.0</text>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"0.5,-188 0.5,-207 185.5,-207 185.5,-188 0.5,-188\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-188 0.5,-207 185.5,-207 185.5,-188 0.5,-188\"/>\n",
       "<text text-anchor=\"start\" x=\"4.5\" y=\"-196\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"36.5\" y=\"-196\" font-family=\"Courier,monospace\" font-size=\"10.00\"> MegatronOptimizerModule</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-169 0.5,-188 107.5,-188 107.5,-169 0.5,-169\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-169 0.5,-188 107.5,-188 107.5,-169 0.5,-169\"/>\n",
       "<text text-anchor=\"start\" x=\"66.5\" y=\"-176\" font-family=\"Courier,monospace\" font-size=\"10.00\">config</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"107.5,-169 107.5,-188 185.5,-188 185.5,-169 107.5,-169\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"111.5,-173 111.5,-184 181.5,-184 181.5,-173 111.5,-173\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"111.5,-173 111.5,-184 181.5,-184 181.5,-173 111.5,-173\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;1:c</title>\n",
       "<path fill=\"none\" stroke=\"#73be73\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M146.5,-172.84C146.5,-165.69 146.5,-150.2 146.5,-133.23\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Config[MegatronOptimizerModule(\n",
       "  config=<Config[OptimizerConfig(\n",
       "    optimizer='adam',\n",
       "    lr=1e-05,\n",
       "    bf16=True,\n",
       "    adam_beta2=0.98,\n",
       "    use_distributed_optimizer=True,\n",
       "    clip_grad=1.0)]>)]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adam_with_cosine_annealing() -> run.Config[nl.OptimizerModule]:\n",
    "    opt_cfg = run.Config(\n",
    "        OptimizerConfig,\n",
    "        optimizer=\"adam\",\n",
    "        lr=1e-5,\n",
    "        adam_beta2=0.98,\n",
    "        use_distributed_optimizer=True,\n",
    "        clip_grad=1.0,\n",
    "        bf16=True,\n",
    "    )\n",
    "    return run.Config(nl.MegatronOptimizerModule, config=opt_cfg)\n",
    "\n",
    "\n",
    "adam_with_cosine_annealing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Configure the Base Model\n",
    "We will perform SFT on top of Llama 3-8B, so we instantiate a `LlamaModel` configuration to pass to the finetune API. This specifies the structure to load the weights imported previously in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llama31_8b() -> run.Config[pl.LightningModule]:\n",
    "    return run.Config(llm.LlamaModel, config=run.Config(llm.Llama31Config8B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Configure Auto Resume\n",
    "Resume training from the imported checkpoint (`nemo://meta-llama/Llama-3.1-8B`).\n",
    "\n",
    "Set `resume_if_exists=True` to automatically continue from the latest checkpoint (in case of previous finetuning experiments) if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resume() -> run.Config[nl.AutoResume]:\n",
    "    return run.Config(\n",
    "        nl.AutoResume,\n",
    "        restore_config=run.Config(\n",
    "            nl.RestoreConfig, path=\"nemo://meta-llama/Llama-3.1-8B\"\n",
    "        ),\n",
    "        resume_if_exists=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6:  Configure the LoRA adapter\n",
    "\n",
    "In this step, you may choose LoRA configurations like adapter dimension, LoRA alpha, as well as target modules. By default, it applies an adapter to all the linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.llm.peft.lora import LoRA\n",
    "\n",
    "def lora() -> run.Config[nl.pytorch.callbacks.PEFT]:\n",
    "    return run.Config(LoRA,\n",
    "                      dim=8,\n",
    "                      alpha=32,\n",
    "                      dropout=0.1,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.7: Configure NeMo 2.0 finetune API\n",
    "Using all the components we created above, the following code configures the NeMo 2.0 finetune API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1582pt\" height=\"629pt\"\n",
       " viewBox=\"0.00 0.00 1581.50 629.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-625 1577.5,-625 1577.5,4 -4,4\"/>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#fff8dc\" stroke=\"transparent\" points=\"20.5,-140.5 20.5,-159.5 157.5,-159.5 157.5,-140.5 20.5,-140.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20.5,-140.5 20.5,-159.5 157.5,-159.5 157.5,-140.5 20.5,-140.5\"/>\n",
       "<text text-anchor=\"start\" x=\"24.5\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"56.5\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> Llama31Config8B</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"20.5,-121.5 20.5,-140.5 157.5,-140.5 157.5,-121.5 20.5,-121.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"20.5,-121.5 20.5,-140.5 157.5,-140.5 157.5,-121.5 20.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"52.5\" y=\"-129.5\" font-family=\"Courier,monospace\" font-style=\"italic\" font-size=\"10.00\">no arguments</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"0.5,-338 0.5,-357 107.5,-357 107.5,-338 0.5,-338\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-338 0.5,-357 107.5,-357 107.5,-338 0.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"4.5\" y=\"-346\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"36.5\" y=\"-346\" font-family=\"Courier,monospace\" font-size=\"10.00\"> LlamaModel</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"0.5,-319 0.5,-338 68.5,-338 68.5,-319 0.5,-319\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0.5,-319 0.5,-338 68.5,-338 68.5,-319 0.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"27.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">config</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"68.5,-319 68.5,-338 107.5,-338 107.5,-319 68.5,-319\"/>\n",
       "<polygon fill=\"#fff8dc\" stroke=\"transparent\" points=\"72.5,-323 72.5,-334 103.5,-334 103.5,-323 72.5,-323\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"72.5,-323 72.5,-334 103.5,-334 103.5,-323 72.5,-323\"/>\n",
       "</g>\n",
       "<!-- 1&#45;&#45;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1:c&#45;&#45;2:c</title>\n",
       "<path fill=\"none\" stroke=\"#cbc6b0\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M88.5,-322.78C88.5,-301.04 88.5,-201.21 88.5,-159.69\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"597.5,-602 597.5,-621 697.5,-621 697.5,-602 597.5,-602\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"597.5,-602 597.5,-621 697.5,-621 697.5,-602 597.5,-602\"/>\n",
       "<text text-anchor=\"start\" x=\"601.5\" y=\"-610\" font-family=\"Courier,monospace\" font-size=\"8.00\">Partial:</text>\n",
       "<text text-anchor=\"start\" x=\"638.5\" y=\"-610\" font-family=\"Courier,monospace\" font-size=\"10.00\"> finetune</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" stroke-dasharray=\"5,2\" points=\"597.5,-583 597.5,-602 664.5,-602 664.5,-583 597.5,-583\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-583 597.5,-602 664.5,-602 664.5,-583 597.5,-583\"/>\n",
       "<text text-anchor=\"start\" x=\"629.5\" y=\"-590\" font-family=\"Courier,monospace\" font-size=\"10.00\">model</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-583 664.5,-602 697.5,-602 697.5,-583 664.5,-583\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"668.5,-587 668.5,-598 693.5,-598 693.5,-587 668.5,-587\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-587 668.5,-598 693.5,-598 693.5,-587 668.5,-587\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-564 597.5,-583 664.5,-583 664.5,-564 597.5,-564\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-564 597.5,-583 664.5,-583 664.5,-564 597.5,-564\"/>\n",
       "<text text-anchor=\"start\" x=\"635.5\" y=\"-571\" font-family=\"Courier,monospace\" font-size=\"10.00\">data</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-564 664.5,-583 697.5,-583 697.5,-564 664.5,-564\"/>\n",
       "<polygon fill=\"#ffa07a\" stroke=\"transparent\" points=\"668.5,-568 668.5,-579 693.5,-579 693.5,-568 668.5,-568\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-568 668.5,-579 693.5,-579 693.5,-568 668.5,-568\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-545 597.5,-564 664.5,-564 664.5,-545 597.5,-545\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-545 597.5,-564 664.5,-564 664.5,-545 597.5,-545\"/>\n",
       "<text text-anchor=\"start\" x=\"617.5\" y=\"-552\" font-family=\"Courier,monospace\" font-size=\"10.00\">trainer</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-545 664.5,-564 697.5,-564 697.5,-545 664.5,-545\"/>\n",
       "<polygon fill=\"#add8e6\" stroke=\"transparent\" points=\"668.5,-549 668.5,-560 693.5,-560 693.5,-549 668.5,-549\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-549 668.5,-560 693.5,-560 693.5,-549 668.5,-549\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-526 597.5,-545 664.5,-545 664.5,-526 597.5,-526\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-526 597.5,-545 664.5,-545 664.5,-526 597.5,-526\"/>\n",
       "<text text-anchor=\"start\" x=\"641.5\" y=\"-533\" font-family=\"Courier,monospace\" font-size=\"10.00\">log</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-526 664.5,-545 697.5,-545 697.5,-526 664.5,-526\"/>\n",
       "<polygon fill=\"#ff6347\" stroke=\"transparent\" points=\"668.5,-530 668.5,-541 693.5,-541 693.5,-530 668.5,-530\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-530 668.5,-541 693.5,-541 693.5,-530 668.5,-530\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-507 597.5,-526 664.5,-526 664.5,-507 597.5,-507\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-507 597.5,-526 664.5,-526 664.5,-507 597.5,-507\"/>\n",
       "<text text-anchor=\"start\" x=\"623.5\" y=\"-514\" font-family=\"Courier,monospace\" font-size=\"10.00\">resume</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-507 664.5,-526 697.5,-526 697.5,-507 664.5,-507\"/>\n",
       "<polygon fill=\"#32cd32\" stroke=\"transparent\" points=\"668.5,-511 668.5,-522 693.5,-522 693.5,-511 668.5,-511\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-511 668.5,-522 693.5,-522 693.5,-511 668.5,-511\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-488 597.5,-507 664.5,-507 664.5,-488 597.5,-488\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-488 597.5,-507 664.5,-507 664.5,-488 597.5,-488\"/>\n",
       "<text text-anchor=\"start\" x=\"629.5\" y=\"-495\" font-family=\"Courier,monospace\" font-size=\"10.00\">optim</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-488 664.5,-507 697.5,-507 697.5,-488 664.5,-488\"/>\n",
       "<polygon fill=\"#7b68ee\" stroke=\"transparent\" points=\"668.5,-492 668.5,-503 693.5,-503 693.5,-492 668.5,-492\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-492 668.5,-503 693.5,-503 693.5,-492 668.5,-492\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"597.5,-469 597.5,-488 664.5,-488 664.5,-469 597.5,-469\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"597.5,-469 597.5,-488 664.5,-488 664.5,-469 597.5,-469\"/>\n",
       "<text text-anchor=\"start\" x=\"635.5\" y=\"-476\" font-family=\"Courier,monospace\" font-size=\"10.00\">peft</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-469 664.5,-488 697.5,-488 697.5,-469 664.5,-469\"/>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"668.5,-473 668.5,-484 693.5,-484 693.5,-473 668.5,-473\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"668.5,-473 668.5,-484 693.5,-484 693.5,-473 668.5,-473\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;1:c</title>\n",
       "<path fill=\"none\" stroke=\"#73be73\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M668.12,-591.58C601.6,-588.89 302.19,-569.35 115.5,-433 88.66,-413.4 70.13,-378.38 60.7,-357.06\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#ffa07a\" stroke=\"transparent\" points=\"125.5,-366 125.5,-385 328.5,-385 328.5,-366 125.5,-366\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125.5,-366 125.5,-385 328.5,-385 328.5,-366 125.5,-366\"/>\n",
       "<text text-anchor=\"start\" x=\"129.5\" y=\"-374\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-374\" font-family=\"Courier,monospace\" font-size=\"10.00\"> LawStackExchangeDataModule</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"125.5,-347 125.5,-366 265.5,-366 265.5,-347 125.5,-347\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125.5,-347 125.5,-366 265.5,-366 265.5,-347 125.5,-347\"/>\n",
       "<text text-anchor=\"start\" x=\"200.5\" y=\"-354\" font-family=\"Courier,monospace\" font-size=\"10.00\">seq_length</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"265.5,-347 265.5,-366 328.5,-366 328.5,-347 265.5,-347\"/>\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-354\" font-family=\"Courier,monospace\" font-size=\"10.00\">2048</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"125.5,-328 125.5,-347 265.5,-347 265.5,-328 125.5,-328\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125.5,-328 125.5,-347 265.5,-347 265.5,-328 125.5,-328\"/>\n",
       "<text text-anchor=\"start\" x=\"164.5\" y=\"-335\" font-family=\"Courier,monospace\" font-size=\"10.00\">micro_batch_size</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"265.5,-328 265.5,-347 328.5,-347 328.5,-328 265.5,-328\"/>\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-335\" font-family=\"Courier,monospace\" font-size=\"10.00\">4</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"125.5,-309 125.5,-328 265.5,-328 265.5,-309 125.5,-309\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125.5,-309 125.5,-328 265.5,-328 265.5,-309 125.5,-309\"/>\n",
       "<text text-anchor=\"start\" x=\"158.5\" y=\"-316\" font-family=\"Courier,monospace\" font-size=\"10.00\">global_batch_size</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"265.5,-309 265.5,-328 328.5,-328 328.5,-309 265.5,-309\"/>\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-316\" font-family=\"Courier,monospace\" font-size=\"10.00\">16</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"125.5,-290 125.5,-309 265.5,-309 265.5,-290 125.5,-290\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"125.5,-290 125.5,-309 265.5,-309 265.5,-290 125.5,-290\"/>\n",
       "<text text-anchor=\"start\" x=\"194.5\" y=\"-297\" font-family=\"Courier,monospace\" font-size=\"10.00\">num_workers</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"265.5,-290 265.5,-309 328.5,-309 328.5,-290 265.5,-290\"/>\n",
       "<text text-anchor=\"start\" x=\"269.5\" y=\"-297\" font-family=\"Courier,monospace\" font-size=\"10.00\">0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;3:c</title>\n",
       "<path fill=\"none\" stroke=\"#cb8061\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M668.26,-569.32C620.91,-555.8 456.35,-505.87 336.5,-433 314.61,-419.69 292.7,-402.06 274.26,-385.67\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"transparent\" points=\"345.5,-414 345.5,-433 513.5,-433 513.5,-414 345.5,-414\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-414 345.5,-433 513.5,-433 513.5,-414 345.5,-414\"/>\n",
       "<text text-anchor=\"start\" x=\"389\" y=\"-422\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"421\" y=\"-422\" font-family=\"Courier,monospace\" font-size=\"10.00\"> Trainer</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-395 345.5,-414 474.5,-414 474.5,-395 345.5,-395\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-395 345.5,-414 474.5,-414 474.5,-395 345.5,-395\"/>\n",
       "<text text-anchor=\"start\" x=\"403.5\" y=\"-402\" font-family=\"Courier,monospace\" font-size=\"10.00\">accelerator</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-395 474.5,-414 513.5,-414 513.5,-395 474.5,-395\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-402\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;gpu&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-376 345.5,-395 474.5,-395 474.5,-376 345.5,-376\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-376 345.5,-395 474.5,-395 474.5,-376 345.5,-376\"/>\n",
       "<text text-anchor=\"start\" x=\"421.5\" y=\"-383\" font-family=\"Courier,monospace\" font-size=\"10.00\">strategy</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-376 474.5,-395 513.5,-395 513.5,-376 474.5,-376\"/>\n",
       "<polygon fill=\"#ff8c00\" stroke=\"transparent\" points=\"478.5,-380 478.5,-391 509.5,-391 509.5,-380 478.5,-380\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"478.5,-380 478.5,-391 509.5,-391 509.5,-380 478.5,-380\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-357 345.5,-376 474.5,-376 474.5,-357 345.5,-357\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-357 345.5,-376 474.5,-376 474.5,-357 345.5,-357\"/>\n",
       "<text text-anchor=\"start\" x=\"427.5\" y=\"-364\" font-family=\"Courier,monospace\" font-size=\"10.00\">devices</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-357 474.5,-376 513.5,-376 513.5,-357 474.5,-357\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-364\" font-family=\"Courier,monospace\" font-size=\"10.00\">4</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-338 345.5,-357 474.5,-357 474.5,-338 345.5,-338\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-338 345.5,-357 474.5,-357 474.5,-338 345.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"415.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">max_steps</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-338 474.5,-357 513.5,-357 513.5,-338 474.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">1000</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-319 345.5,-338 474.5,-338 474.5,-319 345.5,-319\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-319 345.5,-338 474.5,-338 474.5,-319 345.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"367.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">limit_val_batches</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-319 474.5,-338 513.5,-338 513.5,-319 474.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">2</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-300 345.5,-319 474.5,-319 474.5,-300 345.5,-300\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-300 345.5,-319 474.5,-319 474.5,-300 345.5,-300\"/>\n",
       "<text text-anchor=\"start\" x=\"361.5\" y=\"-307\" font-family=\"Courier,monospace\" font-size=\"10.00\">val_check_interval</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-300 474.5,-319 513.5,-319 513.5,-300 474.5,-300\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-307\" font-family=\"Courier,monospace\" font-size=\"10.00\">10</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-281 345.5,-300 474.5,-300 474.5,-281 345.5,-281\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-281 345.5,-300 474.5,-300 474.5,-281 345.5,-281\"/>\n",
       "<text text-anchor=\"start\" x=\"349.5\" y=\"-288\" font-family=\"Courier,monospace\" font-size=\"10.00\">num_sanity_val_steps</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-281 474.5,-300 513.5,-300 513.5,-281 474.5,-281\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-288\" font-family=\"Courier,monospace\" font-size=\"10.00\">0</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-262 345.5,-281 474.5,-281 474.5,-262 345.5,-262\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-262 345.5,-281 474.5,-281 474.5,-262 345.5,-262\"/>\n",
       "<text text-anchor=\"start\" x=\"367.5\" y=\"-269\" font-family=\"Courier,monospace\" font-size=\"10.00\">log_every_n_steps</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-262 474.5,-281 513.5,-281 513.5,-262 474.5,-262\"/>\n",
       "<text text-anchor=\"start\" x=\"478.5\" y=\"-269\" font-family=\"Courier,monospace\" font-size=\"10.00\">1</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"345.5,-243 345.5,-262 474.5,-262 474.5,-243 345.5,-243\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"345.5,-243 345.5,-262 474.5,-262 474.5,-243 345.5,-243\"/>\n",
       "<text text-anchor=\"start\" x=\"427.5\" y=\"-250\" font-family=\"Courier,monospace\" font-size=\"10.00\">plugins</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"474.5,-243 474.5,-262 513.5,-262 513.5,-243 474.5,-243\"/>\n",
       "<polygon fill=\"#8fbc8f\" stroke=\"transparent\" points=\"478.5,-247 478.5,-258 509.5,-258 509.5,-247 478.5,-247\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"478.5,-247 478.5,-258 509.5,-258 509.5,-247 478.5,-247\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;4 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;4:c</title>\n",
       "<path fill=\"none\" stroke=\"#8aacb7\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M673.92,-548.81C650.54,-532.66 577.76,-481.53 522.5,-433 519.57,-430.42 516.61,-427.78 513.66,-425.08\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"#ff6347\" stroke=\"transparent\" points=\"531.5,-376 531.5,-395 831.5,-395 831.5,-376 531.5,-376\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-376 531.5,-395 831.5,-395 831.5,-376 531.5,-376\"/>\n",
       "<text text-anchor=\"start\" x=\"632\" y=\"-384\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"664\" y=\"-384\" font-family=\"Courier,monospace\" font-size=\"10.00\"> NeMoLogger</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"531.5,-357 531.5,-376 660.5,-376 660.5,-357 531.5,-357\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-357 531.5,-376 660.5,-376 660.5,-357 531.5,-357\"/>\n",
       "<text text-anchor=\"start\" x=\"631.5\" y=\"-364\" font-family=\"Courier,monospace\" font-size=\"10.00\">name</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"660.5,-357 660.5,-376 831.5,-376 831.5,-357 660.5,-357\"/>\n",
       "<text text-anchor=\"start\" x=\"664.5\" y=\"-364\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;nemo2_llama31_8b_lse_peft&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"531.5,-338 531.5,-357 660.5,-357 660.5,-338 531.5,-338\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-338 531.5,-357 660.5,-357 660.5,-338 531.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"613.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">log_dir</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"660.5,-338 660.5,-357 831.5,-357 831.5,-338 660.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"664.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;/nemo&#45;experiments/results&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"531.5,-319 531.5,-338 660.5,-338 660.5,-319 531.5,-319\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-319 531.5,-338 660.5,-338 660.5,-319 531.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"535.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">use_datetime_version</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"660.5,-319 660.5,-338 831.5,-338 831.5,-319 660.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"664.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">False</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"531.5,-300 531.5,-319 660.5,-319 660.5,-300 531.5,-300\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-300 531.5,-319 660.5,-319 660.5,-300 531.5,-300\"/>\n",
       "<text text-anchor=\"start\" x=\"631.5\" y=\"-307\" font-family=\"Courier,monospace\" font-size=\"10.00\">ckpt</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"660.5,-300 660.5,-319 831.5,-319 831.5,-300 660.5,-300\"/>\n",
       "<polygon fill=\"#db7093\" stroke=\"transparent\" points=\"664.5,-304 664.5,-315 827.5,-315 827.5,-304 664.5,-304\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-304 664.5,-315 827.5,-315 827.5,-304 664.5,-304\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"531.5,-281 531.5,-300 660.5,-300 660.5,-281 531.5,-281\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"531.5,-281 531.5,-300 660.5,-300 660.5,-281 531.5,-281\"/>\n",
       "<text text-anchor=\"start\" x=\"625.5\" y=\"-288\" font-family=\"Courier,monospace\" font-size=\"10.00\">wandb</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"660.5,-281 660.5,-300 831.5,-300 831.5,-281 660.5,-281\"/>\n",
       "<polygon fill=\"#f0e68c\" stroke=\"transparent\" points=\"664.5,-285 664.5,-296 827.5,-296 827.5,-285 664.5,-285\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"664.5,-285 664.5,-296 827.5,-296 827.5,-285 664.5,-285\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;8 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;8:c</title>\n",
       "<path fill=\"none\" stroke=\"#cb4f38\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M681.5,-529.93C681.5,-512.81 681.5,-445.27 681.5,-395.35\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"#32cd32\" stroke=\"transparent\" points=\"849.5,-347 849.5,-366 993.5,-366 993.5,-347 849.5,-347\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"849.5,-347 849.5,-366 993.5,-366 993.5,-347 849.5,-347\"/>\n",
       "<text text-anchor=\"start\" x=\"872\" y=\"-355\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"904\" y=\"-355\" font-family=\"Courier,monospace\" font-size=\"10.00\"> AutoResume</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"849.5,-328 849.5,-347 954.5,-347 954.5,-328 849.5,-328\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"849.5,-328 849.5,-347 954.5,-347 954.5,-328 849.5,-328\"/>\n",
       "<text text-anchor=\"start\" x=\"865.5\" y=\"-335\" font-family=\"Courier,monospace\" font-size=\"10.00\">restore_config</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"954.5,-328 954.5,-347 993.5,-347 993.5,-328 954.5,-328\"/>\n",
       "<polygon fill=\"#00bfff\" stroke=\"transparent\" points=\"958.5,-332 958.5,-343 989.5,-343 989.5,-332 958.5,-332\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"958.5,-332 958.5,-343 989.5,-343 989.5,-332 958.5,-332\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"849.5,-309 849.5,-328 954.5,-328 954.5,-309 849.5,-309\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"849.5,-309 849.5,-328 954.5,-328 954.5,-309 849.5,-309\"/>\n",
       "<text text-anchor=\"start\" x=\"853.5\" y=\"-316\" font-family=\"Courier,monospace\" font-size=\"10.00\">resume_if_exists</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"954.5,-309 954.5,-328 993.5,-328 993.5,-309 954.5,-309\"/>\n",
       "<text text-anchor=\"start\" x=\"958.5\" y=\"-316\" font-family=\"Courier,monospace\" font-size=\"10.00\">False</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;11 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;11:c</title>\n",
       "<path fill=\"none\" stroke=\"#28a328\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M692.76,-510.93C720.02,-500.73 791,-472.05 840.5,-433 864.69,-413.92 887.13,-386.83 902.22,-366.62\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"#7b68ee\" stroke=\"transparent\" points=\"1012.5,-338 1012.5,-357 1197.5,-357 1197.5,-338 1012.5,-338\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1012.5,-338 1012.5,-357 1197.5,-357 1197.5,-338 1012.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"1016.5\" y=\"-346\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"1048.5\" y=\"-346\" font-family=\"Courier,monospace\" font-size=\"10.00\"> MegatronOptimizerModule</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1012.5,-319 1012.5,-338 1119.5,-338 1119.5,-319 1012.5,-319\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1012.5,-319 1012.5,-338 1119.5,-338 1119.5,-319 1012.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"1078.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">config</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1119.5,-319 1119.5,-338 1197.5,-338 1197.5,-319 1119.5,-319\"/>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"1123.5,-323 1123.5,-334 1193.5,-334 1193.5,-323 1123.5,-323\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1123.5,-323 1123.5,-334 1193.5,-334 1193.5,-323 1123.5,-323\"/>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;13 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;13:c</title>\n",
       "<path fill=\"none\" stroke=\"#6253be\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M693.62,-495.94C737.65,-495.28 892.33,-488.85 1002.5,-433 1039.23,-414.38 1072.4,-378.69 1090.38,-357.05\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"#90ee90\" stroke=\"transparent\" points=\"1215.5,-357 1215.5,-376 1293.5,-376 1293.5,-357 1215.5,-357\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1215.5,-357 1215.5,-376 1293.5,-376 1293.5,-357 1215.5,-357\"/>\n",
       "<text text-anchor=\"start\" x=\"1223\" y=\"-365\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"1255\" y=\"-365\" font-family=\"Courier,monospace\" font-size=\"10.00\"> LoRA</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1215.5,-338 1215.5,-357 1266.5,-357 1266.5,-338 1215.5,-338\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1215.5,-338 1215.5,-357 1266.5,-357 1266.5,-338 1215.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"1243.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">dim</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1266.5,-338 1266.5,-357 1293.5,-357 1293.5,-338 1266.5,-338\"/>\n",
       "<text text-anchor=\"start\" x=\"1270.5\" y=\"-345\" font-family=\"Courier,monospace\" font-size=\"10.00\">8</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1215.5,-319 1215.5,-338 1266.5,-338 1266.5,-319 1215.5,-319\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1215.5,-319 1215.5,-338 1266.5,-338 1266.5,-319 1215.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"1231.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">alpha</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1266.5,-319 1266.5,-338 1293.5,-338 1293.5,-319 1266.5,-319\"/>\n",
       "<text text-anchor=\"start\" x=\"1270.5\" y=\"-326\" font-family=\"Courier,monospace\" font-size=\"10.00\">32</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1215.5,-300 1215.5,-319 1266.5,-319 1266.5,-300 1215.5,-300\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1215.5,-300 1215.5,-319 1266.5,-319 1266.5,-300 1215.5,-300\"/>\n",
       "<text text-anchor=\"start\" x=\"1219.5\" y=\"-307\" font-family=\"Courier,monospace\" font-size=\"10.00\">dropout</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1266.5,-300 1266.5,-319 1293.5,-319 1293.5,-300 1266.5,-300\"/>\n",
       "<text text-anchor=\"start\" x=\"1270.5\" y=\"-307\" font-family=\"Courier,monospace\" font-size=\"10.00\">0.1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&#45;15 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>0:c&#45;&#45;15:c</title>\n",
       "<path fill=\"none\" stroke=\"#73be73\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M693.8,-476.68C768.77,-474.63 1162.55,-462.5 1206.5,-433 1225.97,-419.93 1237.97,-396.43 1245.11,-376.2\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"#ff8c00\" stroke=\"transparent\" points=\"181.5,-140.5 181.5,-159.5 361.5,-159.5 361.5,-140.5 181.5,-140.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181.5,-140.5 181.5,-159.5 361.5,-159.5 361.5,-140.5 181.5,-140.5\"/>\n",
       "<text text-anchor=\"start\" x=\"204\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"236\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> MegatronStrategy</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"181.5,-121.5 181.5,-140.5 346.5,-140.5 346.5,-121.5 181.5,-121.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"181.5,-121.5 181.5,-140.5 346.5,-140.5 346.5,-121.5 181.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"185.5\" y=\"-128.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">tensor_model_parallel_size</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"346.5,-121.5 346.5,-140.5 361.5,-140.5 361.5,-121.5 346.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"350.5\" y=\"-128.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1</text>\n",
       "</g>\n",
       "<!-- 4&#45;&#45;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4:c&#45;&#45;5:c</title>\n",
       "<path fill=\"none\" stroke=\"#cb6f00\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M489.84,-379.91C463.7,-351.37 334.71,-210.52 288.23,-159.77\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"#8fbc8f\" stroke=\"transparent\" points=\"379.5,-178.5 379.5,-197.5 583.5,-197.5 583.5,-178.5 379.5,-178.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-178.5 379.5,-197.5 583.5,-197.5 583.5,-178.5 379.5,-178.5\"/>\n",
       "<text text-anchor=\"start\" x=\"396\" y=\"-186.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"428\" y=\"-186.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> MegatronMixedPrecision</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"379.5,-159.5 379.5,-178.5 502.5,-178.5 502.5,-159.5 379.5,-159.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-159.5 379.5,-178.5 502.5,-178.5 502.5,-159.5 379.5,-159.5\"/>\n",
       "<text text-anchor=\"start\" x=\"443.5\" y=\"-166.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">precision</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"502.5,-159.5 502.5,-178.5 583.5,-178.5 583.5,-159.5 502.5,-159.5\"/>\n",
       "<text text-anchor=\"start\" x=\"506.5\" y=\"-166.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;bf16&#45;mixed&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"379.5,-140.5 379.5,-159.5 502.5,-159.5 502.5,-140.5 379.5,-140.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-140.5 379.5,-159.5 502.5,-159.5 502.5,-140.5 379.5,-140.5\"/>\n",
       "<text text-anchor=\"start\" x=\"425.5\" y=\"-147.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">params_dtype</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"502.5,-140.5 502.5,-159.5 583.5,-159.5 583.5,-140.5 502.5,-140.5\"/>\n",
       "<polygon fill=\"#adff2f\" stroke=\"transparent\" points=\"506.5,-144.5 506.5,-155.5 579.5,-155.5 579.5,-144.5 506.5,-144.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"506.5,-144.5 506.5,-155.5 579.5,-155.5 579.5,-144.5 506.5,-144.5\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"379.5,-121.5 379.5,-140.5 502.5,-140.5 502.5,-121.5 379.5,-121.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-121.5 379.5,-140.5 502.5,-140.5 502.5,-121.5 379.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"413.5\" y=\"-128.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">pipeline_dtype</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"502.5,-121.5 502.5,-140.5 583.5,-140.5 583.5,-121.5 502.5,-121.5\"/>\n",
       "<polygon fill=\"#adff2f\" stroke=\"transparent\" points=\"506.5,-125.5 506.5,-136.5 579.5,-136.5 579.5,-125.5 506.5,-125.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"506.5,-125.5 506.5,-136.5 579.5,-136.5 579.5,-125.5 506.5,-125.5\"/>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"379.5,-102.5 379.5,-121.5 502.5,-121.5 502.5,-102.5 379.5,-102.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-102.5 379.5,-121.5 502.5,-121.5 502.5,-102.5 379.5,-102.5\"/>\n",
       "<text text-anchor=\"start\" x=\"401.5\" y=\"-109.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">autocast_enabled</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"502.5,-102.5 502.5,-121.5 583.5,-121.5 583.5,-102.5 502.5,-102.5\"/>\n",
       "<text text-anchor=\"start\" x=\"506.5\" y=\"-109.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">False</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"379.5,-83.5 379.5,-102.5 502.5,-102.5 502.5,-83.5 379.5,-83.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379.5,-83.5 379.5,-102.5 502.5,-102.5 502.5,-83.5 379.5,-83.5\"/>\n",
       "<text text-anchor=\"start\" x=\"383.5\" y=\"-90.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">grad_reduce_in_fp32</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"502.5,-83.5 502.5,-102.5 583.5,-102.5 583.5,-83.5 502.5,-83.5\"/>\n",
       "<text text-anchor=\"start\" x=\"506.5\" y=\"-90.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "</g>\n",
       "<!-- 4&#45;&#45;6 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4:c&#45;&#45;6:c</title>\n",
       "<path fill=\"none\" stroke=\"#729672\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M494.01,-246.84C493,-238.36 490.6,-218.15 488.17,-197.67\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<polygon fill=\"#adff2f\" stroke=\"transparent\" points=\"497.5,-19 497.5,-38 590.5,-38 590.5,-19 497.5,-19\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"497.5,-19 497.5,-38 590.5,-38 590.5,-19 497.5,-19\"/>\n",
       "<text text-anchor=\"start\" x=\"528.5\" y=\"-26\" font-family=\"Courier,monospace\" font-size=\"10.00\">dtype</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"497.5,0 497.5,-19 590.5,-19 590.5,0 497.5,0\"/>\n",
       "<text text-anchor=\"start\" x=\"501.5\" y=\"-7\" font-family=\"Courier,monospace\" font-size=\"10.00\">torch.bfloat16</text>\n",
       "</g>\n",
       "<!-- 6&#45;&#45;7 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6:c&#45;&#45;7:c</title>\n",
       "<path fill=\"none\" stroke=\"#8acb25\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M543.5,-144.26C543.5,-126.57 543.5,-68.42 543.5,-38.36\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&#45;7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6:c&#45;&#45;7:c</title>\n",
       "<path fill=\"none\" stroke=\"#8acb25\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M543.5,-125.34C543.5,-111.2 543.5,-64.4 543.5,-38.19\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"#db7093\" stroke=\"transparent\" points=\"601.5,-187.5 601.5,-206.5 877.5,-206.5 877.5,-187.5 601.5,-187.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-187.5 601.5,-206.5 877.5,-206.5 877.5,-187.5 601.5,-187.5\"/>\n",
       "<text text-anchor=\"start\" x=\"675\" y=\"-195.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"707\" y=\"-195.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> ModelCheckpoint</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-168.5 601.5,-187.5 748.5,-187.5 748.5,-168.5 601.5,-168.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-168.5 601.5,-187.5 748.5,-187.5 748.5,-168.5 601.5,-168.5\"/>\n",
       "<text text-anchor=\"start\" x=\"701.5\" y=\"-175.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">monitor</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-168.5 748.5,-187.5 877.5,-187.5 877.5,-168.5 748.5,-168.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-175.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;reduced_train_loss&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-149.5 601.5,-168.5 748.5,-168.5 748.5,-149.5 601.5,-149.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-149.5 601.5,-168.5 748.5,-168.5 748.5,-149.5 601.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"689.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_last</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-149.5 748.5,-168.5 877.5,-168.5 877.5,-149.5 748.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-130.5 601.5,-149.5 748.5,-149.5 748.5,-130.5 601.5,-130.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-130.5 601.5,-149.5 748.5,-149.5 748.5,-130.5 601.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"683.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_top_k</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-130.5 748.5,-149.5 877.5,-149.5 877.5,-130.5 748.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-111.5 601.5,-130.5 748.5,-130.5 748.5,-111.5 601.5,-111.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-111.5 601.5,-130.5 748.5,-130.5 748.5,-111.5 601.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"629.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">every_n_train_steps</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-111.5 748.5,-130.5 877.5,-130.5 877.5,-111.5 748.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">200</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-92.5 601.5,-111.5 748.5,-111.5 748.5,-92.5 601.5,-92.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-92.5 601.5,-111.5 748.5,-111.5 748.5,-92.5 601.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"605.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_on_train_epoch_end</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-92.5 748.5,-111.5 877.5,-111.5 877.5,-92.5 748.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"601.5,-73.5 601.5,-92.5 748.5,-92.5 748.5,-73.5 601.5,-73.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.5,-73.5 601.5,-92.5 748.5,-92.5 748.5,-73.5 601.5,-73.5\"/>\n",
       "<text text-anchor=\"start\" x=\"605.5\" y=\"-80.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">save_optim_on_train_end</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"748.5,-73.5 748.5,-92.5 877.5,-92.5 877.5,-73.5 748.5,-73.5\"/>\n",
       "<text text-anchor=\"start\" x=\"752.5\" y=\"-80.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "</g>\n",
       "<!-- 8&#45;&#45;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8:c&#45;&#45;9:c</title>\n",
       "<path fill=\"none\" stroke=\"#af5975\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M746.33,-303.88C745.76,-290.41 743.9,-246.27 742.27,-207.41\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"#f0e68c\" stroke=\"transparent\" points=\"895.5,-149.5 895.5,-168.5 1099.5,-168.5 1099.5,-149.5 895.5,-149.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"895.5,-149.5 895.5,-168.5 1099.5,-168.5 1099.5,-149.5 895.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"945\" y=\"-157.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"977\" y=\"-157.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> WandbLogger</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"895.5,-130.5 895.5,-149.5 946.5,-149.5 946.5,-130.5 895.5,-130.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"895.5,-130.5 895.5,-149.5 946.5,-149.5 946.5,-130.5 895.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"917.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">name</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"946.5,-130.5 946.5,-149.5 1099.5,-149.5 1099.5,-130.5 946.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"950.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;LSE_Run_1&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"895.5,-111.5 895.5,-130.5 946.5,-130.5 946.5,-111.5 895.5,-111.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"895.5,-111.5 895.5,-130.5 946.5,-130.5 946.5,-111.5 895.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"899.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">project</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"946.5,-111.5 946.5,-130.5 1099.5,-130.5 1099.5,-111.5 946.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"950.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;NeMo2_LoRA_LSE_Example&#39;</text>\n",
       "</g>\n",
       "<!-- 8&#45;&#45;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>8:c&#45;&#45;10:c</title>\n",
       "<path fill=\"none\" stroke=\"#bfb770\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M753.5,-284.91C773.97,-272.95 835.51,-236.98 886.5,-207 907.62,-194.58 930.98,-180.8 950.8,-169.1\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"#00bfff\" stroke=\"transparent\" points=\"1117.5,-140.5 1117.5,-159.5 1351.5,-159.5 1351.5,-140.5 1117.5,-140.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1117.5,-140.5 1117.5,-159.5 1351.5,-159.5 1351.5,-140.5 1117.5,-140.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1176\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"1208\" y=\"-148.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> RestoreConfig</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1117.5,-121.5 1117.5,-140.5 1150.5,-140.5 1150.5,-121.5 1117.5,-121.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1117.5,-121.5 1117.5,-140.5 1150.5,-140.5 1150.5,-121.5 1117.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1121.5\" y=\"-128.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">path</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1150.5,-121.5 1150.5,-140.5 1351.5,-140.5 1351.5,-121.5 1150.5,-121.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1154.5\" y=\"-128.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;nemo://meta&#45;llama/Llama&#45;3.1&#45;8B&#39;</text>\n",
       "</g>\n",
       "<!-- 11&#45;&#45;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11:c&#45;&#45;12:c</title>\n",
       "<path fill=\"none\" stroke=\"#0098cb\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M974.54,-331.82C974.9,-317.39 978.03,-269.19 1003.5,-243 1037.89,-207.63 1063.15,-226.43 1108.5,-207 1141.59,-192.82 1177.92,-173.51 1203.03,-159.53\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>14</title>\n",
       "<polygon fill=\"#ffc0cb\" stroke=\"transparent\" points=\"1369.5,-187.5 1369.5,-206.5 1573.5,-206.5 1573.5,-187.5 1369.5,-187.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-187.5 1369.5,-206.5 1573.5,-206.5 1573.5,-187.5 1369.5,-187.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1407\" y=\"-195.5\" font-family=\"Courier,monospace\" font-size=\"8.00\">Config:</text>\n",
       "<text text-anchor=\"start\" x=\"1439\" y=\"-195.5\" font-family=\"Courier,monospace\" font-size=\"10.00\"> OptimizerConfig</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-168.5 1369.5,-187.5 1528.5,-187.5 1528.5,-168.5 1369.5,-168.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-168.5 1369.5,-187.5 1528.5,-187.5 1528.5,-168.5 1369.5,-168.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1469.5\" y=\"-175.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">optimizer</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-168.5 1528.5,-187.5 1573.5,-187.5 1573.5,-168.5 1528.5,-168.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-175.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">&#39;adam&#39;</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-149.5 1369.5,-168.5 1528.5,-168.5 1528.5,-149.5 1369.5,-149.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-149.5 1369.5,-168.5 1528.5,-168.5 1528.5,-149.5 1369.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1511.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">lr</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-149.5 1528.5,-168.5 1573.5,-168.5 1573.5,-149.5 1528.5,-149.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-156.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1e&#45;05</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-130.5 1369.5,-149.5 1528.5,-149.5 1528.5,-130.5 1369.5,-130.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-130.5 1369.5,-149.5 1528.5,-149.5 1528.5,-130.5 1369.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1499.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">bf16</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-130.5 1528.5,-149.5 1573.5,-149.5 1573.5,-130.5 1528.5,-130.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-137.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-111.5 1369.5,-130.5 1528.5,-130.5 1528.5,-111.5 1369.5,-111.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-111.5 1369.5,-130.5 1528.5,-130.5 1528.5,-111.5 1369.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1463.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">adam_beta2</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-111.5 1528.5,-130.5 1573.5,-130.5 1573.5,-111.5 1528.5,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-118.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">0.98</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-92.5 1369.5,-111.5 1528.5,-111.5 1528.5,-92.5 1369.5,-92.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-92.5 1369.5,-111.5 1528.5,-111.5 1528.5,-92.5 1369.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1373.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">use_distributed_optimizer</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-92.5 1528.5,-111.5 1573.5,-111.5 1573.5,-92.5 1528.5,-92.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-99.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">True</text>\n",
       "<polygon fill=\"#eeeeee\" stroke=\"transparent\" points=\"1369.5,-73.5 1369.5,-92.5 1528.5,-92.5 1528.5,-73.5 1369.5,-73.5\"/>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1369.5,-73.5 1369.5,-92.5 1528.5,-92.5 1528.5,-73.5 1369.5,-73.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1469.5\" y=\"-80.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">clip_grad</text>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1528.5,-73.5 1528.5,-92.5 1573.5,-92.5 1573.5,-73.5 1528.5,-73.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1532.5\" y=\"-80.5\" font-family=\"Courier,monospace\" font-size=\"10.00\">1.0</text>\n",
       "</g>\n",
       "<!-- 13&#45;&#45;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13:c&#45;&#45;14:c</title>\n",
       "<path fill=\"none\" stroke=\"#cb99a2\" stroke-width=\"3\" stroke-opacity=\"0.501961\" d=\"M1159.63,-322.69C1163.5,-308.75 1177.68,-264.48 1206.5,-243 1262.85,-200.99 1295.26,-233.16 1360.5,-207 1363.41,-205.83 1366.33,-204.6 1369.25,-203.31\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Partial[finetune(\n",
       "  model=<Config[LlamaModel(config=<Config[Llama31Config8B()]>)]>,\n",
       "  data=<Config[LawStackExchangeDataModule(\n",
       "    seq_length=2048,\n",
       "    micro_batch_size=4,\n",
       "    global_batch_size=16,\n",
       "    num_workers=0)]>,\n",
       "  trainer=<Config[Trainer(\n",
       "    accelerator='gpu',\n",
       "    strategy=<Config[MegatronStrategy(tensor_model_parallel_size=1)]>,\n",
       "    devices=4,\n",
       "    max_steps=1000,\n",
       "    limit_val_batches=2,\n",
       "    val_check_interval=10,\n",
       "    num_sanity_val_steps=0,\n",
       "    log_every_n_steps=1,\n",
       "    plugins=<Config[MegatronMixedPrecision(\n",
       "      precision='bf16-mixed',\n",
       "      params_dtype=torch.bfloat16,\n",
       "      pipeline_dtype=torch.bfloat16,\n",
       "      autocast_enabled=False,\n",
       "      grad_reduce_in_fp32=True)]>)]>,\n",
       "  log=<Config[NeMoLogger(\n",
       "    name='nemo2_llama31_8b_lse_peft',\n",
       "    log_dir='/nemo-experiments/results',\n",
       "    use_datetime_version=False,\n",
       "    ckpt=<Config[ModelCheckpoint(\n",
       "      monitor='reduced_train_loss',\n",
       "      save_last=True,\n",
       "      save_top_k=1,\n",
       "      every_n_train_steps=200,\n",
       "      save_on_train_epoch_end=True,\n",
       "      save_optim_on_train_end=True)]>,\n",
       "    wandb=<Config[WandbLogger(name='LSE_Run_1', project='NeMo2_LoRA_LSE_Example')]>)]>,\n",
       "  resume=<Config[AutoResume(\n",
       "    restore_config=<Config[RestoreConfig(path='nemo://meta-llama/Llama-3.1-8B')]>,\n",
       "    resume_if_exists=False)]>,\n",
       "  optim=<Config[MegatronOptimizerModule(\n",
       "    config=<Config[OptimizerConfig(\n",
       "      optimizer='adam',\n",
       "      lr=1e-05,\n",
       "      bf16=True,\n",
       "      adam_beta2=0.98,\n",
       "      use_distributed_optimizer=True,\n",
       "      clip_grad=1.0)]>)]>,\n",
       "  peft=<Config[LoRA(dim=8, alpha=32, dropout=0.1)]>)]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def configure_finetuning_recipe():\n",
    "    return run.Partial(\n",
    "        llm.finetune,\n",
    "        model=llama31_8b(),\n",
    "        trainer=trainer(),\n",
    "        data=lse_data(),\n",
    "        log=logger(),\n",
    "        optim=adam_with_cosine_annealing(),\n",
    "        peft=lora(),\n",
    "        resume=resume(),\n",
    "    )\n",
    "\n",
    "\n",
    "configure_finetuning_recipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8: Execute LoRA tuning with NeMo-Run\n",
    "\n",
    "We use `LocalExecutor` for executing our configured finetune function. \n",
    "\n",
    "> **NOTE:** You may just as easily run the workflow remotely on a SLURM cluster, or a cloud environment, from the comfort of this Jupyter notebook. That is really the benefit of using NeMo-Run for scalable experimentation. For more details on the NeMo-Run executor, refer to [Execute NeMo Run](https://github.com/NVIDIA/NeMo-Run/blob/main/docs/source/guides/execution.md) of NeMo-Run Guides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.finetune with id: nemo.collections.llm.api.finetune_1754360413</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─── \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.finetune with id: nemo.collections.llm.api.finetune_1754360413\u001b[0m\u001b[92m ───\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1754360413/nemo.collections.llm.api.finetune\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02:20:13] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.finetune for experiment </span>                        <a href=\"file:///opt/Run/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/Run/nemo_run/run/experiment.py#771\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">771</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.finetune</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02:20:13]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.finetune for experiment \u001b[0m                        \u001b]8;id=369630;file:///opt/Run/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955647;file:///opt/Run/nemo_run/run/experiment.py#771\u001b\\\u001b[2m771\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.finetune\u001b[0m                                                      \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1754360413/nemo.collections.llm.api.finetune\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.finetune-lml31tqlql04pc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.finetune_1754360413 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.finetune_1754360413 to finish\u001b[0m\u001b[92m ──────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.finetune_1754360413</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.finetune_1754360413\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.finetune</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.finetune-lml31tqlql04pc\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1754360413/nemo.collections.llm.api.finetune\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.finetune\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.finetune-lml31tqlql04pc\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1754360413/nemo.collections.llm.api.finetune\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.finetune-lml31tqlql04pc to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.finetune/0 I0805 02:20:15.692000 8757 torch/distributed/run.py:649] Using nproc_per_node=4.\n",
      "i.finetune/0 W0805 02:20:15.692000 8757 torch/distributed/run.py:766] \n",
      "i.finetune/0 W0805 02:20:15.692000 8757 torch/distributed/run.py:766] *****************************************\n",
      "i.finetune/0 W0805 02:20:15.692000 8757 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "i.finetune/0 W0805 02:20:15.692000 8757 torch/distributed/run.py:766] *****************************************\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195] Starting elastic_operator with launch configs:\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   min_nodes        : 1\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   max_nodes        : 1\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   nproc_per_node   : 4\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   run_id           : 609\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   rdzv_backend     : c10d\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   rdzv_endpoint    : localhost:0\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   rdzv_configs     : {'timeout': 900}\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   max_restarts     : 0\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   monitor_interval : 0.1\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   log_dir          : /root/.nemo_run/experiments/nemo.collections.llm.api.finetune/nemo.collections.llm.api.finetune_1754360413/nemo.collections.llm.api.finetune/nemo_run/nemo.collections.llm.api.finetune-lml31tqlql04pc/torchelastic/nemo.collections.llm.api.finetune\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195]   metrics_cfg      : {}\n",
      "i.finetune/0 I0805 02:20:15.693000 8757 torch/distributed/launcher/api.py:195] \n",
      "i.finetune/0 I0805 02:20:15.699000 8757 torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python\n",
      "i.finetune/0 I0805 02:20:15.700000 8757 torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   master_addr=phobos\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   master_port=43647\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3]\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3]\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3]\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[4, 4, 4, 4]\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[4, 4, 4, 4]\n",
      "i.finetune/0 I0805 02:20:15.814000 8757 torch/distributed/elastic/agent/server/api.py:525] \n",
      "i.finetune/0 I0805 02:20:15.815000 8757 torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group\n",
      "i.finetune/0 I0805 02:20:15.816000 8757 torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True\n",
      "i.finetune/0 I0805 02:20:15.817000 8757 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "i.finetune/0 I0805 02:20:15.817000 8757 torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:27 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "i.finetune/0 [default0]:      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:28 nemo_logging:393] Disabling try_restore_best_ckpt restoration for adapters\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:28 nemo_logging:393] Experiments will be logged at /nemo-experiments/results/nemo2_llama31_8b_lse_peft\n",
      "i.finetune/0 [default0]:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "i.finetune/0 [default0]:GPU available: True (cuda), used: True\n",
      "i.finetune/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "i.finetune/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:28 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /nemo-experiments/results\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:28 nemo_logging:405] \"update_logger_directory\" is True. Overwriting wandb logger \"save_dir\" to /nemo-experiments/results\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:28 nemo_logging:405] The Trainer already contains a ModelCheckpoint callback. This will be overwritten.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has data parallel group : [0, 1, 2, 3]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3]]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:29 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "i.finetune/0 [default0]:[W805 02:20:29.770030809 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.finetune/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.finetune/0 [default0]:distributed_backend=nccl\n",
      "i.finetune/0 [default0]:All distributed processes registered. Starting with 4 processes\n",
      "i.finetune/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.finetune/0 [default0]:\n",
      "i.finetune/0 [default2]:[W805 02:20:29.932705012 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.finetune/0 [default1]:[W805 02:20:29.287764618 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.finetune/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default3]:[W805 02:20:30.764399932 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.finetune/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.finetune/0 [default0]:wandb: Currently logged in as: shashank-verma (IT-On-Prem-AI) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "i.finetune/0 [default0]:wandb: Tracking run with wandb version 0.21.0\n",
      "i.finetune/0 [default0]:wandb: Run data is saved locally in /nemo-experiments/results/wandb/run-20250805_022032-ho2i26w9\n",
      "i.finetune/0 [default0]:wandb: Run `wandb offline` to turn off syncing.\n",
      "i.finetune/0 [default0]:wandb: Syncing run LSE_Run_1\n",
      "i.finetune/0 [default0]:wandb: ⭐️ View project at https://wandb.ai/IT-On-Prem-AI/NeMo2_LoRA_LSE_Example\n",
      "i.finetune/0 [default0]:wandb: 🚀 View run at https://wandb.ai/IT-On-Prem-AI/NeMo2_LoRA_LSE_Example/runs/ho2i26w9\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:33 nemo_logging:393] Setting up ModelTransform for stage: TrainerFn.FITTING\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:33 nemo_logging:393] Found model_transform attribute on pl_module\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:33 nemo_logging:393] Set model_transform to: <function _call_counter.<locals>.wrapper at 0x701db4097380>\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:34 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:34 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:34 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:34 nemo_logging:393] Doing selective restore from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:34 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x701daefab710> dist-ckpt load strategy.\n",
      "i.finetune/0 [default2]:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "i.finetune/0 [default1]:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "i.finetune/0 [default0]:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:34 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "i.finetune/0 [default3]:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:39 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1754360434.228s : Time spent in load_checkpoint: 5.318s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:39 nemo_logging:393] Restoring model weights from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:39 nemo_logging:393] Finished restoring from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:  | Name   | Type     | Params | Mode  | FLOPs\n",
      "i.finetune/0 [default0]:----------------------------------------------------\n",
      "i.finetune/0 [default0]:0 | module | GPTModel | 8.0 B  | train | 0    \n",
      "i.finetune/0 [default0]:----------------------------------------------------\n",
      "i.finetune/0 [default0]:8.0 B     Trainable params\n",
      "i.finetune/0 [default0]:0         Non-trainable params\n",
      "i.finetune/0 [default0]:8.0 B     Total params\n",
      "i.finetune/0 [default0]:32,121.045Total estimated model params size (MB)\n",
      "i.finetune/0 [default0]:649       Modules in train mode\n",
      "i.finetune/0 [default0]:0         Modules in eval mode\n",
      "i.finetune/0 [default0]:0         Total Flops\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:39 nemo_logging:405] /opt/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:40 nemo_logging:405] /opt/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=55` in the `DataLoader` to improve performance.\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_proj\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_qkv\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] After applying model_transform:\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:  | Name   | Type     | Params | Mode  | FLOPs\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:----------------------------------------------------\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:0 | module | GPTModel | 8.0 B  | train | 0    \n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:----------------------------------------------------\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:17.8 M    Trainable params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:8.0 B     Non-trainable params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:8.0 B     Total params\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:32,192.348Total estimated model params size (MB)\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:1417      Modules in train mode\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:0         Modules in eval mode\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:0         Total Flops\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Initializing model parallel\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8048087040\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393]  > number of trainable parameters: 17825792 (0.22% of total)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 utils:661] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=True, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, reuse_grad_buf_for_mxfp8_param_ag=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False, nccl_ub=False, fsdp_double_buffer=False)\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 utils:682] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "i.finetune/0 [default0]:    Params for bucket 1 (17825792 elements, 17825792 padded size):\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.5.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.3.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.22.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.8.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.28.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.15.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.12.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.31.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.26.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.20.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.10.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.24.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.21.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.18.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.7.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.4.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.1.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.0.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.23.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.30.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.29.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.25.self_attention.linear_qkv.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.19.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.16.self_attention.linear_proj.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.13.mlp.linear_fc2.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.9.self_attention.linear_qkv.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.2.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.27.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.17.mlp.linear_fc1.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.14.mlp.linear_fc1.adapter.linear_in.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.11.self_attention.linear_proj.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:    \tmodule.decoder.layers.6.mlp.linear_fc2.adapter.linear_out.weight\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 nemo_logging:393] Setting up optimizers\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:20:40 utils:661] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=1e-05, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp8_recipe='delayed', fp16=False, bf16=True, reuse_grad_buf_for_mxfp8_param_ag=False, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.98, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:48 rerun_state_machine:1263] Implicit initialization of Rerun State Machine!\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:48 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 0/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 0 | reduced_train_loss: 1.784\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 1/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 1 | reduced_train_loss: 1.942 | consumed_samples: 32\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 2/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 2 | reduced_train_loss: 1.875 | consumed_samples: 48\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 3/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 3 | reduced_train_loss: 1.841 | consumed_samples: 64\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 4/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 4 | reduced_train_loss: 1.929 | consumed_samples: 80\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 5/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 5 | reduced_train_loss: 1.863 | consumed_samples: 96\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 6/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 6 | reduced_train_loss: 2.175 | consumed_samples: 112\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 7/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 7 | reduced_train_loss: 1.801 | consumed_samples: 128\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 8/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 8 | reduced_train_loss: 1.452 | consumed_samples: 144\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 9/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 9 | reduced_train_loss: 1.733 | consumed_samples: 160\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:59 nemo_logging:405] /opt/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:[NeMo W 2025-08-05 02:20:59 nemo_logging:405] /opt/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "i.finetune/0 [default0]:    \n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 10/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 10 | reduced_train_loss: 1.884 | consumed_samples: 176 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 11/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 11 | reduced_train_loss: 1.489 | consumed_samples: 192 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 12/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 12 | reduced_train_loss: 1.731 | consumed_samples: 208 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 13/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 13 | reduced_train_loss: 1.629 | consumed_samples: 224 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 14/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 14 | reduced_train_loss: 1.99 | consumed_samples: 240 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 15/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 15 | reduced_train_loss: 1.664 | consumed_samples: 256 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 16/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 16 | reduced_train_loss: 1.598 | consumed_samples: 272 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 17/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 17 | reduced_train_loss: 1.994 | consumed_samples: 288 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 18/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 18 | reduced_train_loss: 1.491 | consumed_samples: 304 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 19/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 19 | reduced_train_loss: 1.352 | consumed_samples: 320 | val_loss: 1.81\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 20/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 20 | reduced_train_loss: 1.53 | consumed_samples: 336 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 21/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 21 | reduced_train_loss: 1.746 | consumed_samples: 352 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 22/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 22 | reduced_train_loss: 1.727 | consumed_samples: 368 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 23/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 23 | reduced_train_loss: 1.449 | consumed_samples: 384 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 24/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 24 | reduced_train_loss: 1.52 | consumed_samples: 400 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 25/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 25 | reduced_train_loss: 1.545 | consumed_samples: 416 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 26/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 26 | reduced_train_loss: 1.502 | consumed_samples: 432 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 27/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 27 | reduced_train_loss: 1.698 | consumed_samples: 448 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 28/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 28 | reduced_train_loss: 1.703 | consumed_samples: 464 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 29/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 29 | reduced_train_loss: 1.742 | consumed_samples: 480 | val_loss: 1.642\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 30/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 30 | reduced_train_loss: 1.716 | consumed_samples: 496 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 31/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 31 | reduced_train_loss: 1.464 | consumed_samples: 512 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 32/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 32 | reduced_train_loss: 1.676 | consumed_samples: 528 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 33/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 33 | reduced_train_loss: 1.429 | consumed_samples: 544 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 34/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 34 | reduced_train_loss: 1.27 | consumed_samples: 560 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 35/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 35 | reduced_train_loss: 1.56 | consumed_samples: 576 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 36/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 36 | reduced_train_loss: 1.374 | consumed_samples: 592 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 37/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 37 | reduced_train_loss: 1.494 | consumed_samples: 608 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 38/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 38 | reduced_train_loss: 1.503 | consumed_samples: 624 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 39/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 39 | reduced_train_loss: 1.724 | consumed_samples: 640 | val_loss: 1.602\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 40/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 40 | reduced_train_loss: 1.506 | consumed_samples: 656 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 41/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 41 | reduced_train_loss: 1.418 | consumed_samples: 672 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 42/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 42 | reduced_train_loss: 1.557 | consumed_samples: 688 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 43/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 43 | reduced_train_loss: 1.617 | consumed_samples: 704 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 44/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 44 | reduced_train_loss: 1.9 | consumed_samples: 720 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 45/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 45 | reduced_train_loss: 1.667 | consumed_samples: 736 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 46/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 46 | reduced_train_loss: 1.687 | consumed_samples: 752 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 47/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 47 | reduced_train_loss: 1.714 | consumed_samples: 768 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 48/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 48 | reduced_train_loss: 1.894 | consumed_samples: 784 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 49/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 49 | reduced_train_loss: 1.579 | consumed_samples: 800 | val_loss: 1.582\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 50/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 50 | reduced_train_loss: 1.393 | consumed_samples: 816 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 51/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 51 | reduced_train_loss: 1.397 | consumed_samples: 832 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 52/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 52 | reduced_train_loss: 1.529 | consumed_samples: 848 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 53/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 53 | reduced_train_loss: 1.706 | consumed_samples: 864 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 54/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 54 | reduced_train_loss: 1.746 | consumed_samples: 880 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 55/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 55 | reduced_train_loss: 1.603 | consumed_samples: 896 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 56/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 56 | reduced_train_loss: 1.547 | consumed_samples: 912 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 57/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 57 | reduced_train_loss: 1.448 | consumed_samples: 928 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 58/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 58 | reduced_train_loss: 1.393 | consumed_samples: 944 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 59/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 59 | reduced_train_loss: 1.35 | consumed_samples: 960 | val_loss: 1.571\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 60/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 60 | reduced_train_loss: 1.62 | consumed_samples: 976 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 61/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 61 | reduced_train_loss: 1.613 | consumed_samples: 992 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 62/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 62 | reduced_train_loss: 1.643 | consumed_samples: 1008 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 63/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 63 | reduced_train_loss: 1.012 | consumed_samples: 1024 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 64/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 64 | reduced_train_loss: 1.481 | consumed_samples: 1040 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 65/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 65 | reduced_train_loss: 1.41 | consumed_samples: 1056 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 66/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 66 | reduced_train_loss: 1.378 | consumed_samples: 1072 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 67/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 67 | reduced_train_loss: 1.217 | consumed_samples: 1088 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 68/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 68 | reduced_train_loss: 1.619 | consumed_samples: 1104 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 69/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 69 | reduced_train_loss: 1.416 | consumed_samples: 1120 | val_loss: 1.549\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 70/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 70 | reduced_train_loss: 1.442 | consumed_samples: 1136 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 71/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 71 | reduced_train_loss: 1.555 | consumed_samples: 1152 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 72/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 72 | reduced_train_loss: 1.443 | consumed_samples: 1168 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 73/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 73 | reduced_train_loss: 1.306 | consumed_samples: 1184 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 74/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 74 | reduced_train_loss: 1.407 | consumed_samples: 1200 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 75/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 75 | reduced_train_loss: 1.419 | consumed_samples: 1216 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 76/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 76 | reduced_train_loss: 1.37 | consumed_samples: 1232 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 77/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 77 | reduced_train_loss: 1.605 | consumed_samples: 1248 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 78/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 78 | reduced_train_loss: 1.144 | consumed_samples: 1264 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 79/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 79 | reduced_train_loss: 1.247 | consumed_samples: 1280 | val_loss: 1.55\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 80/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 80 | reduced_train_loss: 1.492 | consumed_samples: 1296 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 81/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 81 | reduced_train_loss: 1.462 | consumed_samples: 1312 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 82/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 82 | reduced_train_loss: 1.841 | consumed_samples: 1328 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 83/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 83 | reduced_train_loss: 1.338 | consumed_samples: 1344 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 84/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 84 | reduced_train_loss: 1.312 | consumed_samples: 1360 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 85/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 85 | reduced_train_loss: 1.722 | consumed_samples: 1376 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 86/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 86 | reduced_train_loss: 1.539 | consumed_samples: 1392 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 87/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 87 | reduced_train_loss: 1.176 | consumed_samples: 1408 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 88/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 88 | reduced_train_loss: 1.738 | consumed_samples: 1424 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 89/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 89 | reduced_train_loss: 1.496 | consumed_samples: 1440 | val_loss: 1.548\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 90/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 90 | reduced_train_loss: 1.479 | consumed_samples: 1456 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 91/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 91 | reduced_train_loss: 1.719 | consumed_samples: 1472 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 92/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 92 | reduced_train_loss: 1.303 | consumed_samples: 1488 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 93/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 93 | reduced_train_loss: 1.406 | consumed_samples: 1504 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 94/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 94 | reduced_train_loss: 1.46 | consumed_samples: 1520 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 95/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 95 | reduced_train_loss: 1.443 | consumed_samples: 1536 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 96/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 96 | reduced_train_loss: 1.977 | consumed_samples: 1552 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 97/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 97 | reduced_train_loss: 1.75 | consumed_samples: 1568 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 98/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 98 | reduced_train_loss: 1.462 | consumed_samples: 1584 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 99/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 99 | reduced_train_loss: 1.535 | consumed_samples: 1600 | val_loss: 1.538\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 100/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 100 | reduced_train_loss: 1.946 | consumed_samples: 1616 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 101/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 101 | reduced_train_loss: 1.468 | consumed_samples: 1632 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 102/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 102 | reduced_train_loss: 1.204 | consumed_samples: 1648 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 103/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 103 | reduced_train_loss: 1.65 | consumed_samples: 1664 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 104/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 104 | reduced_train_loss: 1.589 | consumed_samples: 1680 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 105/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 105 | reduced_train_loss: 1.553 | consumed_samples: 1696 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 106/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 106 | reduced_train_loss: 1.498 | consumed_samples: 1712 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 107/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 107 | reduced_train_loss: 1.571 | consumed_samples: 1728 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 108/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 108 | reduced_train_loss: 1.193 | consumed_samples: 1744 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 109/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 109 | reduced_train_loss: 2.151 | consumed_samples: 1760 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 110/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 110 | reduced_train_loss: 1.479 | consumed_samples: 1776 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 111/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 111 | reduced_train_loss: 1.49 | consumed_samples: 1792 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 112/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 112 | reduced_train_loss: 1.794 | consumed_samples: 1808 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 113/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 113 | reduced_train_loss: 1.049 | consumed_samples: 1824 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 114/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 114 | reduced_train_loss: 1.52 | consumed_samples: 1840 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 115/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 115 | reduced_train_loss: 1.731 | consumed_samples: 1856 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 116/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 116 | reduced_train_loss: 1.852 | consumed_samples: 1872 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 117/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 117 | reduced_train_loss: 1.575 | consumed_samples: 1888 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 118/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 118 | reduced_train_loss: 1.059 | consumed_samples: 1904 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 119/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 119 | reduced_train_loss: 1.392 | consumed_samples: 1920 | val_loss: 1.54\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 120/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 120 | reduced_train_loss: 1.626 | consumed_samples: 1936 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 121/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 121 | reduced_train_loss: 1.359 | consumed_samples: 1952 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 122/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 122 | reduced_train_loss: 1.928 | consumed_samples: 1968 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 123/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 123 | reduced_train_loss: 1.453 | consumed_samples: 1984 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 124/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 124 | reduced_train_loss: 1.665 | consumed_samples: 2000 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 125/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 125 | reduced_train_loss: 1.468 | consumed_samples: 2016 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 126/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 126 | reduced_train_loss: 1.503 | consumed_samples: 2032 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 127/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 127 | reduced_train_loss: 1.503 | consumed_samples: 2048 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 128/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 128 | reduced_train_loss: 1.421 | consumed_samples: 2064 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 129/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 129 | reduced_train_loss: 1.533 | consumed_samples: 2080 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 130/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 130 | reduced_train_loss: 1.494 | consumed_samples: 2096 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 131/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 131 | reduced_train_loss: 1.537 | consumed_samples: 2112 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 132/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 132 | reduced_train_loss: 1.394 | consumed_samples: 2128 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 133/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 133 | reduced_train_loss: 1.258 | consumed_samples: 2144 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 134/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 134 | reduced_train_loss: 1.466 | consumed_samples: 2160 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 135/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 135 | reduced_train_loss: 1.527 | consumed_samples: 2176 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 136/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 136 | reduced_train_loss: 1.427 | consumed_samples: 2192 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 137/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 137 | reduced_train_loss: 1.434 | consumed_samples: 2208 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 138/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 138 | reduced_train_loss: 1.59 | consumed_samples: 2224 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 139/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 139 | reduced_train_loss: 1.321 | consumed_samples: 2240 | val_loss: 1.544\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 140/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 140 | reduced_train_loss: 1.7 | consumed_samples: 2256 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 141/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 141 | reduced_train_loss: 1.329 | consumed_samples: 2272 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 142/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 142 | reduced_train_loss: 1.523 | consumed_samples: 2288 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 143/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 143 | reduced_train_loss: 1.666 | consumed_samples: 2304 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 144/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 144 | reduced_train_loss: 1.497 | consumed_samples: 2320 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 145/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 145 | reduced_train_loss: 0.8402 | consumed_samples: 2336 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 146/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 146 | reduced_train_loss: 1.383 | consumed_samples: 2352 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 147/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 147 | reduced_train_loss: 1.668 | consumed_samples: 2368 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 148/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 148 | reduced_train_loss: 1.502 | consumed_samples: 2384 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 149/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 149 | reduced_train_loss: 1.698 | consumed_samples: 2400 | val_loss: 1.539\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 150/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 150 | reduced_train_loss: 1.493 | consumed_samples: 2416 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 151/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 151 | reduced_train_loss: 1.665 | consumed_samples: 2432 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 152/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 152 | reduced_train_loss: 1.312 | consumed_samples: 2448 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 153/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 153 | reduced_train_loss: 1.414 | consumed_samples: 2464 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 154/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 154 | reduced_train_loss: 1.379 | consumed_samples: 2480 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 155/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 155 | reduced_train_loss: 1.29 | consumed_samples: 2496 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 156/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 156 | reduced_train_loss: 1.642 | consumed_samples: 2512 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 157/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 157 | reduced_train_loss: 1.704 | consumed_samples: 2528 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 158/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 158 | reduced_train_loss: 1.403 | consumed_samples: 2544 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 159/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 159 | reduced_train_loss: 1.47 | consumed_samples: 2560 | val_loss: 1.542\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 160/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 160 | reduced_train_loss: 1.25 | consumed_samples: 2576 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 161/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 161 | reduced_train_loss: 1.426 | consumed_samples: 2592 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 162/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 162 | reduced_train_loss: 1.626 | consumed_samples: 2608 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 163/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 163 | reduced_train_loss: 1.296 | consumed_samples: 2624 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 164/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 164 | reduced_train_loss: 1.837 | consumed_samples: 2640 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 165/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 165 | reduced_train_loss: 1.368 | consumed_samples: 2656 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 166/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 166 | reduced_train_loss: 1.52 | consumed_samples: 2672 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 167/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 167 | reduced_train_loss: 1.616 | consumed_samples: 2688 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 168/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 168 | reduced_train_loss: 1.425 | consumed_samples: 2704 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 169/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 169 | reduced_train_loss: 1.552 | consumed_samples: 2720 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 170/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 170 | reduced_train_loss: 1.346 | consumed_samples: 2736 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 171/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 171 | reduced_train_loss: 1.642 | consumed_samples: 2752 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 172/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 172 | reduced_train_loss: 1.683 | consumed_samples: 2768 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 173/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 173 | reduced_train_loss: 1.39 | consumed_samples: 2784 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 174/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 174 | reduced_train_loss: 1.392 | consumed_samples: 2800 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 175/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 175 | reduced_train_loss: 1.518 | consumed_samples: 2816 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 176/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 176 | reduced_train_loss: 1.341 | consumed_samples: 2832 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 177/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 177 | reduced_train_loss: 1.681 | consumed_samples: 2848 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 178/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 178 | reduced_train_loss: 1.451 | consumed_samples: 2864 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 179/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 179 | reduced_train_loss: 1.226 | consumed_samples: 2880 | val_loss: 1.533\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 180/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 180 | reduced_train_loss: 1.778 | consumed_samples: 2896 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 181/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 181 | reduced_train_loss: 1.386 | consumed_samples: 2912 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 182/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 182 | reduced_train_loss: 1.658 | consumed_samples: 2928 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 183/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 183 | reduced_train_loss: 1.765 | consumed_samples: 2944 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 184/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 184 | reduced_train_loss: 1.603 | consumed_samples: 2960 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 185/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 185 | reduced_train_loss: 1.907 | consumed_samples: 2976 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 186/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 186 | reduced_train_loss: 1.722 | consumed_samples: 2992 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 187/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 187 | reduced_train_loss: 1.695 | consumed_samples: 3008 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 188/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 188 | reduced_train_loss: 1.515 | consumed_samples: 3024 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 189/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 189 | reduced_train_loss: 1.646 | consumed_samples: 3040 | val_loss: 1.527\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 190/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 190 | reduced_train_loss: 1.321 | consumed_samples: 3056 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 191/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 191 | reduced_train_loss: 1.865 | consumed_samples: 3072 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 192/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 192 | reduced_train_loss: 1.623 | consumed_samples: 3088 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 193/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 193 | reduced_train_loss: 1.436 | consumed_samples: 3104 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 194/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 194 | reduced_train_loss: 1.317 | consumed_samples: 3120 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 195/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 195 | reduced_train_loss: 1.157 | consumed_samples: 3136 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 196/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 196 | reduced_train_loss: 1.48 | consumed_samples: 3152 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 197/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 197 | reduced_train_loss: 1.652 | consumed_samples: 3168 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 198/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 198 | reduced_train_loss: 1.486 | consumed_samples: 3184 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:Epoch 0, global step 199: 'reduced_train_loss' reached 1.58248 (best 1.58248), saving model to '/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0.ckpt' as top 1\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 199/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 199 | reduced_train_loss: 1.582 | consumed_samples: 3200 | val_loss: 1.526\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:03 nemo_logging:393] Using FullyParallelSaveStrategyWrapper(torch_dist, 1) dist-ckpt save strategy.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:08 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 199 : Start time: 1754360523.812s : Save duration: 4.691s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:08 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:08 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 199 : Start time: 1754360528.779s : Save duration: 0.163s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:09 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:09 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 200/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 200 | reduced_train_loss: 1.596 | consumed_samples: 3216 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:09 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 201/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 201 | reduced_train_loss: 1.507 | consumed_samples: 3232 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:09 nemo_logging:393] Async finalization time took 0.000 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 202/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 202 | reduced_train_loss: 1.419 | consumed_samples: 3248 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:10 nemo_logging:393] Successfully saved checkpoint from iteration     199 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:10 nemo_logging:393] Async checkpoint save for step 200 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:10 nemo_logging:393] Successfully saved checkpoint from iteration     199 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:10 nemo_logging:393] Async checkpoint save for step 200 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.5825-epoch=0-consumed_samples=3200.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:22:10 nemo_logging:393] Async finalization time took 0.088 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 203/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 203 | reduced_train_loss: 1.542 | consumed_samples: 3264 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 204/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 204 | reduced_train_loss: 1.883 | consumed_samples: 3280 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 205/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 205 | reduced_train_loss: 1.584 | consumed_samples: 3296 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 206/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 206 | reduced_train_loss: 1.364 | consumed_samples: 3312 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 207/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 207 | reduced_train_loss: 1.419 | consumed_samples: 3328 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 208/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 208 | reduced_train_loss: 1.719 | consumed_samples: 3344 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 209/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 209 | reduced_train_loss: 1.545 | consumed_samples: 3360 | val_loss: 1.53\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 210/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 210 | reduced_train_loss: 1.374 | consumed_samples: 3376 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 211/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 211 | reduced_train_loss: 1.718 | consumed_samples: 3392 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 212/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 212 | reduced_train_loss: 1.562 | consumed_samples: 3408 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 213/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 213 | reduced_train_loss: 1.692 | consumed_samples: 3424 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 214/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 214 | reduced_train_loss: 1.192 | consumed_samples: 3440 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 215/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 215 | reduced_train_loss: 1.633 | consumed_samples: 3456 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 216/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 216 | reduced_train_loss: 1.488 | consumed_samples: 3472 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 217/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 217 | reduced_train_loss: 1.567 | consumed_samples: 3488 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 218/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 218 | reduced_train_loss: 1.977 | consumed_samples: 3504 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 219/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 219 | reduced_train_loss: 1.612 | consumed_samples: 3520 | val_loss: 1.528\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 220/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 220 | reduced_train_loss: 1.442 | consumed_samples: 3536 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 221/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 221 | reduced_train_loss: 1.328 | consumed_samples: 3552 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 222/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 222 | reduced_train_loss: 1.66 | consumed_samples: 3568 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 223/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 223 | reduced_train_loss: 1.359 | consumed_samples: 3584 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 224/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 224 | reduced_train_loss: 1.397 | consumed_samples: 3600 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 225/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 225 | reduced_train_loss: 1.381 | consumed_samples: 3616 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 226/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 226 | reduced_train_loss: 1.427 | consumed_samples: 3632 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 227/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 227 | reduced_train_loss: 1.675 | consumed_samples: 3648 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 228/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 228 | reduced_train_loss: 1.787 | consumed_samples: 3664 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 229/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 229 | reduced_train_loss: 1.396 | consumed_samples: 3680 | val_loss: 1.523\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 230/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 230 | reduced_train_loss: 1.397 | consumed_samples: 3696 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 231/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 231 | reduced_train_loss: 1.174 | consumed_samples: 3712 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 232/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 232 | reduced_train_loss: 1.564 | consumed_samples: 3728 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 233/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 233 | reduced_train_loss: 1.525 | consumed_samples: 3744 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 234/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 234 | reduced_train_loss: 1.647 | consumed_samples: 3760 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 235/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 235 | reduced_train_loss: 1.71 | consumed_samples: 3776 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 236/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 236 | reduced_train_loss: 1.456 | consumed_samples: 3792 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 237/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 237 | reduced_train_loss: 1.724 | consumed_samples: 3808 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 238/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 238 | reduced_train_loss: 1.398 | consumed_samples: 3824 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 239/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 239 | reduced_train_loss: 1.467 | consumed_samples: 3840 | val_loss: 1.519\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 240/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 240 | reduced_train_loss: 1.656 | consumed_samples: 3856 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 241/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 241 | reduced_train_loss: 1.33 | consumed_samples: 3872 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 242/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 242 | reduced_train_loss: 1.664 | consumed_samples: 3888 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 243/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 243 | reduced_train_loss: 1.297 | consumed_samples: 3904 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 244/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 244 | reduced_train_loss: 1.885 | consumed_samples: 3920 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 245/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 245 | reduced_train_loss: 1.594 | consumed_samples: 3936 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 246/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 246 | reduced_train_loss: 1.465 | consumed_samples: 3952 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 247/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 247 | reduced_train_loss: 1.38 | consumed_samples: 3968 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 248/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 248 | reduced_train_loss: 1.468 | consumed_samples: 3984 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 249/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 249 | reduced_train_loss: 1.145 | consumed_samples: 4000 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 250/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 250 | reduced_train_loss: 1.261 | consumed_samples: 4016 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 251/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 251 | reduced_train_loss: 1.302 | consumed_samples: 4032 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 252/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 252 | reduced_train_loss: 1.345 | consumed_samples: 4048 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 253/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 253 | reduced_train_loss: 1.644 | consumed_samples: 4064 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 254/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 254 | reduced_train_loss: 1.665 | consumed_samples: 4080 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 255/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 255 | reduced_train_loss: 1.714 | consumed_samples: 4096 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 256/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 256 | reduced_train_loss: 1.618 | consumed_samples: 4112 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 257/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 257 | reduced_train_loss: 1.669 | consumed_samples: 4128 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 258/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 258 | reduced_train_loss: 1.534 | consumed_samples: 4144 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 259/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 259 | reduced_train_loss: 1.425 | consumed_samples: 4160 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 260/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 260 | reduced_train_loss: 1.643 | consumed_samples: 4176 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 261/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 261 | reduced_train_loss: 1.681 | consumed_samples: 4192 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 262/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 262 | reduced_train_loss: 1.363 | consumed_samples: 4208 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 263/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 263 | reduced_train_loss: 1.484 | consumed_samples: 4224 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 264/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 264 | reduced_train_loss: 1.353 | consumed_samples: 4240 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 265/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 265 | reduced_train_loss: 1.344 | consumed_samples: 4256 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 266/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 266 | reduced_train_loss: 1.718 | consumed_samples: 4272 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 267/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 267 | reduced_train_loss: 1.409 | consumed_samples: 4288 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 268/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 268 | reduced_train_loss: 1.709 | consumed_samples: 4304 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 269/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 269 | reduced_train_loss: 1.464 | consumed_samples: 4320 | val_loss: 1.518\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 270/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 270 | reduced_train_loss: 1.571 | consumed_samples: 4336 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 271/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 271 | reduced_train_loss: 1.629 | consumed_samples: 4352 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 272/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 272 | reduced_train_loss: 1.505 | consumed_samples: 4368 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 273/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 273 | reduced_train_loss: 1.463 | consumed_samples: 4384 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 274/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 274 | reduced_train_loss: 1.444 | consumed_samples: 4400 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 275/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 275 | reduced_train_loss: 1.399 | consumed_samples: 4416 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 276/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 276 | reduced_train_loss: 1.907 | consumed_samples: 4432 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 277/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 277 | reduced_train_loss: 1.785 | consumed_samples: 4448 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 278/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 278 | reduced_train_loss: 0.9315 | consumed_samples: 4464 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 279/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 279 | reduced_train_loss: 1.555 | consumed_samples: 4480 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 280/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 280 | reduced_train_loss: 1.486 | consumed_samples: 4496 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 281/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 281 | reduced_train_loss: 1.523 | consumed_samples: 4512 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 282/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 282 | reduced_train_loss: 1.463 | consumed_samples: 4528 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 283/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 283 | reduced_train_loss: 1.354 | consumed_samples: 4544 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 284/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 284 | reduced_train_loss: 1.414 | consumed_samples: 4560 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 285/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 285 | reduced_train_loss: 1.728 | consumed_samples: 4576 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 286/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 286 | reduced_train_loss: 1.934 | consumed_samples: 4592 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 287/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 287 | reduced_train_loss: 1.45 | consumed_samples: 4608 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 288/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 288 | reduced_train_loss: 1.302 | consumed_samples: 4624 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 289/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 289 | reduced_train_loss: 1.428 | consumed_samples: 4640 | val_loss: 1.508\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 290/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 290 | reduced_train_loss: 1.51 | consumed_samples: 4656 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 291/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 291 | reduced_train_loss: 1.191 | consumed_samples: 4672 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 292/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 292 | reduced_train_loss: 1.583 | consumed_samples: 4688 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 293/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 293 | reduced_train_loss: 1.823 | consumed_samples: 4704 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 294/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 294 | reduced_train_loss: 1.57 | consumed_samples: 4720 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 295/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 295 | reduced_train_loss: 1.29 | consumed_samples: 4736 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 296/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 296 | reduced_train_loss: 1.387 | consumed_samples: 4752 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 297/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 297 | reduced_train_loss: 1.527 | consumed_samples: 4768 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 298/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 298 | reduced_train_loss: 1.826 | consumed_samples: 4784 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 299/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 299 | reduced_train_loss: 1.358 | consumed_samples: 4800 | val_loss: 1.514\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 300/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 300 | reduced_train_loss: 1.727 | consumed_samples: 4816 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 301/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 301 | reduced_train_loss: 1.436 | consumed_samples: 4832 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 302/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 302 | reduced_train_loss: 1.458 | consumed_samples: 4848 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 303/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 303 | reduced_train_loss: 1.39 | consumed_samples: 4864 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 304/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 304 | reduced_train_loss: 1.787 | consumed_samples: 4880 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 305/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 305 | reduced_train_loss: 1.306 | consumed_samples: 4896 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 306/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 306 | reduced_train_loss: 1.671 | consumed_samples: 4912 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 307/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 307 | reduced_train_loss: 1.139 | consumed_samples: 4928 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 308/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 308 | reduced_train_loss: 1.53 | consumed_samples: 4944 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 309/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 309 | reduced_train_loss: 1.633 | consumed_samples: 4960 | val_loss: 1.513\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 310/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 310 | reduced_train_loss: 1.349 | consumed_samples: 4976 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 311/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 311 | reduced_train_loss: 1.718 | consumed_samples: 4992 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 312/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 312 | reduced_train_loss: 1.449 | consumed_samples: 5008 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 313/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 313 | reduced_train_loss: 1.054 | consumed_samples: 5024 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 314/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 314 | reduced_train_loss: 1.443 | consumed_samples: 5040 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 315/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 315 | reduced_train_loss: 1.526 | consumed_samples: 5056 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 316/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 316 | reduced_train_loss: 1.583 | consumed_samples: 5072 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 317/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 317 | reduced_train_loss: 1.319 | consumed_samples: 5088 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 318/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 318 | reduced_train_loss: 1.07 | consumed_samples: 5104 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 319/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 319 | reduced_train_loss: 1.789 | consumed_samples: 5120 | val_loss: 1.501\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 320/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 320 | reduced_train_loss: 1.786 | consumed_samples: 5136 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 321/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 321 | reduced_train_loss: 1.424 | consumed_samples: 5152 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 322/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 322 | reduced_train_loss: 1.602 | consumed_samples: 5168 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 323/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 323 | reduced_train_loss: 1.569 | consumed_samples: 5184 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 324/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 324 | reduced_train_loss: 1.184 | consumed_samples: 5200 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 325/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 325 | reduced_train_loss: 1.534 | consumed_samples: 5216 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 326/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 326 | reduced_train_loss: 1.673 | consumed_samples: 5232 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 327/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 327 | reduced_train_loss: 1.581 | consumed_samples: 5248 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 328/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 328 | reduced_train_loss: 1.706 | consumed_samples: 5264 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 329/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 329 | reduced_train_loss: 1.516 | consumed_samples: 5280 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 330/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 330 | reduced_train_loss: 1.61 | consumed_samples: 5296 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 331/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 331 | reduced_train_loss: 1.66 | consumed_samples: 5312 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 332/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 332 | reduced_train_loss: 1.629 | consumed_samples: 5328 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 333/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 333 | reduced_train_loss: 1.149 | consumed_samples: 5344 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 334/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 334 | reduced_train_loss: 1.703 | consumed_samples: 5360 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 335/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 335 | reduced_train_loss: 1.323 | consumed_samples: 5376 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 336/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 336 | reduced_train_loss: 1.45 | consumed_samples: 5392 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 337/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 337 | reduced_train_loss: 1.573 | consumed_samples: 5408 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 338/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 338 | reduced_train_loss: 1.578 | consumed_samples: 5424 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 339/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 339 | reduced_train_loss: 1.305 | consumed_samples: 5440 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 340/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 340 | reduced_train_loss: 1.45 | consumed_samples: 5456 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 341/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 341 | reduced_train_loss: 1.406 | consumed_samples: 5472 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 342/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 342 | reduced_train_loss: 1.456 | consumed_samples: 5488 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 343/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 343 | reduced_train_loss: 2.114 | consumed_samples: 5504 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 344/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 344 | reduced_train_loss: 1.539 | consumed_samples: 5520 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 345/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 345 | reduced_train_loss: 1.477 | consumed_samples: 5536 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 346/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 346 | reduced_train_loss: 1.804 | consumed_samples: 5552 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 347/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 347 | reduced_train_loss: 1.214 | consumed_samples: 5568 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 348/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 348 | reduced_train_loss: 1.252 | consumed_samples: 5584 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 349/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 349 | reduced_train_loss: 1.942 | consumed_samples: 5600 | val_loss: 1.51\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 350/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 350 | reduced_train_loss: 1.553 | consumed_samples: 5616 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 351/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 351 | reduced_train_loss: 1.451 | consumed_samples: 5632 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 352/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 352 | reduced_train_loss: 1.389 | consumed_samples: 5648 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 353/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 353 | reduced_train_loss: 1.339 | consumed_samples: 5664 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 354/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 354 | reduced_train_loss: 1.622 | consumed_samples: 5680 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 355/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 355 | reduced_train_loss: 1.241 | consumed_samples: 5696 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 356/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 356 | reduced_train_loss: 1.495 | consumed_samples: 5712 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 357/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 357 | reduced_train_loss: 1.454 | consumed_samples: 5728 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 358/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 358 | reduced_train_loss: 1.372 | consumed_samples: 5744 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 359/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 359 | reduced_train_loss: 1.473 | consumed_samples: 5760 | val_loss: 1.507\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 360/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 360 | reduced_train_loss: 1.672 | consumed_samples: 5776 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 361/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 361 | reduced_train_loss: 1.125 | consumed_samples: 5792 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 362/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 362 | reduced_train_loss: 1.228 | consumed_samples: 5808 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 363/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 363 | reduced_train_loss: 1.489 | consumed_samples: 5824 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 364/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 364 | reduced_train_loss: 1.512 | consumed_samples: 5840 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 365/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 365 | reduced_train_loss: 1.536 | consumed_samples: 5856 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 366/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 366 | reduced_train_loss: 1.582 | consumed_samples: 5872 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 367/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 367 | reduced_train_loss: 1.159 | consumed_samples: 5888 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 368/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 368 | reduced_train_loss: 1.655 | consumed_samples: 5904 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 369/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 369 | reduced_train_loss: 1.784 | consumed_samples: 5920 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 370/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 370 | reduced_train_loss: 1.425 | consumed_samples: 5936 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 371/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 371 | reduced_train_loss: 1.361 | consumed_samples: 5952 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 372/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 372 | reduced_train_loss: 1.77 | consumed_samples: 5968 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 373/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 373 | reduced_train_loss: 1.63 | consumed_samples: 5984 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 374/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 374 | reduced_train_loss: 1.335 | consumed_samples: 6000 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 375/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 375 | reduced_train_loss: 1.715 | consumed_samples: 6016 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 376/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 376 | reduced_train_loss: 1.464 | consumed_samples: 6032 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 377/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 377 | reduced_train_loss: 1.556 | consumed_samples: 6048 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 378/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 378 | reduced_train_loss: 1.518 | consumed_samples: 6064 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 379/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 379 | reduced_train_loss: 1.257 | consumed_samples: 6080 | val_loss: 1.505\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 380/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 380 | reduced_train_loss: 1.504 | consumed_samples: 6096 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 381/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 381 | reduced_train_loss: 1.532 | consumed_samples: 6112 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 382/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 382 | reduced_train_loss: 1.184 | consumed_samples: 6128 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 383/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 383 | reduced_train_loss: 1.698 | consumed_samples: 6144 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 384/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 384 | reduced_train_loss: 1.582 | consumed_samples: 6160 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 385/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 385 | reduced_train_loss: 1.229 | consumed_samples: 6176 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 386/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 386 | reduced_train_loss: 1.505 | consumed_samples: 6192 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 387/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 387 | reduced_train_loss: 1.555 | consumed_samples: 6208 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 388/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 388 | reduced_train_loss: 1.812 | consumed_samples: 6224 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 389/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 389 | reduced_train_loss: 1.633 | consumed_samples: 6240 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 390/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 390 | reduced_train_loss: 1.571 | consumed_samples: 6256 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 391/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 391 | reduced_train_loss: 1.443 | consumed_samples: 6272 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 392/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 392 | reduced_train_loss: 1.787 | consumed_samples: 6288 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 393/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 393 | reduced_train_loss: 1.331 | consumed_samples: 6304 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 394/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 394 | reduced_train_loss: 1.624 | consumed_samples: 6320 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 395/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 395 | reduced_train_loss: 1.525 | consumed_samples: 6336 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 396/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 396 | reduced_train_loss: 1.683 | consumed_samples: 6352 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 397/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 397 | reduced_train_loss: 1.676 | consumed_samples: 6368 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 398/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 398 | reduced_train_loss: 1.857 | consumed_samples: 6384 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Epoch 0, global step 399: 'reduced_train_loss' reached 1.29724 (best 1.29724), saving model to '/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0.ckpt' as top 1\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 399/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 399 | reduced_train_loss: 1.297 | consumed_samples: 6400 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:12 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 399 : Start time: 1754360591.487s : Save duration: 0.690s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:12 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:12 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 399 : Start time: 1754360592.314s : Save duration: 0.135s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:12 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:12 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 400/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 400 | reduced_train_loss: 1.513 | consumed_samples: 6416 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:13 nemo_logging:393] Successfully saved checkpoint from iteration     399 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:13 nemo_logging:393] Async checkpoint save for step 400 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:13 nemo_logging:393] Successfully saved checkpoint from iteration     399 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:13 nemo_logging:393] Async checkpoint save for step 400 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.2972-epoch=0-consumed_samples=6400.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:23:13 nemo_logging:393] Async finalization time took 0.146 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 401/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 401 | reduced_train_loss: 1.333 | consumed_samples: 6432 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 402/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 402 | reduced_train_loss: 1.428 | consumed_samples: 6448 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 403/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 403 | reduced_train_loss: 1.54 | consumed_samples: 6464 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 404/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 404 | reduced_train_loss: 1.286 | consumed_samples: 6480 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 405/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 405 | reduced_train_loss: 1.473 | consumed_samples: 6496 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 406/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 406 | reduced_train_loss: 1.504 | consumed_samples: 6512 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 407/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 407 | reduced_train_loss: 1.472 | consumed_samples: 6528 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 408/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 408 | reduced_train_loss: 1.588 | consumed_samples: 6544 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 409/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 409 | reduced_train_loss: 1.399 | consumed_samples: 6560 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 410/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 410 | reduced_train_loss: 1.779 | consumed_samples: 6576 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 411/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 411 | reduced_train_loss: 1.343 | consumed_samples: 6592 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 412/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 412 | reduced_train_loss: 1.643 | consumed_samples: 6608 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 413/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 413 | reduced_train_loss: 1.704 | consumed_samples: 6624 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 414/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 414 | reduced_train_loss: 1.28 | consumed_samples: 6640 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 415/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 415 | reduced_train_loss: 1.499 | consumed_samples: 6656 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 416/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 416 | reduced_train_loss: 1.335 | consumed_samples: 6672 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 417/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 417 | reduced_train_loss: 1.685 | consumed_samples: 6688 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 418/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 418 | reduced_train_loss: 1.62 | consumed_samples: 6704 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 419/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 419 | reduced_train_loss: 1.559 | consumed_samples: 6720 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 420/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 420 | reduced_train_loss: 1.409 | consumed_samples: 6736 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 421/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 421 | reduced_train_loss: 1.308 | consumed_samples: 6752 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 422/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 422 | reduced_train_loss: 1.562 | consumed_samples: 6768 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 423/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 423 | reduced_train_loss: 1.492 | consumed_samples: 6784 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 424/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 424 | reduced_train_loss: 1.573 | consumed_samples: 6800 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 425/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 425 | reduced_train_loss: 1.637 | consumed_samples: 6816 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 426/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 426 | reduced_train_loss: 1.937 | consumed_samples: 6832 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 427/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 427 | reduced_train_loss: 1.385 | consumed_samples: 6848 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 428/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 428 | reduced_train_loss: 1.505 | consumed_samples: 6864 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 429/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 429 | reduced_train_loss: 1.453 | consumed_samples: 6880 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 430/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 430 | reduced_train_loss: 1.659 | consumed_samples: 6896 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 431/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 431 | reduced_train_loss: 1.467 | consumed_samples: 6912 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 432/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 432 | reduced_train_loss: 1.752 | consumed_samples: 6928 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 433/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 433 | reduced_train_loss: 1.606 | consumed_samples: 6944 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 434/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 434 | reduced_train_loss: 1.793 | consumed_samples: 6960 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 435/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 435 | reduced_train_loss: 1.252 | consumed_samples: 6976 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 436/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 436 | reduced_train_loss: 1.507 | consumed_samples: 6992 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 437/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 437 | reduced_train_loss: 1.655 | consumed_samples: 7008 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 438/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 438 | reduced_train_loss: 1.354 | consumed_samples: 7024 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 439/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 439 | reduced_train_loss: 1.63 | consumed_samples: 7040 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 440/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 440 | reduced_train_loss: 1.422 | consumed_samples: 7056 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 441/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 441 | reduced_train_loss: 1.221 | consumed_samples: 7072 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 442/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 442 | reduced_train_loss: 1.689 | consumed_samples: 7088 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 443/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 443 | reduced_train_loss: 1.546 | consumed_samples: 7104 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 444/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 444 | reduced_train_loss: 1.54 | consumed_samples: 7120 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 445/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 445 | reduced_train_loss: 1.502 | consumed_samples: 7136 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 446/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 446 | reduced_train_loss: 1.628 | consumed_samples: 7152 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 447/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 447 | reduced_train_loss: 1.553 | consumed_samples: 7168 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 448/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 448 | reduced_train_loss: 1.255 | consumed_samples: 7184 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 449/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 449 | reduced_train_loss: 1.284 | consumed_samples: 7200 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 450/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 450 | reduced_train_loss: 1.652 | consumed_samples: 7216 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 451/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 451 | reduced_train_loss: 1.526 | consumed_samples: 7232 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 452/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 452 | reduced_train_loss: 1.497 | consumed_samples: 7248 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 453/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 453 | reduced_train_loss: 1.415 | consumed_samples: 7264 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 454/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 454 | reduced_train_loss: 1.45 | consumed_samples: 7280 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 455/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 455 | reduced_train_loss: 1.325 | consumed_samples: 7296 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 456/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 456 | reduced_train_loss: 1.496 | consumed_samples: 7312 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 457/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 457 | reduced_train_loss: 1.253 | consumed_samples: 7328 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 458/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 458 | reduced_train_loss: 1.376 | consumed_samples: 7344 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 459/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 459 | reduced_train_loss: 1.346 | consumed_samples: 7360 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 460/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 460 | reduced_train_loss: 1.252 | consumed_samples: 7376 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 461/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 461 | reduced_train_loss: 1.553 | consumed_samples: 7392 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 462/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 462 | reduced_train_loss: 1.372 | consumed_samples: 7408 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 463/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 463 | reduced_train_loss: 1.621 | consumed_samples: 7424 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 464/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 464 | reduced_train_loss: 1.507 | consumed_samples: 7440 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 465/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 465 | reduced_train_loss: 1.22 | consumed_samples: 7456 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 466/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 466 | reduced_train_loss: 1.371 | consumed_samples: 7472 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 467/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 467 | reduced_train_loss: 1.321 | consumed_samples: 7488 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 468/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 468 | reduced_train_loss: 1.607 | consumed_samples: 7504 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 469/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 469 | reduced_train_loss: 1.332 | consumed_samples: 7520 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 470/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 470 | reduced_train_loss: 1.091 | consumed_samples: 7536 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 471/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 471 | reduced_train_loss: 1.742 | consumed_samples: 7552 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 472/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 472 | reduced_train_loss: 1.363 | consumed_samples: 7568 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 473/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 473 | reduced_train_loss: 1.258 | consumed_samples: 7584 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 474/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 474 | reduced_train_loss: 1.299 | consumed_samples: 7600 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 475/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 475 | reduced_train_loss: 1.605 | consumed_samples: 7616 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 476/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 476 | reduced_train_loss: 1.539 | consumed_samples: 7632 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 477/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 477 | reduced_train_loss: 1.641 | consumed_samples: 7648 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 478/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 478 | reduced_train_loss: 1.823 | consumed_samples: 7664 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 479/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 479 | reduced_train_loss: 1.334 | consumed_samples: 7680 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 480/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 480 | reduced_train_loss: 1.423 | consumed_samples: 7696 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 481/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 481 | reduced_train_loss: 1.372 | consumed_samples: 7712 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 482/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 482 | reduced_train_loss: 1.57 | consumed_samples: 7728 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 483/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 483 | reduced_train_loss: 1.53 | consumed_samples: 7744 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 484/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 484 | reduced_train_loss: 1.544 | consumed_samples: 7760 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 485/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 485 | reduced_train_loss: 1.708 | consumed_samples: 7776 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 486/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 486 | reduced_train_loss: 1.757 | consumed_samples: 7792 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 487/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 487 | reduced_train_loss: 1.425 | consumed_samples: 7808 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 488/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 488 | reduced_train_loss: 1.53 | consumed_samples: 7824 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 489/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 489 | reduced_train_loss: 1.407 | consumed_samples: 7840 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 490/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 490 | reduced_train_loss: 1.358 | consumed_samples: 7856 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 491/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 491 | reduced_train_loss: 1.758 | consumed_samples: 7872 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 492/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 492 | reduced_train_loss: 1.637 | consumed_samples: 7888 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 493/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 493 | reduced_train_loss: 1.651 | consumed_samples: 7904 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 494/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 494 | reduced_train_loss: 1.409 | consumed_samples: 7920 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 495/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 495 | reduced_train_loss: 1.49 | consumed_samples: 7936 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 496/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 496 | reduced_train_loss: 1.57 | consumed_samples: 7952 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 497/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 497 | reduced_train_loss: 1.239 | consumed_samples: 7968 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 498/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 498 | reduced_train_loss: 1.51 | consumed_samples: 7984 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 499/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 499 | reduced_train_loss: 1.549 | consumed_samples: 8000 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 500/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 500 | reduced_train_loss: 1.437 | consumed_samples: 8016 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 501/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 501 | reduced_train_loss: 1.574 | consumed_samples: 8032 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 502/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 502 | reduced_train_loss: 1.544 | consumed_samples: 8048 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 503/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 503 | reduced_train_loss: 1.484 | consumed_samples: 8064 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 504/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 504 | reduced_train_loss: 1.037 | consumed_samples: 8080 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 505/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 505 | reduced_train_loss: 1.474 | consumed_samples: 8096 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 506/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 506 | reduced_train_loss: 1.336 | consumed_samples: 8112 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 507/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 507 | reduced_train_loss: 1.486 | consumed_samples: 8128 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 508/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 508 | reduced_train_loss: 1.36 | consumed_samples: 8144 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 509/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 509 | reduced_train_loss: 1.443 | consumed_samples: 8160 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 510/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 510 | reduced_train_loss: 1.432 | consumed_samples: 8176 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 511/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 511 | reduced_train_loss: 1.51 | consumed_samples: 8192 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 512/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 512 | reduced_train_loss: 1.412 | consumed_samples: 8208 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 513/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 513 | reduced_train_loss: 1.274 | consumed_samples: 8224 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 514/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 514 | reduced_train_loss: 1.297 | consumed_samples: 8240 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 515/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 515 | reduced_train_loss: 1.678 | consumed_samples: 8256 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 516/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 516 | reduced_train_loss: 1.467 | consumed_samples: 8272 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 517/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 517 | reduced_train_loss: 1.634 | consumed_samples: 8288 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 518/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 518 | reduced_train_loss: 1.552 | consumed_samples: 8304 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 519/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 519 | reduced_train_loss: 1.544 | consumed_samples: 8320 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 520/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 520 | reduced_train_loss: 1.363 | consumed_samples: 8336 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 521/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 521 | reduced_train_loss: 1.479 | consumed_samples: 8352 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 522/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 522 | reduced_train_loss: 1.126 | consumed_samples: 8368 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 523/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 523 | reduced_train_loss: 1.564 | consumed_samples: 8384 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 524/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 524 | reduced_train_loss: 1.415 | consumed_samples: 8400 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 525/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 525 | reduced_train_loss: 1.402 | consumed_samples: 8416 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 526/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 526 | reduced_train_loss: 1.335 | consumed_samples: 8432 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 527/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 527 | reduced_train_loss: 1.632 | consumed_samples: 8448 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 528/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 528 | reduced_train_loss: 1.521 | consumed_samples: 8464 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 529/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 529 | reduced_train_loss: 1.699 | consumed_samples: 8480 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 530/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 530 | reduced_train_loss: 1.69 | consumed_samples: 8496 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 531/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 531 | reduced_train_loss: 1.592 | consumed_samples: 8512 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 532/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 532 | reduced_train_loss: 1.544 | consumed_samples: 8528 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 533/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 533 | reduced_train_loss: 1.544 | consumed_samples: 8544 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 534/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 534 | reduced_train_loss: 1.549 | consumed_samples: 8560 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 535/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 535 | reduced_train_loss: 1.47 | consumed_samples: 8576 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 536/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 536 | reduced_train_loss: 1.887 | consumed_samples: 8592 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 537/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 537 | reduced_train_loss: 1.414 | consumed_samples: 8608 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 538/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 538 | reduced_train_loss: 1.443 | consumed_samples: 8624 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 539/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 539 | reduced_train_loss: 1.58 | consumed_samples: 8640 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 540/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 540 | reduced_train_loss: 1.527 | consumed_samples: 8656 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 541/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 541 | reduced_train_loss: 1.431 | consumed_samples: 8672 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 542/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 542 | reduced_train_loss: 1.391 | consumed_samples: 8688 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 543/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 543 | reduced_train_loss: 1.438 | consumed_samples: 8704 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 544/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 544 | reduced_train_loss: 1.564 | consumed_samples: 8720 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 545/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 545 | reduced_train_loss: 1.714 | consumed_samples: 8736 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 546/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 546 | reduced_train_loss: 1.21 | consumed_samples: 8752 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 547/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 547 | reduced_train_loss: 1.41 | consumed_samples: 8768 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 548/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 548 | reduced_train_loss: 1.651 | consumed_samples: 8784 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 549/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 549 | reduced_train_loss: 1.368 | consumed_samples: 8800 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 550/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 550 | reduced_train_loss: 2.036 | consumed_samples: 8816 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 551/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 551 | reduced_train_loss: 1.669 | consumed_samples: 8832 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 552/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 552 | reduced_train_loss: 1.393 | consumed_samples: 8848 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 553/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 553 | reduced_train_loss: 1.481 | consumed_samples: 8864 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 554/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 554 | reduced_train_loss: 1.584 | consumed_samples: 8880 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 555/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 555 | reduced_train_loss: 1.348 | consumed_samples: 8896 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 556/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 556 | reduced_train_loss: 1.386 | consumed_samples: 8912 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 557/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 557 | reduced_train_loss: 1.443 | consumed_samples: 8928 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 558/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 558 | reduced_train_loss: 1.467 | consumed_samples: 8944 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 559/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 559 | reduced_train_loss: 1.586 | consumed_samples: 8960 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 560/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 560 | reduced_train_loss: 1.797 | consumed_samples: 8976 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 561/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 561 | reduced_train_loss: 1.526 | consumed_samples: 8992 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 562/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 562 | reduced_train_loss: 1.243 | consumed_samples: 9008 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 563/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 563 | reduced_train_loss: 1.401 | consumed_samples: 9024 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 564/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 564 | reduced_train_loss: 1.274 | consumed_samples: 9040 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 565/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 565 | reduced_train_loss: 1.495 | consumed_samples: 9056 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 566/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 566 | reduced_train_loss: 2.066 | consumed_samples: 9072 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 567/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 567 | reduced_train_loss: 1.803 | consumed_samples: 9088 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 568/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 568 | reduced_train_loss: 1.366 | consumed_samples: 9104 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 569/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 569 | reduced_train_loss: 1.457 | consumed_samples: 9120 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 570/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 570 | reduced_train_loss: 1.265 | consumed_samples: 9136 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 571/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 571 | reduced_train_loss: 1.75 | consumed_samples: 9152 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 572/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 572 | reduced_train_loss: 1.889 | consumed_samples: 9168 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 573/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 573 | reduced_train_loss: 1.385 | consumed_samples: 9184 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 574/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 574 | reduced_train_loss: 1.745 | consumed_samples: 9200 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 575/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 575 | reduced_train_loss: 1.598 | consumed_samples: 9216 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 576/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 576 | reduced_train_loss: 1.403 | consumed_samples: 9232 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 577/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 577 | reduced_train_loss: 1.125 | consumed_samples: 9248 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 578/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 578 | reduced_train_loss: 1.62 | consumed_samples: 9264 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 579/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 579 | reduced_train_loss: 1.671 | consumed_samples: 9280 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 580/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 580 | reduced_train_loss: 1.369 | consumed_samples: 9296 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 581/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 581 | reduced_train_loss: 1.262 | consumed_samples: 9312 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 582/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 582 | reduced_train_loss: 1.435 | consumed_samples: 9328 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 583/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 583 | reduced_train_loss: 1.515 | consumed_samples: 9344 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 584/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 584 | reduced_train_loss: 1.686 | consumed_samples: 9360 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 585/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 585 | reduced_train_loss: 1.387 | consumed_samples: 9376 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 586/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 586 | reduced_train_loss: 1.278 | consumed_samples: 9392 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 587/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 587 | reduced_train_loss: 1.711 | consumed_samples: 9408 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 588/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 588 | reduced_train_loss: 1.42 | consumed_samples: 9424 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 589/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 589 | reduced_train_loss: 1.596 | consumed_samples: 9440 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 590/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 590 | reduced_train_loss: 1.633 | consumed_samples: 9456 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 591/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 591 | reduced_train_loss: 1.534 | consumed_samples: 9472 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 592/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 592 | reduced_train_loss: 1.257 | consumed_samples: 9488 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 593/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 593 | reduced_train_loss: 1.498 | consumed_samples: 9504 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 594/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 594 | reduced_train_loss: 1.613 | consumed_samples: 9520 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 595/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 595 | reduced_train_loss: 1.484 | consumed_samples: 9536 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 596/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 596 | reduced_train_loss: 1.379 | consumed_samples: 9552 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 597/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 597 | reduced_train_loss: 1.747 | consumed_samples: 9568 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 598/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 598 | reduced_train_loss: 1.197 | consumed_samples: 9584 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Epoch 0, global step 599: 'reduced_train_loss' was not in top 1\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 599/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 599 | reduced_train_loss: 1.648 | consumed_samples: 9600 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 599 : Start time: 1754360654.677s : Save duration: 0.683s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.6483-epoch=0-consumed_samples=9600.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 600/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 600 | reduced_train_loss: 1.76 | consumed_samples: 9616 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Successfully saved checkpoint from iteration     599 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.6483-epoch=0-consumed_samples=9600.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Async checkpoint save for step 600 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.6483-epoch=0-consumed_samples=9600.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:24:15 nemo_logging:393] Async finalization time took 0.063 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 601/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 601 | reduced_train_loss: 1.246 | consumed_samples: 9632 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 602/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 602 | reduced_train_loss: 1.533 | consumed_samples: 9648 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 603/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 603 | reduced_train_loss: 1.488 | consumed_samples: 9664 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 604/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 604 | reduced_train_loss: 1.48 | consumed_samples: 9680 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 605/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 605 | reduced_train_loss: 1.741 | consumed_samples: 9696 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 606/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 606 | reduced_train_loss: 1.473 | consumed_samples: 9712 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 607/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 607 | reduced_train_loss: 1.574 | consumed_samples: 9728 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 608/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 608 | reduced_train_loss: 1.457 | consumed_samples: 9744 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 609/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 609 | reduced_train_loss: 1.369 | consumed_samples: 9760 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 610/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 610 | reduced_train_loss: 1.704 | consumed_samples: 9776 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 611/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 611 | reduced_train_loss: 1.409 | consumed_samples: 9792 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 612/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 612 | reduced_train_loss: 1.46 | consumed_samples: 9808 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 613/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 613 | reduced_train_loss: 1.356 | consumed_samples: 9824 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 614/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 614 | reduced_train_loss: 1.43 | consumed_samples: 9840 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 615/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 615 | reduced_train_loss: 1.829 | consumed_samples: 9856 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 616/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 616 | reduced_train_loss: 1.507 | consumed_samples: 9872 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 617/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 617 | reduced_train_loss: 1.809 | consumed_samples: 9888 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 618/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 618 | reduced_train_loss: 1.763 | consumed_samples: 9904 | val_loss: 1.488i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 619/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 619 | reduced_train_loss: 1.642 | consumed_samples: 9920 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 620/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 620 | reduced_train_loss: 1.329 | consumed_samples: 9936 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 621/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 621 | reduced_train_loss: 1.1 | consumed_samples: 9952 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 622/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 622 | reduced_train_loss: 1.714 | consumed_samples: 9968 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 623/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 623 | reduced_train_loss: 1.813 | consumed_samples: 9984 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 624/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 624 | reduced_train_loss: 1.289 | consumed_samples: 10000 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 625/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 625 | reduced_train_loss: 1.453 | consumed_samples: 10016 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 626/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 626 | reduced_train_loss: 1.578 | consumed_samples: 10032 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 627/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 627 | reduced_train_loss: 1.091 | consumed_samples: 10048 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 628/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 628 | reduced_train_loss: 1.45 | consumed_samples: 10064 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 629/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 629 | reduced_train_loss: 1.727 | consumed_samples: 10080 | val_loss: 1.49\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 630/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 630 | reduced_train_loss: 1.408 | consumed_samples: 10096 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 631/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 631 | reduced_train_loss: 1.516 | consumed_samples: 10112 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 632/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 632 | reduced_train_loss: 1.483 | consumed_samples: 10128 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 633/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 633 | reduced_train_loss: 1.35 | consumed_samples: 10144 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 634/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 634 | reduced_train_loss: 1.601 | consumed_samples: 10160 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 635/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 635 | reduced_train_loss: 1.266 | consumed_samples: 10176 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 636/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 636 | reduced_train_loss: 1.346 | consumed_samples: 10192 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 637/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 637 | reduced_train_loss: 1.676 | consumed_samples: 10208 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 638/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 638 | reduced_train_loss: 1.348 | consumed_samples: 10224 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 639/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 639 | reduced_train_loss: 1.359 | consumed_samples: 10240 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 640/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 640 | reduced_train_loss: 1.474 | consumed_samples: 10256 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 641/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 641 | reduced_train_loss: 1.492 | consumed_samples: 10272 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 642/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 642 | reduced_train_loss: 1.557 | consumed_samples: 10288 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 643/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 643 | reduced_train_loss: 1.366 | consumed_samples: 10304 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 644/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 644 | reduced_train_loss: 1.567 | consumed_samples: 10320 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 645/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 645 | reduced_train_loss: 1.533 | consumed_samples: 10336 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 646/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 646 | reduced_train_loss: 1.438 | consumed_samples: 10352 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 647/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 647 | reduced_train_loss: 1.561 | consumed_samples: 10368 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 648/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 648 | reduced_train_loss: 1.518 | consumed_samples: 10384 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 649/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 649 | reduced_train_loss: 1.305 | consumed_samples: 10400 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 650/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 650 | reduced_train_loss: 1.469 | consumed_samples: 10416 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 651/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 651 | reduced_train_loss: 1.391 | consumed_samples: 10432 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 652/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 652 | reduced_train_loss: 1.577 | consumed_samples: 10448 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 653/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 653 | reduced_train_loss: 1.287 | consumed_samples: 10464 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 654/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 654 | reduced_train_loss: 1.632 | consumed_samples: 10480 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 655/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 655 | reduced_train_loss: 1.625 | consumed_samples: 10496 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 656/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 656 | reduced_train_loss: 1.476 | consumed_samples: 10512 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 657/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 657 | reduced_train_loss: 1.82 | consumed_samples: 10528 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 658/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 658 | reduced_train_loss: 1.635 | consumed_samples: 10544 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 659/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 659 | reduced_train_loss: 1.289 | consumed_samples: 10560 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 660/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 660 | reduced_train_loss: 1.572 | consumed_samples: 10576 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 661/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 661 | reduced_train_loss: 1.458 | consumed_samples: 10592 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 662/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 662 | reduced_train_loss: 1.775 | consumed_samples: 10608 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 663/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 663 | reduced_train_loss: 1.274 | consumed_samples: 10624 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 664/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 664 | reduced_train_loss: 0.9939 | consumed_samples: 10640 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 665/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 665 | reduced_train_loss: 1.653 | consumed_samples: 10656 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 666/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 666 | reduced_train_loss: 1.394 | consumed_samples: 10672 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 667/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 667 | reduced_train_loss: 1.591 | consumed_samples: 10688 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 668/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 668 | reduced_train_loss: 1.677 | consumed_samples: 10704 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 669/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 669 | reduced_train_loss: 1.531 | consumed_samples: 10720 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 670/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 670 | reduced_train_loss: 1.613 | consumed_samples: 10736 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 671/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 671 | reduced_train_loss: 1.635 | consumed_samples: 10752 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 672/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 672 | reduced_train_loss: 1.385 | consumed_samples: 10768 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 673/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 673 | reduced_train_loss: 1.324 | consumed_samples: 10784 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 674/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 674 | reduced_train_loss: 1.325 | consumed_samples: 10800 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 675/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 675 | reduced_train_loss: 1.15 | consumed_samples: 10816 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 676/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 676 | reduced_train_loss: 1.407 | consumed_samples: 10832 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 677/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 677 | reduced_train_loss: 1.707 | consumed_samples: 10848 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 678/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 678 | reduced_train_loss: 1.786 | consumed_samples: 10864 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 679/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 679 | reduced_train_loss: 1.884 | consumed_samples: 10880 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 680/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 680 | reduced_train_loss: 1.574 | consumed_samples: 10896 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 681/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 681 | reduced_train_loss: 1.4 | consumed_samples: 10912 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 682/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 682 | reduced_train_loss: 1.566 | consumed_samples: 10928 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 683/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 683 | reduced_train_loss: 1.241 | consumed_samples: 10944 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 684/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 684 | reduced_train_loss: 1.608 | consumed_samples: 10960 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 685/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 685 | reduced_train_loss: 1.263 | consumed_samples: 10976 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 686/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 686 | reduced_train_loss: 1.38 | consumed_samples: 10992 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 687/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 687 | reduced_train_loss: 1.357 | consumed_samples: 11008 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 688/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 688 | reduced_train_loss: 1.545 | consumed_samples: 11024 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 689/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 689 | reduced_train_loss: 1.462 | consumed_samples: 11040 | val_loss: 1.492\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 690/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 690 | reduced_train_loss: 1.686 | consumed_samples: 11056 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 691/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 691 | reduced_train_loss: 1.273 | consumed_samples: 11072 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 692/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 692 | reduced_train_loss: 1.611 | consumed_samples: 11088 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 693/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 693 | reduced_train_loss: 1.748 | consumed_samples: 11104 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 694/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 694 | reduced_train_loss: 1.601 | consumed_samples: 11120 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 695/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 695 | reduced_train_loss: 1.348 | consumed_samples: 11136 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 696/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 696 | reduced_train_loss: 1.483 | consumed_samples: 11152 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 697/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 697 | reduced_train_loss: 1.307 | consumed_samples: 11168 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 698/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 698 | reduced_train_loss: 1.2 | consumed_samples: 11184 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 699/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 699 | reduced_train_loss: 1.614 | consumed_samples: 11200 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 700/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 700 | reduced_train_loss: 1.764 | consumed_samples: 11216 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 701/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 701 | reduced_train_loss: 1.733 | consumed_samples: 11232 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 702/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 702 | reduced_train_loss: 1.382 | consumed_samples: 11248 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 703/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 703 | reduced_train_loss: 1.19 | consumed_samples: 11264 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 704/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 704 | reduced_train_loss: 1.836 | consumed_samples: 11280 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 705/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 705 | reduced_train_loss: 1.599 | consumed_samples: 11296 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 706/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 706 | reduced_train_loss: 1.429 | consumed_samples: 11312 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 707/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 707 | reduced_train_loss: 1.176 | consumed_samples: 11328 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 708/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 708 | reduced_train_loss: 1.388 | consumed_samples: 11344 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 709/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 709 | reduced_train_loss: 1.603 | consumed_samples: 11360 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 710/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 710 | reduced_train_loss: 1.248 | consumed_samples: 11376 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 711/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 711 | reduced_train_loss: 1.52 | consumed_samples: 11392 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 712/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 712 | reduced_train_loss: 1.641 | consumed_samples: 11408 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 713/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 713 | reduced_train_loss: 1.507 | consumed_samples: 11424 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 714/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 714 | reduced_train_loss: 1.455 | consumed_samples: 11440 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 715/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 715 | reduced_train_loss: 1.391 | consumed_samples: 11456 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 716/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 716 | reduced_train_loss: 1.552 | consumed_samples: 11472 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 717/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 717 | reduced_train_loss: 1.322 | consumed_samples: 11488 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 718/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 718 | reduced_train_loss: 1.43 | consumed_samples: 11504 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 719/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 719 | reduced_train_loss: 1.531 | consumed_samples: 11520 | val_loss: 1.5\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 720/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 720 | reduced_train_loss: 1.558 | consumed_samples: 11536 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 721/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 721 | reduced_train_loss: 1.418 | consumed_samples: 11552 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 722/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 722 | reduced_train_loss: 1.9 | consumed_samples: 11568 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 723/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 723 | reduced_train_loss: 1.192 | consumed_samples: 11584 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 724/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 724 | reduced_train_loss: 1.647 | consumed_samples: 11600 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 725/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 725 | reduced_train_loss: 1.4 | consumed_samples: 11616 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 726/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 726 | reduced_train_loss: 1.584 | consumed_samples: 11632 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 727/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 727 | reduced_train_loss: 1.53 | consumed_samples: 11648 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 728/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 728 | reduced_train_loss: 1.772 | consumed_samples: 11664 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 729/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 729 | reduced_train_loss: 1.447 | consumed_samples: 11680 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 730/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 730 | reduced_train_loss: 1.348 | consumed_samples: 11696 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 731/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 731 | reduced_train_loss: 1.226 | consumed_samples: 11712 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 732/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 732 | reduced_train_loss: 1.336 | consumed_samples: 11728 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 733/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 733 | reduced_train_loss: 1.47 | consumed_samples: 11744 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 734/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 734 | reduced_train_loss: 1.438 | consumed_samples: 11760 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 735/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 735 | reduced_train_loss: 1.614 | consumed_samples: 11776 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 736/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 736 | reduced_train_loss: 1.448 | consumed_samples: 11792 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 737/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 737 | reduced_train_loss: 1.289 | consumed_samples: 11808 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 738/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 738 | reduced_train_loss: 1.457 | consumed_samples: 11824 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 739/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 739 | reduced_train_loss: 1.229 | consumed_samples: 11840 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 740/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 740 | reduced_train_loss: 1.616 | consumed_samples: 11856 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 741/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 741 | reduced_train_loss: 1.483 | consumed_samples: 11872 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 742/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 742 | reduced_train_loss: 1.629 | consumed_samples: 11888 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 743/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 743 | reduced_train_loss: 1.672 | consumed_samples: 11904 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 744/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 744 | reduced_train_loss: 1.545 | consumed_samples: 11920 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 745/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 745 | reduced_train_loss: 1.493 | consumed_samples: 11936 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 746/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 746 | reduced_train_loss: 1.296 | consumed_samples: 11952 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 747/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 747 | reduced_train_loss: 1.207 | consumed_samples: 11968 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 748/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 748 | reduced_train_loss: 1.405 | consumed_samples: 11984 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 749/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 749 | reduced_train_loss: 1.611 | consumed_samples: 12000 | val_loss: 1.509\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 750/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 750 | reduced_train_loss: 1.747 | consumed_samples: 12016 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 751/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 751 | reduced_train_loss: 1.685 | consumed_samples: 12032 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 752/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 752 | reduced_train_loss: 1.547 | consumed_samples: 12048 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 753/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 753 | reduced_train_loss: 1.86 | consumed_samples: 12064 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 754/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 754 | reduced_train_loss: 1.354 | consumed_samples: 12080 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 755/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 755 | reduced_train_loss: 1.672 | consumed_samples: 12096 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 756/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 756 | reduced_train_loss: 1.482 | consumed_samples: 12112 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 757/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 757 | reduced_train_loss: 1.84 | consumed_samples: 12128 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 758/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 758 | reduced_train_loss: 1.48 | consumed_samples: 12144 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 759/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 759 | reduced_train_loss: 1.385 | consumed_samples: 12160 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 760/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 760 | reduced_train_loss: 1.385 | consumed_samples: 12176 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 761/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 761 | reduced_train_loss: 1.566 | consumed_samples: 12192 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 762/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 762 | reduced_train_loss: 1.551 | consumed_samples: 12208 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 763/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 763 | reduced_train_loss: 1.517 | consumed_samples: 12224 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 764/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 764 | reduced_train_loss: 1.358 | consumed_samples: 12240 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 765/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 765 | reduced_train_loss: 1.389 | consumed_samples: 12256 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 766/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 766 | reduced_train_loss: 1.175 | consumed_samples: 12272 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 767/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 767 | reduced_train_loss: 1.37 | consumed_samples: 12288 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 768/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 768 | reduced_train_loss: 1.65 | consumed_samples: 12304 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 769/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 769 | reduced_train_loss: 1.517 | consumed_samples: 12320 | val_loss: 1.491\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 770/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 770 | reduced_train_loss: 1.715 | consumed_samples: 12336 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 771/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 771 | reduced_train_loss: 1.306 | consumed_samples: 12352 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 772/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 772 | reduced_train_loss: 1.624 | consumed_samples: 12368 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 773/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 773 | reduced_train_loss: 1.701 | consumed_samples: 12384 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 774/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 774 | reduced_train_loss: 1.482 | consumed_samples: 12400 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 775/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 775 | reduced_train_loss: 1.312 | consumed_samples: 12416 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 776/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 776 | reduced_train_loss: 1.364 | consumed_samples: 12432 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 777/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 777 | reduced_train_loss: 1.529 | consumed_samples: 12448 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 778/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 778 | reduced_train_loss: 1.584 | consumed_samples: 12464 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 779/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 779 | reduced_train_loss: 1.557 | consumed_samples: 12480 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 780/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 780 | reduced_train_loss: 1.396 | consumed_samples: 12496 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 781/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 781 | reduced_train_loss: 1.482 | consumed_samples: 12512 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 782/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 782 | reduced_train_loss: 1.332 | consumed_samples: 12528 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 783/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 783 | reduced_train_loss: 1.62 | consumed_samples: 12544 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 784/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 784 | reduced_train_loss: 1.424 | consumed_samples: 12560 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 785/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 785 | reduced_train_loss: 1.597 | consumed_samples: 12576 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 786/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 786 | reduced_train_loss: 1.187 | consumed_samples: 12592 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 787/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 787 | reduced_train_loss: 1.4 | consumed_samples: 12608 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 788/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 788 | reduced_train_loss: 1.917 | consumed_samples: 12624 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 789/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 789 | reduced_train_loss: 1.449 | consumed_samples: 12640 | val_loss: 1.499\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 790/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 790 | reduced_train_loss: 1.768 | consumed_samples: 12656 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 791/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 791 | reduced_train_loss: 1.756 | consumed_samples: 12672 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 792/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 792 | reduced_train_loss: 1.339 | consumed_samples: 12688 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 793/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 793 | reduced_train_loss: 1.39 | consumed_samples: 12704 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 794/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 794 | reduced_train_loss: 1.609 | consumed_samples: 12720 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 795/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 795 | reduced_train_loss: 1.305 | consumed_samples: 12736 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 796/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 796 | reduced_train_loss: 1.475 | consumed_samples: 12752 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 797/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 797 | reduced_train_loss: 1.39 | consumed_samples: 12768 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 798/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 798 | reduced_train_loss: 1.565 | consumed_samples: 12784 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 799/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 799 | reduced_train_loss: 1.82 | consumed_samples: 12800 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Epoch 0, global step 799: 'reduced_train_loss' was not in top 1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:16 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 799 : Start time: 1754360716.374s : Save duration: 0.217s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:16 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.8204-epoch=0-consumed_samples=12800.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:16 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 800/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 800 | reduced_train_loss: 1.441 | consumed_samples: 12816 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:17 nemo_logging:393] Successfully saved checkpoint from iteration     799 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.8204-epoch=0-consumed_samples=12800.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:17 nemo_logging:393] Async checkpoint save for step 800 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.8204-epoch=0-consumed_samples=12800.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:25:17 nemo_logging:393] Async finalization time took 0.087 s\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 801/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 801 | reduced_train_loss: 1.595 | consumed_samples: 12832 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 802/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 802 | reduced_train_loss: 1.621 | consumed_samples: 12848 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 803/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 803 | reduced_train_loss: 1.796 | consumed_samples: 12864 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 804/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 804 | reduced_train_loss: 1.645 | consumed_samples: 12880 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 805/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 805 | reduced_train_loss: 1.262 | consumed_samples: 12896 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 806/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 806 | reduced_train_loss: 1.766 | consumed_samples: 12912 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 807/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 807 | reduced_train_loss: 1.551 | consumed_samples: 12928 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 808/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 808 | reduced_train_loss: 1.558 | consumed_samples: 12944 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 809/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 809 | reduced_train_loss: 1.518 | consumed_samples: 12960 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 810/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 810 | reduced_train_loss: 1.606 | consumed_samples: 12976 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 811/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 811 | reduced_train_loss: 1.385 | consumed_samples: 12992 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 812/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 812 | reduced_train_loss: 1.71 | consumed_samples: 13008 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 813/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 813 | reduced_train_loss: 1.638 | consumed_samples: 13024 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 814/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 814 | reduced_train_loss: 1.698 | consumed_samples: 13040 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 815/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 815 | reduced_train_loss: 1.479 | consumed_samples: 13056 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 816/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 816 | reduced_train_loss: 1.683 | consumed_samples: 13072 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 817/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 817 | reduced_train_loss: 1.273 | consumed_samples: 13088 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 818/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 818 | reduced_train_loss: 1.456 | consumed_samples: 13104 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 819/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 819 | reduced_train_loss: 1.761 | consumed_samples: 13120 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 820/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 820 | reduced_train_loss: 1.308 | consumed_samples: 13136 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 821/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 821 | reduced_train_loss: 1.371 | consumed_samples: 13152 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 822/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 822 | reduced_train_loss: 1.629 | consumed_samples: 13168 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 823/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 823 | reduced_train_loss: 1.673 | consumed_samples: 13184 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 824/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 824 | reduced_train_loss: 1.587 | consumed_samples: 13200 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 825/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 825 | reduced_train_loss: 1.68 | consumed_samples: 13216 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 826/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 826 | reduced_train_loss: 1.624 | consumed_samples: 13232 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 827/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 827 | reduced_train_loss: 1.452 | consumed_samples: 13248 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 828/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 828 | reduced_train_loss: 1.187 | consumed_samples: 13264 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 829/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 829 | reduced_train_loss: 1.493 | consumed_samples: 13280 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 830/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 830 | reduced_train_loss: 1.44 | consumed_samples: 13296 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 831/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 831 | reduced_train_loss: 1.696 | consumed_samples: 13312 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 832/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 832 | reduced_train_loss: 1.44 | consumed_samples: 13328 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 833/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 833 | reduced_train_loss: 1.474 | consumed_samples: 13344 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 834/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 834 | reduced_train_loss: 1.338 | consumed_samples: 13360 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 835/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 835 | reduced_train_loss: 1.822 | consumed_samples: 13376 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 836/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 836 | reduced_train_loss: 1.552 | consumed_samples: 13392 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 837/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 837 | reduced_train_loss: 1.574 | consumed_samples: 13408 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 838/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 838 | reduced_train_loss: 1.534 | consumed_samples: 13424 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 839/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 839 | reduced_train_loss: 1.221 | consumed_samples: 13440 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 840/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 840 | reduced_train_loss: 1.606 | consumed_samples: 13456 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 841/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 841 | reduced_train_loss: 1.342 | consumed_samples: 13472 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 842/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 842 | reduced_train_loss: 1.66 | consumed_samples: 13488 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 843/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 843 | reduced_train_loss: 1.487 | consumed_samples: 13504 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 844/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 844 | reduced_train_loss: 1.096 | consumed_samples: 13520 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 845/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 845 | reduced_train_loss: 1.452 | consumed_samples: 13536 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 846/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 846 | reduced_train_loss: 1.596 | consumed_samples: 13552 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 847/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 847 | reduced_train_loss: 1.47 | consumed_samples: 13568 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 848/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 848 | reduced_train_loss: 1.761 | consumed_samples: 13584 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 849/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 849 | reduced_train_loss: 1.592 | consumed_samples: 13600 | val_loss: 1.502\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 850/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 850 | reduced_train_loss: 1.667 | consumed_samples: 13616 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 851/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 851 | reduced_train_loss: 1.528 | consumed_samples: 13632 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 852/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 852 | reduced_train_loss: 1.373 | consumed_samples: 13648 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 853/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 853 | reduced_train_loss: 1.463 | consumed_samples: 13664 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 854/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 854 | reduced_train_loss: 1.669 | consumed_samples: 13680 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 855/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 855 | reduced_train_loss: 1.629 | consumed_samples: 13696 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 856/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 856 | reduced_train_loss: 1.48 | consumed_samples: 13712 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 857/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 857 | reduced_train_loss: 1.882 | consumed_samples: 13728 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 858/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 858 | reduced_train_loss: 1.898 | consumed_samples: 13744 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 859/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 859 | reduced_train_loss: 1.63 | consumed_samples: 13760 | val_loss: 1.504\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 860/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 860 | reduced_train_loss: 1.486 | consumed_samples: 13776 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 861/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 861 | reduced_train_loss: 1.673 | consumed_samples: 13792 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 862/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 862 | reduced_train_loss: 1.223 | consumed_samples: 13808 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 863/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 863 | reduced_train_loss: 1.531 | consumed_samples: 13824 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 864/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 864 | reduced_train_loss: 1.328 | consumed_samples: 13840 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 865/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 865 | reduced_train_loss: 1.455 | consumed_samples: 13856 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 866/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 866 | reduced_train_loss: 1.41 | consumed_samples: 13872 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 867/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 867 | reduced_train_loss: 1.409 | consumed_samples: 13888 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 868/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 868 | reduced_train_loss: 1.334 | consumed_samples: 13904 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 869/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 869 | reduced_train_loss: 1.688 | consumed_samples: 13920 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 870/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 870 | reduced_train_loss: 1.318 | consumed_samples: 13936 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 871/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 871 | reduced_train_loss: 1.552 | consumed_samples: 13952 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 872/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 872 | reduced_train_loss: 1.5 | consumed_samples: 13968 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 873/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 873 | reduced_train_loss: 1.489 | consumed_samples: 13984 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 874/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 874 | reduced_train_loss: 1.239 | consumed_samples: 14000 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 875/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 875 | reduced_train_loss: 1.327 | consumed_samples: 14016 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 876/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 876 | reduced_train_loss: 1.432 | consumed_samples: 14032 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 877/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 877 | reduced_train_loss: 1.729 | consumed_samples: 14048 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 878/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 878 | reduced_train_loss: 1.288 | consumed_samples: 14064 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 879/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 879 | reduced_train_loss: 1.584 | consumed_samples: 14080 | val_loss: 1.493\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 880/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 880 | reduced_train_loss: 1.356 | consumed_samples: 14096 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 881/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 881 | reduced_train_loss: 1.349 | consumed_samples: 14112 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 882/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 882 | reduced_train_loss: 1.814 | consumed_samples: 14128 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 883/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 883 | reduced_train_loss: 1.657 | consumed_samples: 14144 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 884/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 884 | reduced_train_loss: 1.493 | consumed_samples: 14160 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 885/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 885 | reduced_train_loss: 1.385 | consumed_samples: 14176 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 886/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 886 | reduced_train_loss: 1.624 | consumed_samples: 14192 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 887/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 887 | reduced_train_loss: 1.577 | consumed_samples: 14208 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 888/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 888 | reduced_train_loss: 1.303 | consumed_samples: 14224 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 889/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 889 | reduced_train_loss: 1.499 | consumed_samples: 14240 | val_loss: 1.496\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 890/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 890 | reduced_train_loss: 1.651 | consumed_samples: 14256 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 891/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 891 | reduced_train_loss: 1.553 | consumed_samples: 14272 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 892/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 892 | reduced_train_loss: 1.343 | consumed_samples: 14288 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 893/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 893 | reduced_train_loss: 1.501 | consumed_samples: 14304 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 894/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 894 | reduced_train_loss: 1.689 | consumed_samples: 14320 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 895/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 895 | reduced_train_loss: 1.678 | consumed_samples: 14336 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 896/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 896 | reduced_train_loss: 1.414 | consumed_samples: 14352 | val_loss: 1.494i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 897/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 897 | reduced_train_loss: 1.608 | consumed_samples: 14368 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 898/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 898 | reduced_train_loss: 1.327 | consumed_samples: 14384 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 899/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 899 | reduced_train_loss: 1.44 | consumed_samples: 14400 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 900/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 900 | reduced_train_loss: 1.265 | consumed_samples: 14416 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 901/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 901 | reduced_train_loss: 1.346 | consumed_samples: 14432 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 902/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 902 | reduced_train_loss: 1.583 | consumed_samples: 14448 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 903/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 903 | reduced_train_loss: 1.505 | consumed_samples: 14464 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 904/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 904 | reduced_train_loss: 1.52 | consumed_samples: 14480 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 905/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 905 | reduced_train_loss: 1.731 | consumed_samples: 14496 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 906/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 906 | reduced_train_loss: 1.259 | consumed_samples: 14512 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 907/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 907 | reduced_train_loss: 1.537 | consumed_samples: 14528 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 908/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 908 | reduced_train_loss: 1.445 | consumed_samples: 14544 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 909/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 909 | reduced_train_loss: 1.439 | consumed_samples: 14560 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 910/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 910 | reduced_train_loss: 1.604 | consumed_samples: 14576 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 911/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 911 | reduced_train_loss: 1.356 | consumed_samples: 14592 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 912/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 912 | reduced_train_loss: 1.289 | consumed_samples: 14608 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 913/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 913 | reduced_train_loss: 1.755 | consumed_samples: 14624 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 914/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 914 | reduced_train_loss: 1.275 | consumed_samples: 14640 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 915/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 915 | reduced_train_loss: 1.525 | consumed_samples: 14656 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 916/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 916 | reduced_train_loss: 1.509 | consumed_samples: 14672 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 917/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 917 | reduced_train_loss: 1.689 | consumed_samples: 14688 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 918/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 918 | reduced_train_loss: 1.381 | consumed_samples: 14704 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 919/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 919 | reduced_train_loss: 1.607 | consumed_samples: 14720 | val_loss: 1.486\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 920/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 920 | reduced_train_loss: 1.902 | consumed_samples: 14736 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 921/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 921 | reduced_train_loss: 1.33 | consumed_samples: 14752 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 922/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 922 | reduced_train_loss: 1.375 | consumed_samples: 14768 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 923/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 923 | reduced_train_loss: 1.406 | consumed_samples: 14784 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 924/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 924 | reduced_train_loss: 1.316 | consumed_samples: 14800 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 925/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 925 | reduced_train_loss: 1.392 | consumed_samples: 14816 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 926/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 926 | reduced_train_loss: 1.375 | consumed_samples: 14832 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 927/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 927 | reduced_train_loss: 1.501 | consumed_samples: 14848 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 928/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 928 | reduced_train_loss: 1.52 | consumed_samples: 14864 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 929/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 929 | reduced_train_loss: 1.458 | consumed_samples: 14880 | val_loss: 1.495\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 930/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 930 | reduced_train_loss: 1.96 | consumed_samples: 14896 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 931/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 931 | reduced_train_loss: 1.529 | consumed_samples: 14912 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 932/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 932 | reduced_train_loss: 1.306 | consumed_samples: 14928 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 933/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 933 | reduced_train_loss: 1.767 | consumed_samples: 14944 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 934/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 934 | reduced_train_loss: 1.725 | consumed_samples: 14960 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 935/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 935 | reduced_train_loss: 1.551 | consumed_samples: 14976 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 936/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 936 | reduced_train_loss: 1.685 | consumed_samples: 14992 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 937/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 937 | reduced_train_loss: 1.315 | consumed_samples: 15008 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 938/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 938 | reduced_train_loss: 1.473 | consumed_samples: 15024 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 939/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 939 | reduced_train_loss: 1.766 | consumed_samples: 15040 | val_loss: 1.488\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 940/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 940 | reduced_train_loss: 1.463 | consumed_samples: 15056 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 941/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 941 | reduced_train_loss: 1.505 | consumed_samples: 15072 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 942/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 942 | reduced_train_loss: 1.447 | consumed_samples: 15088 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 943/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 943 | reduced_train_loss: 1.349 | consumed_samples: 15104 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 944/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 944 | reduced_train_loss: 1.409 | consumed_samples: 15120 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 945/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 945 | reduced_train_loss: 1.486 | consumed_samples: 15136 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 946/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 946 | reduced_train_loss: 1.632 | consumed_samples: 15152 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 947/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 947 | reduced_train_loss: 1.246 | consumed_samples: 15168 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 948/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 948 | reduced_train_loss: 1.267 | consumed_samples: 15184 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 949/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 949 | reduced_train_loss: 1.566 | consumed_samples: 15200 | val_loss: 1.484\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 950/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 950 | reduced_train_loss: 1.266 | consumed_samples: 15216 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 951/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 951 | reduced_train_loss: 1.402 | consumed_samples: 15232 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 952/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 952 | reduced_train_loss: 1.527 | consumed_samples: 15248 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 953/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 953 | reduced_train_loss: 1.632 | consumed_samples: 15264 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 954/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 954 | reduced_train_loss: 1.457 | consumed_samples: 15280 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 955/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 955 | reduced_train_loss: 1.138 | consumed_samples: 15296 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 956/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 956 | reduced_train_loss: 1.47 | consumed_samples: 15312 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 957/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 957 | reduced_train_loss: 1.467 | consumed_samples: 15328 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 958/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 958 | reduced_train_loss: 1.879 | consumed_samples: 15344 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 959/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 959 | reduced_train_loss: 1.42 | consumed_samples: 15360 | val_loss: 1.487\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 960/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 960 | reduced_train_loss: 1.592 | consumed_samples: 15376 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 961/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 961 | reduced_train_loss: 2.0 | consumed_samples: 15392 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 962/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 962 | reduced_train_loss: 1.334 | consumed_samples: 15408 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 963/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 963 | reduced_train_loss: 1.448 | consumed_samples: 15424 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 964/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 964 | reduced_train_loss: 1.587 | consumed_samples: 15440 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 965/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 965 | reduced_train_loss: 1.758 | consumed_samples: 15456 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 966/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 966 | reduced_train_loss: 1.402 | consumed_samples: 15472 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 967/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 967 | reduced_train_loss: 1.757 | consumed_samples: 15488 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 968/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 968 | reduced_train_loss: 1.518 | consumed_samples: 15504 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 969/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 969 | reduced_train_loss: 1.502 | consumed_samples: 15520 | val_loss: 1.485\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 970/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 970 | reduced_train_loss: 1.37 | consumed_samples: 15536 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 971/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 971 | reduced_train_loss: 1.669 | consumed_samples: 15552 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 972/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 972 | reduced_train_loss: 1.563 | consumed_samples: 15568 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 973/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 973 | reduced_train_loss: 1.59 | consumed_samples: 15584 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 974/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 974 | reduced_train_loss: 1.854 | consumed_samples: 15600 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 975/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 975 | reduced_train_loss: 1.763 | consumed_samples: 15616 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 976/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 976 | reduced_train_loss: 1.229 | consumed_samples: 15632 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 977/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 977 | reduced_train_loss: 1.556 | consumed_samples: 15648 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 978/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 978 | reduced_train_loss: 1.533 | consumed_samples: 15664 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 979/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 979 | reduced_train_loss: 1.375 | consumed_samples: 15680 | val_loss: 1.489\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 980/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 980 | reduced_train_loss: 1.488 | consumed_samples: 15696 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 981/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 981 | reduced_train_loss: 1.411 | consumed_samples: 15712 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 982/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 982 | reduced_train_loss: 1.173 | consumed_samples: 15728 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 983/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 983 | reduced_train_loss: 1.324 | consumed_samples: 15744 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 984/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 984 | reduced_train_loss: 1.535 | consumed_samples: 15760 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 985/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 985 | reduced_train_loss: 1.575 | consumed_samples: 15776 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 986/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 986 | reduced_train_loss: 1.213 | consumed_samples: 15792 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 987/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 987 | reduced_train_loss: 1.591 | consumed_samples: 15808 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 988/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 988 | reduced_train_loss: 1.736 | consumed_samples: 15824 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 989/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 989 | reduced_train_loss: 1.226 | consumed_samples: 15840 | val_loss: 1.494\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 990/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 990 | reduced_train_loss: 1.52 | consumed_samples: 15856 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 991/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 991 | reduced_train_loss: 1.246 | consumed_samples: 15872 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 992/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 992 | reduced_train_loss: 1.648 | consumed_samples: 15888 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 993/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 993 | reduced_train_loss: 1.725 | consumed_samples: 15904 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 994/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 994 | reduced_train_loss: 1.545 | consumed_samples: 15920 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 995/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 995 | reduced_train_loss: 1.459 | consumed_samples: 15936 | val_loss: 1.497i.finetune/0 [default0]:\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 996/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 996 | reduced_train_loss: 1.419 | consumed_samples: 15952 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 997/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 997 | reduced_train_loss: 1.541 | consumed_samples: 15968 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 998/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 998 | reduced_train_loss: 1.541 | consumed_samples: 15984 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Training epoch 0, iteration 999/999 | lr: 1e-05 | global_batch_size: 16 | global_step: 999 | reduced_train_loss: 1.305 | consumed_samples: 16000 | val_loss: 1.497\n",
      "i.finetune/0 [default0]:Epoch 0, global step 999: 'reduced_train_loss' was not in top 1\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Global Checkpoint Save : Rank: 0 : Iteration: 999 : Start time: 1754360781.053s : Save duration: 0.216s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Scheduled async checkpoint save for /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.3045-epoch=0-consumed_samples=16000.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Async finalization time took 0.001 s\n",
      "i.finetune/0 [default0]:Validation: iteration 1/2\n",
      "i.finetune/0 [default0]:Validation: iteration 2/2\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Async finalization time took 0.000 s\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Pending async checkpoint saves. Finalizing them synchronously now\n",
      "i.finetune/0 [default0]:`Trainer.fit` stopped: `max_steps=1000` reached.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Successfully saved checkpoint from iteration     999 to /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.3045-epoch=0-consumed_samples=16000.0-last.ckpt\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Async checkpoint save for step 1000 (/nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.3045-epoch=0-consumed_samples=16000.0-last.ckpt) finalized successfully.\n",
      "i.finetune/0 [default0]:[NeMo I 2025-08-05 02:26:21 nemo_logging:393] Async finalization time took 0.178 s\n",
      "i.finetune/0 [default0]:\u001b[1;34mwandb\u001b[0m: \n",
      "i.finetune/0 [default0]:\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mLSE_Run_1\u001b[0m at: \u001b[34mhttps://wandb.ai/IT-On-Prem-AI/NeMo2_LoRA_LSE_Example/runs/ho2i26w9\u001b[0m\n",
      "i.finetune/0 [default0]:\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35m../nemo-experiments/results/wandb/run-20250805_022032-ho2i26w9/logs\u001b[0m\n",
      "i.finetune/0 I0805 02:26:40.398000 8757 torch/distributed/elastic/agent/server/api.py:879] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "i.finetune/0 I0805 02:26:40.401000 8757 torch/distributed/elastic/agent/server/api.py:932] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "i.finetune/0 I0805 02:26:40.404000 8757 torch/distributed/elastic/agent/server/api.py:946] Done waiting for other agents. Elapsed: 0.0013799667358398438 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.finetune-lml31tqlql04pc finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.finetune']</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune_1754360413\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.finetune\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.finetune']\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune_1754360413\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.finetune\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.finetune_1754360413</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.finetune_1754360413 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.finetune_1754360413 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                              </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1754360413\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1754360413\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.finetune_1754360413\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def local_executor_torchrun(nodes: int = 1, devices: int = 2) -> run.LocalExecutor:\n",
    "    # Env vars for jobs are configured here\n",
    "    env_vars = {\n",
    "        \"TORCH_NCCL_AVOID_RECORD_STREAMS\": \"1\",\n",
    "        \"NCCL_NVLS_ENABLE\": \"0\",\n",
    "    }\n",
    "\n",
    "    executor = run.LocalExecutor(\n",
    "        ntasks_per_node=devices, launcher=\"torchrun\", env_vars=env_vars\n",
    "    )\n",
    "\n",
    "    return executor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run.run(\n",
    "        configure_finetuning_recipe(),\n",
    "        executor=local_executor_torchrun(devices=NUM_GPU_DEVICES),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4. Run In-Framework Generation\n",
    "\n",
    "For a sanity check, we use the `llm.generate` API in NeMo 2.0 to generate results from the trained checkpoint. Find your last saved checkpoint from your experiment `results` dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will load SFT checkpoint from: /nemo-experiments/results/nemo2_llama31_8b_lse_peft/checkpoints/nemo2_llama31_8b_lse_peft--reduced_train_loss=1.3045-epoch=0-consumed_samples=16000.0-last\n"
     ]
    }
   ],
   "source": [
    "sft_ckpt_path = str(\n",
    "    next(\n",
    "        (\n",
    "            d\n",
    "            for d in Path(\n",
    "                LOG_DIR + \"/\" + LOG_NAME + \"/checkpoints/\"\n",
    "            ).iterdir()\n",
    "            if d.is_dir() and d.name.endswith(\"-last\")\n",
    "        ),\n",
    "        None,\n",
    "    )\n",
    ")\n",
    "print(\"We will load SFT checkpoint from:\", sft_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the `llm.generate` API, you can provide a data module, for example: `input_dataset=lse_data()`. This will use the test set from the specified data module to generate predictions. In the example below, the generated predictions are saved to the `peft_predictions.txt` file.\n",
    "\n",
    "Generating predictions needs only 1 GPU (`tensor_model_parallel_size=1`). However, using multiple GPU devices can speed up inference.\n",
    "\n",
    "> **Note:** The following cell may take about 20 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.generate with id: nemo.collections.llm.api.generate_1754365308</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ───</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─── \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.generate with id: nemo.collections.llm.api.generate_1754365308\u001b[0m\u001b[92m ───\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.generate/nemo.collections.llm.api.generate_1754365308/nemo.collections.llm.api.generate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03:41:48] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.generate for experiment </span>                        <a href=\"file:///opt/Run/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/Run/nemo_run/run/experiment.py#771\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">771</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.generate</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03:41:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.generate for experiment \u001b[0m                        \u001b]8;id=52367;file:///opt/Run/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=808446;file:///opt/Run/nemo_run/run/experiment.py#771\u001b\\\u001b[2m771\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.generate\u001b[0m                                                      \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.generate/nemo.collections.llm.api.generate_1754365308/nemo.collections.llm.api.generate\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.generate-lkzx5v6ssdx4cc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.generate_1754365308 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.generate_1754365308 to finish\u001b[0m\u001b[92m ──────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.generate_1754365308</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.generate_1754365308\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.generate</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.generate-lkzx5v6ssdx4cc\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/nemo.collections.llm.api.generate/nemo.collections.llm.api.generate_1754365308/nemo.collections.llm.api.generate\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.generate\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.generate-lkzx5v6ssdx4cc\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/nemo.collections.llm.api.generate/nemo.collections.llm.api.generate_1754365308/nemo.collections.llm.api.generate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.generate-lkzx5v6ssdx4cc to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.generate/0 I0805 03:41:49.960000 12109 torch/distributed/run.py:649] Using nproc_per_node=4.\n",
      "i.generate/0 W0805 03:41:49.961000 12109 torch/distributed/run.py:766] \n",
      "i.generate/0 W0805 03:41:49.961000 12109 torch/distributed/run.py:766] *****************************************\n",
      "i.generate/0 W0805 03:41:49.961000 12109 torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "i.generate/0 W0805 03:41:49.961000 12109 torch/distributed/run.py:766] *****************************************\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195] Starting elastic_operator with launch configs:\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   entrypoint       : nemo_run.core.runners.fdl_runner\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   min_nodes        : 1\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   max_nodes        : 1\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   nproc_per_node   : 4\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   run_id           : 7488\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   rdzv_backend     : c10d\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   rdzv_endpoint    : localhost:0\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   rdzv_configs     : {'timeout': 900}\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   max_restarts     : 0\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   monitor_interval : 0.1\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   log_dir          : /root/.nemo_run/experiments/nemo.collections.llm.api.generate/nemo.collections.llm.api.generate_1754365308/nemo.collections.llm.api.generate/nemo_run/nemo.collections.llm.api.generate-lkzx5v6ssdx4cc/torchelastic/nemo.collections.llm.api.generate\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195]   metrics_cfg      : {}\n",
      "i.generate/0 I0805 03:41:49.962000 12109 torch/distributed/launcher/api.py:195] \n",
      "i.generate/0 I0805 03:41:49.969000 12109 torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python\n",
      "i.generate/0 I0805 03:41:49.970000 12109 torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   restart_count=0\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   master_addr=phobos\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   master_port=40109\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   group_rank=0\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   group_world_size=1\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3]\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3]\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3]\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[4, 4, 4, 4]\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[4, 4, 4, 4]\n",
      "i.generate/0 I0805 03:41:50.202000 12109 torch/distributed/elastic/agent/server/api.py:525] \n",
      "i.generate/0 I0805 03:41:50.203000 12109 torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group\n",
      "i.generate/0 I0805 03:41:50.204000 12109 torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True\n",
      "i.generate/0 I0805 03:41:50.205000 12109 torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.\n",
      "i.generate/0 I0805 03:41:50.206000 12109 torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.\n",
      "i.generate/0 [default0]:[NeMo W 2025-08-05 03:42:01 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "i.generate/0 [default0]:      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "i.generate/0 [default0]:    \n",
      "i.generate/0 [default0]:💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "i.generate/0 [default0]:GPU available: True (cuda), used: True\n",
      "i.generate/0 [default0]:TPU available: False, using: 0 TPU cores\n",
      "i.generate/0 [default0]:HPU available: False, using: 0 HPUs\n",
      "i.generate/0 [default1]:[W805 03:42:03.002825877 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.generate/0 [default2]:[W805 03:42:03.996453878 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.generate/0 [default3]:[W805 03:42:03.982053255 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Enabling Flash Decode for in-framework inference\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has data parallel group : [0, 1, 2, 3]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0, 1, 2, 3]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0, 1, 2, 3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All context parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All tensor model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All pipeline model parallel group ranks: [[0], [1], [2], [3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] All embedding group ranks: [[0], [1], [2], [3]]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "i.generate/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default0]:[W805 03:42:03.182836894 ProcessGroupNCCL.cpp:959] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "i.generate/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.generate/0 [default0]:distributed_backend=nccl\n",
      "i.generate/0 [default0]:All distributed processes registered. Starting with 4 processes\n",
      "i.generate/0 [default0]:----------------------------------------------------------------------------------------------------\n",
      "i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:03 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "i.generate/0 [default1]:[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default2]:[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default3]:[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:04 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:04 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:04 nemo_logging:393] Doing selective restore from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:04 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x720b06d0ff20> dist-ckpt load strategy.\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1754365324.435s : Time spent in load_checkpoint: 6.036s\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Restoring model weights from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Finished restoring from RestoreConfig(path='/nemo-experiments/models/meta-llama/Llama-3.1-8B', load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.0.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.1.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.2.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.3.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.4.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.5.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.6.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.7.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.8.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.9.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.10.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.11.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.12.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.13.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.14.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.15.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.16.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.17.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.18.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.19.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.20.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.21.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.22.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.23.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.24.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.25.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.26.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.27.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.28.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.29.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.30.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.self_attention.linear_proj\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.self_attention.linear_qkv\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.mlp.linear_fc1\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Adding lora to: module.module.decoder.layers.31.mlp.linear_fc2\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x720b0613b290> dist-ckpt load strategy.\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 03:42:10 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1754365330.582s : Time spent in load_checkpoint: 0.176s\n",
      "i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   0%|          | 0/305 [00:00<?, ?it/s][default2]:\n",
      "i.generate/0 [default2]:static requests:   0%|          | 0/305 [00:00<?, ?it/s][default3]:\n",
      "i.generate/0 [default3]:static requests:   0%|          | 0/304 [00:00<?, ?it/s]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   0%|          | 0/305 [00:00<?, ?it/s]i.generate/0 [default0]:[WARNING  | DotProductAttention]: flash-attn v3 may provide important feature support or performance improvement. Please install flash-attn v3 by \n",
      "i.generate/0 [default0]:(1) git clone https://github.com/Dao-AILab/flash-attention.git\n",
      "i.generate/0 [default0]:(2) cd flash-attention/ && git checkout 27f501d && cd hopper/ && python setup.py install\n",
      "i.generate/0 [default0]:(3) python_path=`python -c \"import site; print(site.getsitepackages()[0])\"`\n",
      "i.generate/0 [default0]:(4) mkdir -p $python_path/flash_attn_3\n",
      "i.generate/0 [default0]:(5) wget -P $python_path/flash_attn_3 https://raw.githubusercontent.com/Dao-AILab/flash-attention/27f501dbe011f4371bff938fe7e09311ab3002fa/hopper/flash_attn_interface.py\n",
      "i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   1%|▏         | 4/305 [00:09<12:05,  2.41s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   1%|▏         | 4/304 [00:10<13:43,  2.74s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   1%|▏         | 4/305 [00:12<15:03,  3.00s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   1%|▏         | 4/305 [00:17<22:32,  4.49s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   3%|▎         | 8/305 [00:19<11:52,  2.40s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   3%|▎         | 8/305 [00:24<15:26,  3.12s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   4%|▍         | 12/305 [00:26<09:06,  1.86s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   3%|▎         | 8/305 [00:26<15:31,  3.14s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   4%|▍         | 12/305 [00:39<15:35,  3.19s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   4%|▍         | 12/305 [00:47<21:55,  4.49s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   5%|▌         | 16/305 [00:50<14:27,  3.00s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   5%|▌         | 16/305 [00:54<18:56,  3.93s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   3%|▎         | 8/304 [00:56<38:16,  7.76s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   4%|▍         | 12/304 [01:01<23:20,  4.80s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   7%|▋         | 20/305 [01:02<14:23,  3.03s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   5%|▌         | 16/305 [01:03<21:03,  4.37s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   5%|▌         | 16/304 [01:10<18:24,  3.84s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   7%|▋         | 20/305 [01:15<18:18,  3.85s/it][default3]:\n",
      "i.generate/0 [default3]:static requests:   7%|▋         | 20/304 [01:15<13:44,  2.90s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   8%|▊         | 24/305 [01:22<14:38,  3.13s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   7%|▋         | 20/305 [01:24<24:47,  5.22s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   8%|▊         | 24/304 [01:28<13:56,  2.99s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:   9%|▉         | 28/305 [01:37<15:19,  3.32s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   8%|▊         | 24/305 [01:39<23:55,  5.11s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:   9%|▉         | 28/304 [01:42<14:30,  3.15s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  10%|█         | 32/305 [01:43<12:27,  2.74s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:   9%|▉         | 28/305 [01:47<19:01,  4.12s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   8%|▊         | 24/305 [01:59<29:53,  6.38s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  12%|█▏        | 36/305 [02:01<14:49,  3.31s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  10%|█         | 32/305 [02:03<18:33,  4.08s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  11%|█         | 32/304 [02:06<18:29,  4.08s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:   9%|▉         | 28/305 [02:07<22:49,  4.94s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  13%|█▎        | 40/305 [02:19<16:13,  3.67s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  12%|█▏        | 36/304 [02:26<19:35,  4.39s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  14%|█▍        | 44/305 [02:28<14:13,  3.27s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  12%|█▏        | 36/305 [02:30<22:03,  4.92s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  13%|█▎        | 40/304 [02:32<15:28,  3.52s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  10%|█         | 32/305 [02:33<24:59,  5.49s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  14%|█▍        | 44/304 [02:37<11:56,  2.76s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  12%|█▏        | 36/305 [02:41<19:34,  4.37s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  16%|█▌        | 48/304 [02:44<10:42,  2.51s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  13%|█▎        | 40/305 [02:46<15:12,  3.44s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  13%|█▎        | 40/305 [02:53<22:36,  5.12s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  14%|█▍        | 44/305 [02:55<13:15,  3.05s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  17%|█▋        | 52/304 [02:59<12:02,  2.87s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  18%|█▊        | 56/304 [03:04<09:48,  2.37s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  16%|█▌        | 48/305 [03:06<21:52,  5.11s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  20%|█▉        | 60/304 [03:14<09:45,  2.40s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  14%|█▍        | 44/305 [03:23<25:29,  5.86s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  21%|██        | 64/304 [03:27<10:34,  2.65s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  16%|█▌        | 48/305 [03:33<20:43,  4.84s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  16%|█▌        | 48/305 [03:36<22:20,  5.22s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  22%|██▏       | 68/304 [03:40<11:17,  2.87s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  17%|█▋        | 52/305 [03:46<27:54,  6.62s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  17%|█▋        | 52/305 [03:48<19:03,  4.52s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  17%|█▋        | 52/305 [03:53<20:47,  4.93s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  18%|█▊        | 56/305 [03:56<15:33,  3.75s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  18%|█▊        | 56/305 [04:02<17:15,  4.16s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  20%|█▉        | 60/305 [04:08<14:29,  3.55s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  20%|█▉        | 60/305 [04:15<15:49,  3.88s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  18%|█▊        | 56/305 [04:17<28:52,  6.96s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  24%|██▎       | 72/304 [04:19<19:04,  4.93s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  20%|█▉        | 60/305 [04:23<21:33,  5.28s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  21%|██        | 64/305 [04:23<14:27,  3.60s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  21%|██        | 64/305 [04:28<14:45,  3.67s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  22%|██▏       | 68/305 [04:29<11:47,  2.99s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  22%|██▏       | 68/305 [04:33<11:42,  2.97s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  21%|██        | 64/305 [04:35<18:30,  4.61s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  25%|██▌       | 76/304 [04:36<17:45,  4.67s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  24%|██▎       | 72/305 [04:41<11:39,  3.00s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  24%|██▎       | 72/305 [04:42<10:38,  2.74s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  22%|██▏       | 68/305 [04:45<15:42,  3.98s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  25%|██▍       | 76/305 [04:47<09:40,  2.54s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  25%|██▍       | 76/305 [04:52<10:11,  2.67s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  26%|██▋       | 80/304 [04:54<17:16,  4.63s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  24%|██▎       | 72/305 [04:58<14:37,  3.77s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  25%|██▍       | 76/305 [05:03<11:23,  2.98s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  26%|██▌       | 80/305 [05:07<12:08,  3.24s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  28%|██▊       | 84/304 [05:14<17:24,  4.75s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  28%|██▊       | 84/305 [05:21<12:09,  3.30s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  26%|██▌       | 80/305 [05:22<15:24,  4.11s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  29%|██▉       | 88/305 [05:27<10:02,  2.77s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  26%|██▌       | 80/305 [05:30<15:30,  4.13s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  29%|██▉       | 88/304 [05:30<16:27,  4.57s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  28%|██▊       | 84/305 [05:41<15:52,  4.31s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  30%|███       | 92/304 [05:51<16:50,  4.77s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  29%|██▉       | 88/305 [05:52<13:46,  3.81s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  30%|███       | 92/305 [05:56<10:38,  3.00s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  28%|██▊       | 84/305 [05:58<18:26,  5.01s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  29%|██▉       | 88/305 [06:05<14:31,  4.02s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  32%|███▏      | 96/304 [06:06<15:30,  4.47s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  30%|███       | 92/305 [06:14<19:25,  5.47s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  33%|███▎      | 100/304 [06:15<12:56,  3.80s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  31%|███▏      | 96/305 [06:16<12:34,  3.61s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  34%|███▍      | 104/304 [06:22<10:30,  3.15s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  36%|███▌      | 108/304 [06:30<09:11,  2.82s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  33%|███▎      | 100/305 [06:30<12:09,  3.56s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  31%|███▏      | 96/305 [06:31<17:46,  5.10s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  30%|███       | 92/305 [06:34<17:39,  4.97s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  34%|███▍      | 104/305 [06:46<12:14,  3.65s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  33%|███▎      | 100/305 [06:47<16:25,  4.81s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  35%|███▌      | 108/305 [06:47<08:49,  2.69s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  37%|███▋      | 112/304 [06:50<11:10,  3.49s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  31%|███▏      | 96/305 [06:53<17:09,  4.93s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  37%|███▋      | 112/305 [07:11<11:51,  3.69s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  33%|███▎      | 100/305 [07:12<16:45,  4.90s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  38%|███▊      | 116/304 [07:23<15:24,  4.92s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  34%|███▍      | 104/305 [07:27<21:13,  6.33s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  39%|███▉      | 120/304 [07:30<12:06,  3.95s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  38%|███▊      | 116/305 [07:38<14:18,  4.54s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  41%|████      | 124/304 [07:42<10:52,  3.63s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  35%|███▌      | 108/305 [07:43<18:33,  5.65s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  39%|███▉      | 120/305 [07:47<11:53,  3.85s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  34%|███▍      | 104/305 [07:49<20:44,  6.19s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  42%|████▏     | 128/304 [07:53<10:03,  3.43s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  41%|████      | 124/305 [07:54<09:42,  3.22s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  37%|███▋      | 112/305 [07:56<15:52,  4.93s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  35%|███▌      | 108/305 [08:00<16:57,  5.16s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  43%|████▎     | 132/304 [08:02<08:39,  3.02s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  38%|███▊      | 116/305 [08:04<12:40,  4.03s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  42%|████▏     | 128/305 [08:06<09:23,  3.18s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  39%|███▉      | 120/305 [08:09<10:01,  3.25s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  43%|████▎     | 132/305 [08:18<09:07,  3.16s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  45%|████▍     | 136/304 [08:19<09:38,  3.44s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  37%|███▋      | 112/305 [08:20<16:20,  5.08s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  45%|████▍     | 136/305 [08:28<08:20,  2.96s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  46%|████▌     | 140/304 [08:33<09:26,  3.46s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  38%|███▊      | 116/305 [08:35<14:45,  4.69s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  46%|████▌     | 140/305 [08:36<07:13,  2.63s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  41%|████      | 124/305 [08:36<12:58,  4.30s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  39%|███▉      | 120/305 [08:41<11:37,  3.77s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  47%|████▋     | 144/305 [08:42<06:07,  2.28s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  47%|████▋     | 144/304 [08:43<08:17,  3.11s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  49%|████▊     | 148/305 [08:53<06:19,  2.42s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  49%|████▊     | 148/304 [08:55<08:03,  3.10s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  41%|████      | 124/305 [08:58<11:47,  3.91s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  42%|████▏     | 128/305 [09:07<09:53,  3.36s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  50%|████▉     | 152/305 [09:09<07:23,  2.90s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  42%|████▏     | 128/305 [09:10<16:17,  5.52s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  43%|████▎     | 132/305 [09:15<08:37,  2.99s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  50%|█████     | 152/304 [09:15<09:24,  3.72s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  51%|█████     | 156/305 [09:19<07:01,  2.83s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  52%|█████▏    | 160/305 [09:25<05:48,  2.40s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  54%|█████▍    | 164/305 [09:30<04:51,  2.06s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  55%|█████▌    | 168/305 [09:38<04:41,  2.06s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  45%|████▍     | 136/305 [09:47<12:37,  4.48s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  51%|█████▏    | 156/304 [09:56<13:57,  5.66s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  43%|████▎     | 132/305 [09:58<21:33,  7.48s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  56%|█████▋    | 172/305 [10:00<06:47,  3.06s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  58%|█████▊    | 176/305 [10:08<05:58,  2.78s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  53%|█████▎    | 160/304 [10:12<12:23,  5.16s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  46%|████▌     | 140/305 [10:15<14:26,  5.25s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  45%|████▍     | 136/305 [10:19<19:07,  6.79s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  54%|█████▍    | 164/304 [10:22<10:04,  4.32s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  55%|█████▌    | 168/304 [10:26<07:33,  3.33s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  59%|█████▉    | 180/305 [10:31<07:39,  3.68s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  60%|██████    | 184/305 [10:35<05:45,  2.85s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  57%|█████▋    | 172/304 [10:36<06:53,  3.14s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  46%|████▌     | 140/305 [10:38<17:01,  6.19s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  62%|██████▏   | 188/305 [10:40<04:40,  2.39s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  58%|█████▊    | 176/304 [10:55<07:34,  3.55s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  47%|████▋     | 144/305 [11:00<16:03,  5.99s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  63%|██████▎   | 192/305 [11:02<06:16,  3.33s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  49%|████▊     | 148/305 [11:03<11:34,  4.42s/it][default3]:\n",
      "i.generate/0 [default3]:static requests:  59%|█████▉    | 180/304 [11:03<06:29,  3.14s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  47%|████▋     | 144/305 [11:09<20:47,  7.75s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  50%|████▉     | 152/305 [11:10<09:13,  3.62s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  51%|█████     | 156/305 [11:17<07:37,  3.07s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  61%|██████    | 184/304 [11:23<07:23,  3.69s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  52%|█████▏    | 160/305 [11:27<06:57,  2.88s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  49%|████▊     | 148/305 [11:29<18:06,  6.92s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  50%|████▉     | 152/305 [11:33<13:07,  5.15s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  64%|██████▍   | 196/305 [11:33<08:25,  4.64s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  54%|█████▍    | 164/305 [11:38<06:41,  2.85s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  62%|██████▏   | 188/304 [11:44<07:57,  4.11s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  66%|██████▌   | 200/305 [11:44<07:08,  4.08s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  51%|█████     | 156/305 [11:49<11:53,  4.79s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  63%|██████▎   | 192/304 [12:00<07:39,  4.10s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  67%|██████▋   | 204/305 [12:00<06:45,  4.01s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  64%|██████▍   | 196/304 [12:03<05:37,  3.12s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  52%|█████▏    | 160/305 [12:10<11:48,  4.89s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  66%|██████▌   | 200/304 [12:20<05:58,  3.45s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  54%|█████▍    | 164/305 [12:24<10:33,  4.49s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  55%|█████▌    | 168/305 [12:24<12:24,  5.44s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  56%|█████▋    | 172/305 [12:29<09:13,  4.16s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  68%|██████▊   | 208/305 [12:40<09:22,  5.79s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  67%|██████▋   | 204/304 [12:42<06:44,  4.05s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  55%|█████▌    | 168/305 [12:43<10:24,  4.56s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  70%|██████▉   | 212/305 [12:47<07:08,  4.61s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  68%|██████▊   | 208/304 [12:52<05:45,  3.60s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  58%|█████▊    | 176/305 [12:53<10:12,  4.75s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  70%|██████▉   | 212/304 [13:03<05:04,  3.31s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  56%|█████▋    | 172/305 [13:04<10:35,  4.78s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  71%|███████   | 216/305 [13:09<07:11,  4.85s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  71%|███████   | 216/304 [13:14<04:38,  3.16s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  58%|█████▊    | 176/305 [13:21<09:56,  4.62s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  59%|█████▉    | 180/305 [13:24<11:44,  5.63s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  59%|█████▉    | 180/305 [13:30<08:13,  3.95s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  72%|███████▏  | 220/305 [13:34<07:31,  5.31s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  60%|██████    | 184/305 [13:39<06:47,  3.37s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  60%|██████    | 184/305 [13:40<10:21,  5.14s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  62%|██████▏   | 188/305 [13:48<06:01,  3.09s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  72%|███████▏  | 220/304 [13:51<07:01,  5.02s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  62%|██████▏   | 188/305 [13:57<09:31,  4.88s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  63%|██████▎   | 192/305 [14:00<05:42,  3.03s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  63%|██████▎   | 192/305 [14:08<07:59,  4.25s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  74%|███████▎  | 224/304 [14:13<06:48,  5.11s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  64%|██████▍   | 196/305 [14:18<06:19,  3.48s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  73%|███████▎  | 224/305 [14:21<09:48,  7.27s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  75%|███████▌  | 228/304 [14:28<06:00,  4.74s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  75%|███████▍  | 228/305 [14:28<07:09,  5.58s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  66%|██████▌   | 200/305 [14:32<06:07,  3.50s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  64%|██████▍   | 196/305 [14:33<08:49,  4.86s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  76%|███████▋  | 232/304 [14:36<04:42,  3.92s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  78%|███████▊  | 236/304 [14:39<03:21,  2.96s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  67%|██████▋   | 204/305 [14:45<05:44,  3.41s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  76%|███████▌  | 232/305 [14:46<06:23,  5.25s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  79%|███████▉  | 240/304 [14:49<02:59,  2.80s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  68%|██████▊   | 208/305 [14:50<04:25,  2.74s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  77%|███████▋  | 236/305 [14:57<05:10,  4.50s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  66%|██████▌   | 200/305 [15:20<12:01,  6.88s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  79%|███████▊  | 240/305 [15:20<05:16,  4.87s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  80%|████████  | 244/304 [15:26<04:45,  4.75s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  67%|██████▋   | 204/305 [15:30<09:25,  5.60s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  80%|████████  | 244/305 [15:31<04:17,  4.22s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  82%|████████▏ | 248/304 [15:36<03:49,  4.10s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  68%|██████▊   | 208/305 [15:39<07:28,  4.62s/it][default1]:\n",
      "i.generate/0 [default1]:static requests:  70%|██████▉   | 212/305 [15:40<08:46,  5.66s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  83%|████████▎ | 252/304 [15:41<02:47,  3.22s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  81%|████████▏ | 248/305 [15:52<04:17,  4.52s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  71%|███████   | 216/305 [15:53<07:19,  4.94s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  72%|███████▏  | 220/305 [15:58<05:30,  3.89s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  70%|██████▉   | 212/305 [16:03<07:45,  5.01s/it][default3]:\n",
      "i.generate/0 [default3]:static requests:  84%|████████▍ | 256/304 [16:03<03:08,  3.93s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  86%|████████▌ | 260/304 [16:07<02:14,  3.07s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  83%|████████▎ | 252/305 [16:08<03:52,  4.39s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  73%|███████▎  | 224/305 [16:09<04:42,  3.49s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  87%|████████▋ | 264/304 [16:15<01:49,  2.75s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  75%|███████▍  | 228/305 [16:21<04:22,  3.41s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  88%|████████▊ | 268/304 [16:22<01:26,  2.39s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  71%|███████   | 216/305 [16:26<07:41,  5.18s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  72%|███████▏  | 220/305 [16:37<06:21,  4.48s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  89%|████████▉ | 272/304 [16:40<01:38,  3.08s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  84%|████████▍ | 256/305 [16:40<04:29,  5.50s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  76%|███████▌  | 232/305 [16:43<04:53,  4.02s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  91%|█████████ | 276/304 [16:47<01:13,  2.62s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  73%|███████▎  | 224/305 [16:57<06:16,  4.65s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  77%|███████▋  | 236/305 [16:59<04:35,  3.99s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  75%|███████▍  | 228/305 [17:05<04:55,  3.84s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  92%|█████████▏| 280/304 [17:11<01:28,  3.68s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  85%|████████▌ | 260/305 [17:16<04:52,  6.51s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  76%|███████▌  | 232/305 [17:17<04:20,  3.57s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  79%|███████▊  | 240/305 [17:17<04:28,  4.13s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  93%|█████████▎| 284/304 [17:21<01:05,  3.28s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  87%|████████▋ | 264/305 [17:22<03:26,  5.05s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  80%|████████  | 244/305 [17:25<03:35,  3.53s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  77%|███████▋  | 236/305 [17:31<04:07,  3.59s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  88%|████████▊ | 268/305 [17:33<02:41,  4.37s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  79%|███████▊  | 240/305 [17:42<03:36,  3.33s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  81%|████████▏ | 248/305 [17:44<03:41,  3.89s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  95%|█████████▍| 288/304 [17:47<01:08,  4.27s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  96%|█████████▌| 292/304 [17:59<00:46,  3.88s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  83%|████████▎ | 252/305 [18:02<03:36,  4.08s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  97%|█████████▋| 296/304 [18:06<00:26,  3.26s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  84%|████████▍ | 256/305 [18:12<02:57,  3.62s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  80%|████████  | 244/305 [18:14<04:46,  4.70s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  89%|████████▉ | 272/305 [18:18<03:31,  6.42s/it]i.generate/0 [default3]:\n",
      "i.generate/0 [default3]:static requests:  99%|█████████▊| 300/304 [18:21<00:13,  3.43s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  85%|████████▌ | 260/305 [18:23<02:30,  3.34s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  90%|█████████ | 276/305 [18:28<02:31,  5.22s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  81%|████████▏ | 248/305 [18:28<04:10,  4.40s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  87%|████████▋ | 264/305 [18:32<02:01,  2.97s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  83%|████████▎ | 252/305 [18:34<03:05,  3.49s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  92%|█████████▏| 280/305 [18:36<01:45,  4.22s/it][default3]:\n",
      "i.generate/0 [default3]:static requests: 100%|██████████| 304/304 [18:36<00:00,  3.49s/it]\n",
      "i.generate/0 [default3]:static requests: 100%|██████████| 304/304 [18:36<00:00,  3.67s/it]\n",
      "i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  84%|████████▍ | 256/305 [18:40<02:20,  2.86s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  88%|████████▊ | 268/305 [18:44<01:52,  3.03s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  93%|█████████▎| 284/305 [18:50<01:25,  4.08s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  94%|█████████▍| 288/305 [18:56<00:55,  3.26s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  85%|████████▌ | 260/305 [18:58<02:32,  3.39s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  89%|████████▉ | 272/305 [19:05<02:01,  3.69s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  90%|█████████ | 276/305 [19:24<01:55,  4.00s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  92%|█████████▏| 280/305 [19:40<01:38,  3.96s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  96%|█████████▌| 292/305 [19:41<01:13,  5.65s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  87%|████████▋ | 264/305 [19:44<03:58,  5.81s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  97%|█████████▋| 296/305 [19:46<00:39,  4.34s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests:  98%|█████████▊| 300/305 [19:54<00:18,  3.68s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  88%|████████▊ | 268/305 [20:10<03:43,  6.04s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests: 100%|█████████▉| 304/305 [20:11<00:03,  3.79s/it]i.generate/0 [default0]:\n",
      "i.generate/0 [default0]:static requests: 100%|██████████| 305/305 [20:13<00:00,  3.68s/it]\n",
      "i.generate/0 [default0]:static requests: 100%|██████████| 305/305 [20:13<00:00,  3.98s/it]\n",
      "i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  93%|█████████▎| 284/305 [20:33<02:21,  6.75s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  94%|█████████▍| 288/305 [20:38<01:26,  5.11s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  89%|████████▉ | 272/305 [20:53<04:06,  7.46s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  96%|█████████▌| 292/305 [20:55<01:03,  4.89s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  97%|█████████▋| 296/305 [21:00<00:33,  3.76s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  90%|█████████ | 276/305 [21:01<02:48,  5.82s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests:  98%|█████████▊| 300/305 [21:05<00:14,  3.00s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests: 100%|█████████▉| 304/305 [21:15<00:02,  2.88s/it]i.generate/0 [default1]:\n",
      "i.generate/0 [default1]:static requests: 100%|██████████| 305/305 [21:18<00:00,  2.83s/it]\n",
      "i.generate/0 [default1]:static requests: 100%|██████████| 305/305 [21:18<00:00,  4.19s/it]\n",
      "i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  92%|█████████▏| 280/305 [21:22<02:21,  5.66s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  93%|█████████▎| 284/305 [22:22<02:56,  8.42s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  94%|█████████▍| 288/305 [22:30<01:51,  6.53s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  96%|█████████▌| 292/305 [22:48<01:17,  5.93s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  97%|█████████▋| 296/305 [23:06<00:49,  5.46s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests:  98%|█████████▊| 300/305 [23:19<00:23,  4.79s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests: 100%|█████████▉| 304/305 [23:29<00:04,  4.09s/it]i.generate/0 [default2]:\n",
      "i.generate/0 [default2]:static requests: 100%|██████████| 305/305 [23:31<00:00,  3.94s/it]\n",
      "i.generate/0 [default2]:static requests: 100%|██████████| 305/305 [23:31<00:00,  4.63s/it]\n",
      "i.generate/0 [default0]:[NeMo I 2025-08-05 04:05:45 nemo_logging:393] Predictions written to peft_prediction.jsonl\n",
      "i.generate/0 I0805 04:05:52.905000 12109 torch/distributed/elastic/agent/server/api.py:879] [default] worker group successfully finished. Waiting 300 seconds for other agents to finish.\n",
      "i.generate/0 I0805 04:05:52.907000 12109 torch/distributed/elastic/agent/server/api.py:932] Local worker group finished (WorkerState.SUCCEEDED). Waiting 300 seconds for other agents to finish\n",
      "i.generate/0 I0805 04:05:52.909000 12109 torch/distributed/elastic/agent/server/api.py:946] Done waiting for other agents. Elapsed: 0.0007038116455078125 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.generate-lkzx5v6ssdx4cc finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.generate']</span><span style=\"background-color: #272822\">                           </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.generate_1754365308\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.generate\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.generate\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">                </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.generate']\u001b[0m\u001b[48;2;39;40;34m                           \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.generate_1754365308\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.generate\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.generate\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m                \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.generate_1754365308</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.generate_1754365308 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.generate_1754365308 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                              </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.generate_1754365308\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.generate_1754365308\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.generate_1754365308\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from megatron.core.inference.common_inference_params import CommonInferenceParams\n",
    "\n",
    "\n",
    "def trainer() -> run.Config[nl.Trainer]:\n",
    "    strategy = run.Config(\n",
    "        nl.MegatronStrategy,\n",
    "        tensor_model_parallel_size=1,\n",
    "    )\n",
    "    trainer = run.Config(\n",
    "        nl.Trainer,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=NUM_GPU_DEVICES,\n",
    "        num_nodes=1,\n",
    "        strategy=strategy,\n",
    "        plugins=bf16_mixed(),\n",
    "    )\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def configure_inference():\n",
    "    return run.Partial(\n",
    "        llm.generate,\n",
    "        path=str(sft_ckpt_path),\n",
    "        trainer=trainer(),\n",
    "        input_dataset=lse_data(),\n",
    "        inference_params=CommonInferenceParams(num_tokens_to_generate=50, top_k=1),\n",
    "        output_path=\"peft_prediction.jsonl\",\n",
    "    )\n",
    "\n",
    "\n",
    "def local_executor_torchrun(nodes: int = 1, devices: int = 1) -> run.LocalExecutor:\n",
    "    # Env vars for jobs are configured here\n",
    "    env_vars = {\n",
    "        \"TORCH_NCCL_AVOID_RECORD_STREAMS\": \"1\",\n",
    "        \"NCCL_NVLS_ENABLE\": \"0\",\n",
    "    }\n",
    "\n",
    "    executor = run.LocalExecutor(\n",
    "        ntasks_per_node=devices, launcher=\"torchrun\", env_vars=env_vars\n",
    "    )\n",
    "\n",
    "    return executor\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run.run(\n",
    "        configure_inference(), executor=local_executor_torchrun(devices=NUM_GPU_DEVICES)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the inference is complete, you will see results similar to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I bet most of you have heard - in some music compositions - short 5-10 seconds &quot;injections&quot; of voice-lines from some old movies.\\nI'm producing a track right now, where I want to insert a phrase from &quot;Conan the Destroyer&quot; (1984), it's under 10 seconds in length. I wonder if such use is &quot;legal&quot;?\\nI assume, due to neglectable short length of the sound-sample, it should be fine, but I just want to double-check. Any links to corresponding laws/acts would be appreciated, thanks. \\nTITLE: \", \"label\": \"Voice samples from the old movies in the music tracks\", \"prediction\": \"5-10 seconds of voice-line from old movie - is it legal to use in a music composition?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: Hypothetical: A UK company advertises a service and promises a free gift for new subscribers. I enter the service contract with the company as a private individual and get the &quot;free&quot; gift. The gift fails after a year in a way that would be covered under warranty if I had purchased the gift from a retailer. Is the company required to honor warranty? Can they just decide to issue a \\u00a30 refund?\\nI assume the answer is &quot;it depends on the nature of the service contract, the gift, and the advertisement&quot;, thus my question is: what are the rules? \\nTITLE: \", \"label\": \"&quot;free&quot; bundled items warranty in England\", \"prediction\": \"1. Is a company required to honor warranty on a &quot;free&quot; gift? 2. What are the rules?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: The same as the title.\\nIf I was underage (broke the ToS), could I be arrested? \\nTITLE: \", \"label\": \"Before I was 13 I had a facebook account. Could I be arrested?\", \"prediction\": \"18 USC 1030: Can I be arrested for breaking the ToS?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: If I have a proof that someone has (or has had) an illegal copy of my work how much time do I have in order to sue for copyright infringement? \\nTITLE: \", \"label\": \"How much time do you have for sueing someone for copyright infringement from the moment you have the proof?\", \"prediction\": \"3 year statute of limitations for copyright infringement?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I was reading USA Today article about Bannon, and one statement piqued my interest:\\n\\n\\n  Bannon\\u2019s military personnel file, obtained by USA TODAY, shows he was regularly promoted during his seven years of service.\\n\\n\\nThe quote directly linked to downloadable document of the file.\\n\\n\\nAre personnel files of former servicepeople considered private information that is not supposed to be made public? (i'm almost certain it's \\\"yes\\\" but don't know the precise legal rationale).\\nIf so, does USA Today obtaining it make it in any way legally culpable? (on one hand, possession of stolen goods makes one legally culpable, on the other hand, Pentagon Papers showed that this concept probably doesn't always apply to information).\\nEither way, my main question is, does USA Today publishing it make it in any way legally culpable, either in criminal court, or in possble civil litigation?\\n\\n\\nNot sure if it matters greatly, but at cursory look, the file has not been scrubbed of any information, so whatever PII/personal info was in it, would still be in it \\nTITLE: \", \"label\": \"Is Steve Bannon&#39;s Navy Personnel file protected information and if so, does USA Today bear legal culpability for obtaining and publishing it?\", \"prediction\": \" Are personnel files of former servicepeople considered private information that is not supposed to be made public?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I've seen a few similar questions asked before, however would posting a screenshot of an email onto social media be legal under the following circumstances:\\n\\nThe poster on social media is the recipient of such email\\nThe recipient uses Gmail, which ties the email address of the Sender to the a LinkedIn profile if they have one, displaying it to the right of the email and including the Name of the Sender, Photo of the Sender, and current job of the Sender, which were otherwise not stated in the email.\\nThe screenshot of the email includes all of this information: it displays not only the sender's email address and the original email, but also the information of the Sender's LinkedIn account (name, current job, photo) that the recipient's Gmail account linked to\\n\\nI'm curious to see how others would interpret these facts. The question here is not so much the content of the email but rather the inclusion of the other identifiable information (Name, email address, photo, current job) \\nTITLE: \", \"label\": \"Is it legal to post an email to social media if the email also contains a photo of the sender and other personal identifiable information?\", \"prediction\": \"1) Is it legal to post a screenshot of an email on social media? 2) Is it legal to post a screenshot of an email on social media if it includes the sender&#39;s LinkedIn information?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: My father passed away, and I want to put the house under my mothers name.\\nThe loan servicing company is asking for a transfer of title document. \\n\\nI am unsure what that is, or how I would go about attaining one. \\n\\nSide information: the house is in NJ \\nTITLE: \", \"label\": \"What is a transfer of title document?\", \"prediction\": \"1st time home buyer, how do I transfer title?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I have an app/website which connects people into groups and then the group performs work in the real world. That work in the real world will occasionally require that group members talk to each other. My app/website does not have a messaging feature yet and so I'm considering my options. While I could embed a chat screen into my app/website, that is a chunk of work I'd like to avoid for the moment. Instead, I'm considering other well supported messaging options such as email or SMS. Specifically, launching the default email or SMS app on the user's device. Since the point of the messaging is for members of the group to message each other, this would require that I hand over one group member's personal data (i.e. email address or phone number) to another group member. I understand that under GDPR I need to get specific consent for this use case when I first collect their personal data. If I get this consent, have I fully complied with the GDPR rules in the scenario I've described?\\nDoes the user who my app/website gives the personal data to have any obligations under GDPR?\\nDoes launching the native email app (or SMS app) with a fellow group member's personal data have legal issues beyond GDPR? \\nTITLE: \", \"label\": \"Do users who are given another user&#39;s email address have obligations under GDPR?\", \"prediction\": \"3rd party messaging in a group\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: The Bootstrap homepage states : \\n\\n\\n  Glyphicons Halflings are normally not available for free, but their creator has made them available for Bootstrap free of cost. As a thank you, we only ask that you include a link back to Glyphicons whenever possible.\\n\\n\\n- it asks me to \\\"link back to Glyphicons\\\" - is this legally binding ? \\nTITLE: \", \"label\": \"Do I have to link to the glyphicon website?\", \"prediction\": \" Is the Bootstrap license legally binding?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I am a newbie novelist and in my novel, I have copied a small part from the 1973 Swedish film Scenes from a Marriage. I am from India and the film is Swedish. I want to ask, is the film in public domain after so many years? If I get published can I get sued for coping that part? \\nTITLE: \", \"label\": \"Can I get sued for copying a 1973 Swedish film?\", \"prediction\": \"1973 Swedish film Scenes from a Marriage\"}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 10 peft_prediction.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curator\t\t\t       lse_chatdatamodule.py\n",
      "NeMo\t\t\t       lse_datamodule.py\n",
      "README_chat_templates.md       nemo-data-flywheel-tutorials\n",
      "__pycache__\t\t       nemo_experiments\n",
      "bge-base-financial-matryoshka  peft_prediction.jsonl\n",
      "convert_llama_embedding.py     sft_prediction.jsonl\n",
      "convert_to_hf.py\t       snap\n",
      "data\t\t\t       test\n",
      "dms_logs.json\t\t       test_dataset.json\n",
      "example_usage.py\t       train_dataset.json\n",
      "fiqa_data\t\t       unsloth_compiled_cache\n",
      "gemma3_ticket_router\t       virt-envs\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I bet most of you have heard - in some music compositions - short 5-10 seconds &quot;injections&quot; of voice-lines from some old movies.\\nI'm producing a track right now, where I want to insert a phrase from &quot;Conan the Destroyer&quot; (1984), it's under 10 seconds in length. I wonder if such use is &quot;legal&quot;?\\nI assume, due to neglectable short length of the sound-sample, it should be fine, but I just want to double-check. Any links to corresponding laws/acts would be appreciated, thanks. \\nTITLE: \", \"label\": \"Voice samples from the old movies in the music tracks\", \"prediction\": \"5-10 seconds of voice-line from old movie - is it legal to use in a music composition?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: Hypothetical: A UK company advertises a service and promises a free gift for new subscribers. I enter the service contract with the company as a private individual and get the &quot;free&quot; gift. The gift fails after a year in a way that would be covered under warranty if I had purchased the gift from a retailer. Is the company required to honor warranty? Can they just decide to issue a \\u00a30 refund?\\nI assume the answer is &quot;it depends on the nature of the service contract, the gift, and the advertisement&quot;, thus my question is: what are the rules? \\nTITLE: \", \"label\": \"&quot;free&quot; bundled items warranty in England\", \"prediction\": \"1. Is a company required to honor warranty on a &quot;free&quot; gift? 2. What are the rules?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: The same as the title.\\nIf I was underage (broke the ToS), could I be arrested? \\nTITLE: \", \"label\": \"Before I was 13 I had a facebook account. Could I be arrested?\", \"prediction\": \"18 USC 1030: Can I be arrested for breaking the ToS?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: If I have a proof that someone has (or has had) an illegal copy of my work how much time do I have in order to sue for copyright infringement? \\nTITLE: \", \"label\": \"How much time do you have for sueing someone for copyright infringement from the moment you have the proof?\", \"prediction\": \"3 year statute of limitations for copyright infringement?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I was reading USA Today article about Bannon, and one statement piqued my interest:\\n\\n\\n  Bannon\\u2019s military personnel file, obtained by USA TODAY, shows he was regularly promoted during his seven years of service.\\n\\n\\nThe quote directly linked to downloadable document of the file.\\n\\n\\nAre personnel files of former servicepeople considered private information that is not supposed to be made public? (i'm almost certain it's \\\"yes\\\" but don't know the precise legal rationale).\\nIf so, does USA Today obtaining it make it in any way legally culpable? (on one hand, possession of stolen goods makes one legally culpable, on the other hand, Pentagon Papers showed that this concept probably doesn't always apply to information).\\nEither way, my main question is, does USA Today publishing it make it in any way legally culpable, either in criminal court, or in possble civil litigation?\\n\\n\\nNot sure if it matters greatly, but at cursory look, the file has not been scrubbed of any information, so whatever PII/personal info was in it, would still be in it \\nTITLE: \", \"label\": \"Is Steve Bannon&#39;s Navy Personnel file protected information and if so, does USA Today bear legal culpability for obtaining and publishing it?\", \"prediction\": \" Are personnel files of former servicepeople considered private information that is not supposed to be made public?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I've seen a few similar questions asked before, however would posting a screenshot of an email onto social media be legal under the following circumstances:\\n\\nThe poster on social media is the recipient of such email\\nThe recipient uses Gmail, which ties the email address of the Sender to the a LinkedIn profile if they have one, displaying it to the right of the email and including the Name of the Sender, Photo of the Sender, and current job of the Sender, which were otherwise not stated in the email.\\nThe screenshot of the email includes all of this information: it displays not only the sender's email address and the original email, but also the information of the Sender's LinkedIn account (name, current job, photo) that the recipient's Gmail account linked to\\n\\nI'm curious to see how others would interpret these facts. The question here is not so much the content of the email but rather the inclusion of the other identifiable information (Name, email address, photo, current job) \\nTITLE: \", \"label\": \"Is it legal to post an email to social media if the email also contains a photo of the sender and other personal identifiable information?\", \"prediction\": \"1) Is it legal to post a screenshot of an email on social media? 2) Is it legal to post a screenshot of an email on social media if it includes the sender&#39;s LinkedIn information?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: My father passed away, and I want to put the house under my mothers name.\\nThe loan servicing company is asking for a transfer of title document. \\n\\nI am unsure what that is, or how I would go about attaining one. \\n\\nSide information: the house is in NJ \\nTITLE: \", \"label\": \"What is a transfer of title document?\", \"prediction\": \"1st time home buyer, how do I transfer title?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I have an app/website which connects people into groups and then the group performs work in the real world. That work in the real world will occasionally require that group members talk to each other. My app/website does not have a messaging feature yet and so I'm considering my options. While I could embed a chat screen into my app/website, that is a chunk of work I'd like to avoid for the moment. Instead, I'm considering other well supported messaging options such as email or SMS. Specifically, launching the default email or SMS app on the user's device. Since the point of the messaging is for members of the group to message each other, this would require that I hand over one group member's personal data (i.e. email address or phone number) to another group member. I understand that under GDPR I need to get specific consent for this use case when I first collect their personal data. If I get this consent, have I fully complied with the GDPR rules in the scenario I've described?\\nDoes the user who my app/website gives the personal data to have any obligations under GDPR?\\nDoes launching the native email app (or SMS app) with a fellow group member's personal data have legal issues beyond GDPR? \\nTITLE: \", \"label\": \"Do users who are given another user&#39;s email address have obligations under GDPR?\", \"prediction\": \"3rd party messaging in a group\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: The Bootstrap homepage states : \\n\\n\\n  Glyphicons Halflings are normally not available for free, but their creator has made them available for Bootstrap free of cost. As a thank you, we only ask that you include a link back to Glyphicons whenever possible.\\n\\n\\n- it asks me to \\\"link back to Glyphicons\\\" - is this legally binding ? \\nTITLE: \", \"label\": \"Do I have to link to the glyphicon website?\", \"prediction\": \" Is the Bootstrap license legally binding?\"}\n",
      "{\"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I am a newbie novelist and in my novel, I have copied a small part from the 1973 Swedish film Scenes from a Marriage. I am from India and the film is Swedish. I want to ask, is the film in public domain after so many years? If I get published can I get sued for coping that part? \\nTITLE: \", \"label\": \"Can I get sued for copying a 1973 Swedish film?\", \"prediction\": \"1973 Swedish film Scenes from a Marriage\"}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 10 peft_prediction.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see output similar to the following:\n",
    "```json\n",
    "{\n",
    "    \"input\": \"Generate a concise, legally-relevant, and SEO-friendly title for the following legal question in the Law Stack Exchange internet forum.\\nQUESTION: I bet most of you have heard - in some music compositions - short 5-10 seconds &quot;injections&quot; of voice-lines from some old movies.\\nI'm producing a track right now, where I want to insert a phrase from &quot;Conan the Destroyer&quot; (1984), it's under 10 seconds in length. I wonder if such use is &quot;legal&quot;?\\nI assume, due to neglectable short length of the sound-sample, it should be fine, but I just want to double-check. Any links to corresponding laws/acts would be appreciated, thanks. \\nTITLE: \", \n",
    "    \"label\": \"Voice samples from the old movies in the music tracks\", \n",
    "    \"prediction\": \"5-10 seconds of voice-line from old movie - is it legal to use in a music composition?\"\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5. Calculate Evaluation Metrics\n",
    "\n",
    "We can evaluate the model's predictions by calculating the following metrics -\n",
    "- **Exact Match** is a binary measure (0 or 1) checking if the model outputs match one of the\n",
    "ground truth answer exactly.\n",
    "- **F1 score** is the harmonic mean of precision and recall for the answer words.\n",
    "- **ROUGE-L score** is a metric that measures the longest common subsequence between the predicted and reference answers, capturing how well the generated text matches the ground truth in terms of sequence similarity.\n",
    "\n",
    "Below is a script that computes these metrics. In this notebook, we only train for a few steps for demonstration. The sample scores can be improved by training the model further and performing hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match 0.902\tf1 28.642\trougeL 29.365\ttotal 1219.000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python /opt/NeMo/scripts/metric_calculation/peft_metric_calc.py \\\n",
    "    --pred_file peft_prediction.jsonl \\\n",
    "    --label_field \"label\" \\\n",
    "    --pred_field \"prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6. Export to HF\n",
    "\n",
    "The next step is to export the model to HF format. This format can be ingested by NVIDIA NIM for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the export directory\n",
    "EXPORT_DIR = \"/nemo-experiments/models/llama-3.1-8b-peft-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell uses the `llm.export_ckpt` API, wrapped by NeMo Run's `run.Partial` primitive, followed by executing it.\n",
    "\n",
    "Its worth noting that `target=hf-peft` indicates that it will export the PEFT (LoRA) adapter. For exporting a full model, you may use `target=hf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">─ </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Entering Experiment nemo.collections.llm.api.export_ckpt with id: nemo.collections.llm.api.export_ckpt_1754367…</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m─ \u001b[0m\u001b[1;35mEntering Experiment nemo.collections.llm.api.export_ckpt with id: nemo.collections.llm.api.export_ckpt_1754367…\u001b[0m\u001b[92m ─\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.export_ckpt/nemo.collections.llm.api.export_ckpt_1754367034/nemo.collections.llm.api.export_ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[04:10:34] </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Launching job nemo.collections.llm.api.export_ckpt for experiment </span>                     <a href=\"file:///opt/Run/nemo_run/run/experiment.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">experiment.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/Run/nemo_run/run/experiment.py#771\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">771</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">nemo.collections.llm.api.export_ckpt</span>                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[04:10:34]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;36mLaunching job nemo.collections.llm.api.export_ckpt for experiment \u001b[0m                     \u001b]8;id=336192;file:///opt/Run/nemo_run/run/experiment.py\u001b\\\u001b[2mexperiment.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=694631;file:///opt/Run/nemo_run/run/experiment.py#771\u001b\\\u001b[2m771\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36mnemo.collections.llm.api.export_ckpt\u001b[0m                                                   \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log directory is: /root/.nemo_run/experiments/nemo.collections.llm.api.export_ckpt/nemo.collections.llm.api.export_ckpt_1754367034/nemo.collections.llm.api.export_ckpt\n",
      "Launched app: local_persistent://nemo_run/nemo.collections.llm.api.export_ckpt-hrc7pbxj6rs74c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────── </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Waiting for Experiment nemo.collections.llm.api.export_ckpt_1754367034 to finish</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────── \u001b[0m\u001b[1;35mWaiting for Experiment nemo.collections.llm.api.export_ckpt_1754367034 to finish\u001b[0m\u001b[92m ─────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Experiment Status for</span> <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.export_ckpt_1754367034</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mExperiment Status for\u001b[0m \u001b[1;38;5;214mnemo.collections.llm.api.export_ckpt_1754367034\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task 0</span>: <span style=\"color: #ffaf00; text-decoration-color: #ffaf00; font-weight: bold\">nemo.collections.llm.api.export_ckpt</span>\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Status</span>: RUNNING\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Executor</span>: LocalExecutor\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Job id</span>: nemo.collections.llm.api.export_ckpt-hrc7pbxj6rs74c\n",
       "- <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Local Directory</span>: /root/.nemo_run/experiments/nemo.collections.llm.api.export_ckpt/nemo.collections.llm.api.export_ckpt_1754367034/nemo.collections.llm.api.export_ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTask 0\u001b[0m: \u001b[1;38;5;214mnemo.collections.llm.api.export_ckpt\u001b[0m\n",
       "- \u001b[1;32mStatus\u001b[0m: RUNNING\n",
       "- \u001b[1;32mExecutor\u001b[0m: LocalExecutor\n",
       "- \u001b[1;32mJob id\u001b[0m: nemo.collections.llm.api.export_ckpt-hrc7pbxj6rs74c\n",
       "- \u001b[1;32mLocal Directory\u001b[0m: /root/.nemo_run/experiments/nemo.collections.llm.api.export_ckpt/nemo.collections.llm.api.export_ckpt_1754367034/nemo.collections.llm.api.export_ckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for job nemo.collections.llm.api.export_ckpt-hrc7pbxj6rs74c to finish [log=True]...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xport_ckpt/0 [NeMo W 2025-08-05 04:10:47 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "xport_ckpt/0       warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "xport_ckpt/0     \n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "xport_ckpt/0 GPU available: True (cuda), used: False\n",
      "xport_ckpt/0 TPU available: False, using: 0 TPU cores\n",
      "xport_ckpt/0 HPU available: False, using: 0 HPUs\n",
      "xport_ckpt/0 [NeMo W 2025-08-05 04:10:50 nemo_logging:405] /opt/venv/lib/python3.12/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "xport_ckpt/0     \n",
      "xport_ckpt/0 ----------------------------------------------------------------------------------------------------\n",
      "xport_ckpt/0 distributed_backend=gloo\n",
      "xport_ckpt/0 All distributed processes registered. Starting with 1 processes\n",
      "xport_ckpt/0 ----------------------------------------------------------------------------------------------------\n",
      "xport_ckpt/0 \n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:50 nemo_logging:393] Padded vocab_size: 128256, original vocab_size: 128256, dummy tokens: 0.\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:55 nemo_logging:393] Apply rope scaling with factor=8.0, low_freq_factor=1.0, high_freq_factor=4.0, old_context_len=8192.\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:55 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 8030261248\n",
      "xport_ckpt/0 [NeMo W 2025-08-05 04:10:55 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.0.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.0.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.1.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.1.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.2.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.2.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.3.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.3.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.4.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.4.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.5.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.5.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.6.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.6.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.7.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.7.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.8.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.8.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.9.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.9.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.10.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.10.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.11.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.11.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.12.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.12.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.13.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.13.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.14.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.14.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.15.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.15.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.16.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.16.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.17.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.17.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.18.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.18.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.19.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.19.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.20.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.20.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.21.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.21.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.22.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.22.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.23.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.23.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.24.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.24.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.25.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.25.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.26.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.26.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.27.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.27.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.28.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.28.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.29.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.29.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.30.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.30.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_proj\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.31.self_attention.linear_qkv\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc1\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Adding lora to: module.decoder.layers.31.mlp.linear_fc2\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x761e0ef3e240> dist-ckpt load strategy.\n",
      "xport_ckpt/0 [NeMo I 2025-08-05 04:10:56 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1754367056.374s : Time spent in load_checkpoint: 0.209s\n",
      "xport_ckpt/0 \u001b[32m✓ Checkpoint exported to \u001b[0m\u001b[32m/nemo-experiments/models/\u001b[0m\u001b[32mllama-3.1-8b-peft-hf\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job nemo.collections.llm.api.export_ckpt-hrc7pbxj6rs74c finished: SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># The experiment was run with the following tasks: ['nemo.collections.llm.api.export_ckpt']</span><span style=\"background-color: #272822\">                        </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect and reconstruct this experiment at a later point in time using:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> run</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">from_id(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.export_ckpt_1754367034\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">status() </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the overall status</span><span style=\"background-color: #272822\">                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">logs(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.export_ckpt\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Gets the log for the provided task</span><span style=\"background-color: #272822\">                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">experiment</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">cancel(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"nemo.collections.llm.api.export_ckpt\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># Cancels the provided task if still running</span><span style=\"background-color: #272822\">             </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# The experiment was run with the following tasks: ['nemo.collections.llm.api.export_ckpt']\u001b[0m\u001b[48;2;39;40;34m                        \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect and reconstruct this experiment at a later point in time using:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrun\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mExperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfrom_id\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.export_ckpt_1754367034\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the overall status\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.export_ckpt\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Gets the log for the provided task\u001b[0m\u001b[48;2;39;40;34m                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnemo.collections.llm.api.export_ckpt\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# Cancels the provided task if still running\u001b[0m\u001b[48;2;39;40;34m             \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># You can inspect this experiment at a later point in time using the CLI as well:</span><span style=\"background-color: #272822\">                                  </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment status nemo.collections.llm.api.export_ckpt_1754367034</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment logs nemo.collections.llm.api.export_ckpt_1754367034 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">nemo experiment cancel nemo.collections.llm.api.export_ckpt_1754367034 </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"background-color: #272822\">                                           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;149;144;119;48;2;39;40;34m# You can inspect this experiment at a later point in time using the CLI as well:\u001b[0m\u001b[48;2;39;40;34m                                  \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstatus\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.export_ckpt_1754367034\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlogs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.export_ckpt_1754367034\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mnemo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mexperiment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcancel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnemo.collections.llm.api.export_ckpt_1754367034\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[48;2;39;40;34m                                           \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported Hugging Face model to: /nemo-experiments/models/llama-3.1-8b-peft-hf\n"
     ]
    }
   ],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# import nemo_run as run\n",
    "# from nemo.collections import llm\n",
    "\n",
    "\n",
    "def configure_export_ckpt():\n",
    "    return run.Partial(\n",
    "        llm.export_ckpt,\n",
    "        path=sft_ckpt_path,\n",
    "        target=\"hf-peft\",\n",
    "        output_path=EXPORT_DIR,\n",
    "    )\n",
    "\n",
    "\n",
    "local_executor = run.LocalExecutor()\n",
    "run.run(configure_export_ckpt(), executor=local_executor)\n",
    "print(f\"Exported Hugging Face model to: {EXPORT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember this export path, as you will need it in the next steps to deploy the model with NIM for inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
